<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />


<meta name="author" content="Marcos Longo" />

<meta name="date" content="2022-04-25" />

<title>TRY traits trade-offs</title>

<script src="site_libs/header-attrs-2.25/header-attrs.js"></script>
<script src="site_libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/darkly.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<style>h1 {font-size: 34px;}
       h1.title {font-size: 38px;}
       h2 {font-size: 30px;}
       h3 {font-size: 24px;}
       h4 {font-size: 18px;}
       h5 {font-size: 16px;}
       h6 {font-size: 12px;}
       code {color: inherit; background-color: rgba(0, 0, 0, 0.04);}
       pre:not([class]) { background-color: white }</style>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/textmate.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>

<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
    </style>

<style type="text/css">code{white-space: pre;}</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>






<link rel="stylesheet" href="styles.css" type="text/css" />



<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
details > summary > p:only-child {
  display: inline;
}
pre code {
  padding: 0;
}
</style>


<style type="text/css">
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #adb5bd;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script type="text/javascript">
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark the anchor link active (and if it's in a dropdown, also mark that active)
  var dropdown = menuAnchor.closest('li.dropdown');
  if (window.bootstrap) { // Bootstrap 4+
    menuAnchor.addClass('active');
    dropdown.find('> .dropdown-toggle').addClass('active');
  } else { // Bootstrap 3
    menuAnchor.parent().addClass('active');
    dropdown.addClass('active');
  }

  // Navbar adjustments
  var navHeight = $(".navbar").first().height() + 15;
  var style = document.createElement('style');
  var pt = "padding-top: " + navHeight + "px; ";
  var mt = "margin-top: -" + navHeight + "px; ";
  var css = "";
  // offset scroll position for anchor links (for fixed navbar)
  for (var i = 1; i <= 6; i++) {
    css += ".section h" + i + "{ " + pt + mt + "}\n";
  }
  style.innerHTML = "body {" + pt + "padding-bottom: 40px; }\n" + css;
  document.head.appendChild(style);
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before, .tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "\e259";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "\e258";
  font-family: 'Glyphicons Halflings';
  border: none;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->




</head>

<body>


<div class="container-fluid main-container">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-bs-toggle="collapse" data-target="#navbar" data-bs-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">Trait and Allometry Workflow</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">Home</a>
</li>
<li>
  <a href="TidyTraitAllomDB.html">Tidy trait and allometry data base</a>
</li>
<li>
  <a href="TraitTradeOffs.html">Trait trade-off analysis</a>
</li>
<li>
  <a href="AllomModelFit.html">Allometric model fitting</a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div id="header">



<h1 class="title toc-ignore">TRY traits trade-offs</h1>
<h4 class="author">Marcos Longo</h4>
<h4 class="date">2022-04-25</h4>

</div>


<style>
pre {
  overflow-x: auto;
}
pre code {
  word-wrap: normal;
  white-space: pre;
}
</style>
<div id="introduction." class="section level1">
<h1>Introduction.</h1>
<p>This script seeks to establish trait trade-off relationships for
different plant functional groups.</p>
<p>Set paths and file names for input and output.</p>
<ul>
<li><strong>home_path</strong>. The user home path.</li>
<li><strong>main_path</strong>. Main working directory</li>
<li><strong>util_path</strong>. The path with the additional utility
scripts (the full path of <code>RUtils</code>).</li>
<li><strong>summ_path</strong>. Path for summaries by species, genus and
cluster.</li>
<li><strong>plot_path</strong>. The main output path for the simulation
plots.</li>
<li><strong>rdata_path</strong>. Output path for R objects (so we can
use it for comparisons.)</li>
<li><strong>br_state_shp</strong>. Shapefile with Brazilian states.</li>
</ul>
<pre class="r"><code># Set useful paths and file names
home_path       = path.expand(&quot;~&quot;)
main_path       = file.path(home_path,&quot;Data&quot;,&quot;TraitAllom_Workflow&quot;)
util_path       = file.path(main_path,&quot;RUtils&quot;)
summ_path       = file.path(main_path,&quot;TaxonSummary&quot;)
plot_path       = file.path(main_path,&quot;Figures&quot;)
rdata_path      = file.path(main_path,&quot;RData&quot;)
br_state_shp    = file.path(main_path,&quot;BrazilianStatesMap&quot;,&quot;BrazilianStates.shp&quot;)</code></pre>
<p>Settings for reloading or rerunning multiple steps of this script.
These are all logical variables, with <code>TRUE</code> meaning to
reload previous calculations, and <code>FALSE</code> meaning to
calculate the step again. If the RData file is not found, these
variables will be ignored.</p>
<ul>
<li><strong>reload_SMA_trait</strong>. Reload the SMA fits for traits
(general)?</li>
<li><strong>reload_SMA_photo</strong>. Reload the SMA fits for traits
(photosynthesis traits)?</li>
<li><strong>reload_corr_trait</strong>. Reload the rank correlation
matrix (general)?</li>
<li><strong>reload_impute</strong>. Reload the imputed data sets?</li>
<li><strong>reload_cluster</strong>. Reload the cluster analysis.</li>
</ul>
<pre class="r"><code>reload_SMA_trait  = c(FALSE,TRUE)[2L]
reload_SMA_photo  = c(FALSE,TRUE)[2L]
reload_corr_trait = c(FALSE,TRUE)[2L]
reload_impute     = c(FALSE,TRUE)[2L]
reload_cluster    = c(FALSE,TRUE)[2L]</code></pre>
<p>This flag defines whether to exclude observations from traits that
show high light plasticity but were not collected from sunny leaves.</p>
<pre class="r"><code>plastic_sun_only = c(FALSE,TRUE)[2L]</code></pre>
<p>This flag defines the levels of experiments to be included (missing
values are always assumed natural and thus included). -
<strong>0</strong>. Control data sets (i.e., those without treatment in
treatment experiments) - <strong>1</strong>. Minor treatments (i.e.,
fences or logging, where the changes in environment are unlikely to
affect traits beyond what could normally occur in the landscape) -
<strong>2</strong>. Temperature treatments (warming / cooling). -
<strong>3</strong>. Water treatments (droughts, irrigation) -
<strong>4</strong>. Light treatments (lamps, shades) -
<strong>5</strong>. <span class="math inline">\(\mathrm{CO}_2\)</span>
experiments (enhancement, removal). - <strong>6</strong>. Nutrient
experiments (fertilisation, suppression). - <strong>7</strong>. Other
experiments (ozone, pesticides, multiple factors).</p>
<p>If <code>use_treat_level=integer(0L)</code>, then only data from
non-treatment studies will be considered. We advise to include at least
level 0, as they are often equivalent to non-treatment studies. If
<code>use_treat_level=NA_integer_</code>, then the flag will be ignored,
meaning that treatment data will be all considered.</p>
<pre class="r"><code>use_treat_level = c(0L,1L) # Which treatment levels to include in data analysis</code></pre>
<p>This flag defines whether to keep only woody plants, and how strict
we should be about it. Possible values are:</p>
<ul>
<li><strong>tree_only</strong>. Only trees (sensu stricto) are included.
This will exclude shrubs, lianas, hemiepiphytes and tree-like forms
(e.g., palms, yucca “trees”).</li>
<li><strong>woody_ss_free</strong>. All free-standing woody plants
(sensu stricto) are included. This will include trees and shrubs, but
exclude lianas, hemiepiphytes, and tree-like forms.</li>
<li><strong>woody_ss_all</strong>. All woody plants (sensu stricto) are
included. This will include trees, lianas, shrubs and hemiepiphytes, but
exclude tree-like forms.Summ</li>
<li><strong>woody_sl_free</strong>. All free-standing woody plants
(sensu lato) are included. This will include trees, shrubs and tree-like
forms, but exclude lianas and hemiepiphytes.</li>
<li><strong>woody_sl_all</strong>. All woody plants (sensu lato) are
included. This will include trees, lianas, shrubs, palms and
hemiepiphytes.</li>
<li><strong>all_plants</strong>. All plants will be retained.</li>
</ul>
<pre class="r"><code>use_woody_level = c(&quot;tree_only&quot;,&quot;woody_ss_free&quot;,&quot;woody_ss_all&quot;,&quot;woody_sl_free&quot;,&quot;woody_sl_all&quot;,&quot;all_plants&quot;)[2L]</code></pre>
<p>The following block defines some settings for the standardised major
axis for most traits and photosynthesis traits:</p>
<ul>
<li><p><strong>xsma_TraitID</strong>. Variable to be used as the X axis
of the SMA fit for most traits. This must be a trait ID that matches one
of the traits listed in <code>try_trait</code>, defined in the trait
file list (<code>trait_file</code>) and loaded from file
<code>rdata_TidyTRY</code>.</p></li>
<li><p><strong>xphoto_TraitID</strong>. Variable to be used as the X
axis of the SMA fits for photosynthesis. This must be a trait ID that
matches one of the traits listed in <code>try_trait</code>, defined in
the trait file list (<code>trait_file</code>) and loaded from file
<code>rdata_TidyTRY</code>.</p></li>
<li><p><strong>n_violin_min</strong>. Minimum number of valid points to
consider for violin diagrams.</p></li>
<li><p><strong>n_fit_min</strong>. Minimum number of valid points to
consider for SMA fits.</p></li>
<li><p><strong>n_predict</strong>. Number of points used along the trait
span to make the fitted curve.</p></li>
<li><p><strong>n_boot</strong>. Number of bootstrap iterations for
building confidence bands for SMA models.</p></li>
<li><p><strong>SMA_ConfInt</strong>. Confidence range for the SMA
models.</p></li>
<li><p><strong>SMA_CorrMin</strong>. Minimum (absolute) correlation to
fit SMA models. This is needed because at very low correlations, the
slope of the SMA fit may flip from negative to positive in between
bootstrap samples and cause very odd confidence ranges. These fits are
not significant, so we skip them altogether.</p></li>
<li><p><strong>SMA_Robust</strong>. Use robust approach for fitting SMA
(<code>TRUE</code>|<code>FALSE</code>). Robust fitting is better, but it
takes much longer because of the bootstrap uncertainty quantification.
Set this to <code>FALSE</code> when testing, so it saves time, and set
this to <code>TRUE</code> when producing the final results.</p></li>
<li><p><strong>SMA_MaxIter</strong>. Maximum number of iterations for
confidence interval. This is needed especially when SMA_Robust is
<code>FALSE</code>, because the default SMA is not robust to outliers,
and confidence ranges may be outside the expected value. This typically
occurs in poor model fittings.</p></li>
<li><p><strong>use_lifeclass</strong>. Which life-form/phylogenetic
level was used to subset the original data set. Options are:</p>
<ul>
<li><code>"FlowerTrees"</code>. Trees, classes Magnoliopsida and
Liliopsida (flowering plants).</li>
<li><code>"Shrubs"</code>. Shrubs</li>
<li><code>"Grasses"</code>. Grasses/Herbs</li>
<li><code>"FlowerPlants"</code>. All life forms, classes Magnoliopsida
and Liliopsida</li>
<li><code>"Pinopsida"</code>. Conifers (class Pinopsida), all life
forms</li>
<li><code>"SeedPlants"</code>. Seed plants, all life forms: classes
Cycadopsida, Ginkgoopsida, Gnetopsida, Liliopsida, Magnoliopsida and
Pinopsida.</li>
<li><code>"Plantae"</code>. All plants</li>
</ul></li>
<li><p><strong>use_realm</strong>. Which realm was used to subset the
original data set. Current options are:</p>
<ul>
<li><code>"NeoTropical"</code>. South and Central America</li>
<li><code>"PanTropical"</code>. All continents.</li>
</ul></li>
<li><p><strong>fit_taxon</strong>. Which taxonomic level of detail to
use for SMA analyses? Options are:</p>
<ul>
<li><code>"Individual"</code>. Treat each individual independently (only
individuals with measurements of traits in both axes will be
included).</li>
<li><code>"Species"</code>. Find trait averages for species then compute
SMA (useful for somewhat sparse measurements).</li>
<li><code>"Genus"</code>. Find trait averages for genus then compute SMA
(useful for very sparse measurements).</li>
</ul></li>
</ul>
<pre class="r"><code># Variable to use as X axis for trait SMA analyses?
xsma_TraitID    = c(SLA=3117L,wood_dens=4L,leaf_c2n=146L,leaf_n_area=50L)[1L]

# Variable to use as X axis for trait SMA analyses of photosynthesis traits?
xphoto_TraitID  = c(a_amax=53L,a_vcmax=186L,a_jmax=269L,m_amax=40L,m_vcmax=185L,m_jmax=270L)[2L]  

# Minimum number for plotting violins
n_violin_min    = 10L

# Minimum number of points for SMA fitting.
n_fit_min       = 20L

# Number of points to build prediction curve.
n_predict       = 200L

# Number of bootstrap iterations
n_boot          = 1000L

# Confidence range for SMA models and correlation tests
SMA_ConfInt     = 0.95

# Minimum absolute correlation to fit the SMA model
SMA_AbsCorrMin  = 10^(-0.5)

# Use robust fitting for SMA?
SMA_Robust      = FALSE

# How many attempts for bootstrapping before giving up?
SMA_MaxIter     = 10L

# Life-form/phylogenetic level to use for SMA analyses.
use_lifeclass  = c(&quot;FlowerTrees&quot;,&quot;Shrubs&quot;,&quot;Grasses&quot;,&quot;FlowerPlants&quot;,&quot;Pinopsida&quot;,&quot;SeedPlants&quot;,&quot;Plantae&quot;)[4L]

# Realm to use for SMA analyses.
use_realm  = c(&quot;NeoTropical&quot;,&quot;PanTropical&quot;)[1L]

# Taxonomic level of detail for SMA analyses.
fit_taxon = c(&quot;Individual&quot;,&quot;Species&quot;,&quot;Genus&quot;)[2L]</code></pre>
<p>Settings for Kendall correlation table</p>
<ul>
<li><strong>n_kendall_min</strong>. This is the minimum number of valid
pairs of variables for computing correlation.</li>
<li><strong>pmax_kendall_show</strong>. Maximum p-value for which
correlations are written to the CSV file.</li>
</ul>
<pre class="r"><code>n_kendall_min     = 30L   # Minimum number of data pairs for Kendall correlation.
pmax_kendall_show = 0.001 # Maximum correlation reported in the CSV file.</code></pre>
<p>Settings for the Imputation, Cluster Analysis and Principal Component
Analysis:</p>
<ul>
<li><strong>impute_cluster_test</strong>. Flag to decide whether to run
the code in test mode. If <code>TRUE</code>, this will reduce the number
of Monte Carlo iterations to 10, halt the code after running the cluster
analysis and skip saving the imputation and cluster analysis RData
objects so the code can be tested again. When running the actual
analyses, make sure this is set to <code>FALSE</code>.</li>
<li><strong>n_row_numtrait_impute</strong>. For each entry (row), we
check whether the trait has a sufficient number of numeric
(non-categorical) traits to be included in imputation, and analyses that
depend upon the imputed table.</li>
<li><strong>f_col_trait_impute</strong>. For each column (trait), we
check whether the trait has sufficient valid data relative to the most
abundant numeric trait. Only those traits (numeric or categorical) that
exceed this threshold will be considered for imputation and subsequent
analyses (cluster analysis, PCA, etc.). This is provided as a
fraction.</li>
<li><strong>f_var_min_impute</strong>. For each column (trait), we check
whether the trait has sufficient variability to be included. For numeric
traits, variability is defined as standard deviation divided by the mean
of absolute values (to get the mean magnitude of trait values and not
worry about the sign or when the mean is close to zero). For categorical
traits, variability isd defined as evenness.</li>
<li><strong>rseed_impute</strong>. This is used to define the seed for
random numbers ahead of the imputation, to ensure reproducibility. If
set to <code>NA_integer_</code>, the code will use time for setting the
seed, making it truly random.</li>
<li><strong>cluster_kmin</strong>. Minimum number of clusters to
consider (when seeking the optimum number of clusters)</li>
<li><strong>cluster_kmax</strong>. Maximum number of clusters to
consider (when seeking the optimum number of clusters)</li>
<li><strong>cluster_kfix</strong>. A number of clusters to be saved
regardless of the optimum. It must be between <code>cluster_kmin</code>
and <code>cluster_kmax</code>. This is used depending on how
<code>cluster_method</code> is set.</li>
<li><strong>min_weight_cluster</strong>. Weighting threshold below which
traits are ignored in the cluster analysis</li>
<li><strong>rseed_cluster</strong>. This is used to define the seed for
random numbers ahead of the cluster analysis standard error, to ensure
reproducibility. If set to <code>NA_integer_</code>, the code will use
time for setting the seed, making it truly random.</li>
<li><strong>n_mcarlo_cluster</strong>. Number of Monte Carlo iterations
to produce standard error for the gap statistics. Higher numbers yield
to more robust estimates, but this step takes a lot of time.</li>
<li><strong>method_gap_maxSE</strong>. Which method to use for selecting
the maximum gap statistics. This must be one of the options for argument
<code>method</code> in function <code>clusGap::maxSE</code>.</li>
<li><strong>cluster_method</strong>. Which method to use for selecting
the optimum number of clusters. Current options are “sil” (for
silhouette), “gap” (for gap statistics) or “fix” for a fixed number of
clusters (as set by <code>cluster_kfix</code>. The script always
calculates both the silhouette and the gap stastitics, but the default
method is the one applied for subsequent analyses.</li>
<li><strong>n_pca_min</strong>. This is the minimum number of valid
points for running a PCA (after imputation).</li>
</ul>
<pre class="r"><code># Run imputation and cluster analyses in test mode?
impute_cluster_test = c(FALSE,TRUE)[1L]

# Minimum number of numeric traits for keeping the entry for imputation. This avoids keeping plants for which we only have a few traits
n_row_numtrait_impute = 3L

# Minimum fraction of complete observations (relative to the most abundant numeric trait) for being considered in the imputation
f_col_trait_impute = 1./6.

# Minimum variability of the variable to be included in the imputation. Variability is sd(x)/mean(abs(x)) for numeric traits and
#    evenness for categorical traits (including ordered, integers, logical variables, and characters).
f_var_min_impute = 0.01

# Random seed for the imputation analysis (so results are reproducible)
rseed_impute = 6L

# Select the minimum and maximum number of clusters to consider.
cluster_kmin = 3L
cluster_kmax = 20L
cluster_kfix = 4L

# Minimum weight (first guess) below which the traits will be disregarded for cluster analysis
min_weight_cluster = 1./6.

# Random seed for the cluster analysis (so results are reproducible)
rseed_cluster = 12L

# Number of Monte Carlo iterations (for gap statistics standard error)
n_mcarlo_cluster = 100L

# Method for maximum gap statistics whilst accounting for standard error. See maxSE help for details.
method_gap_maxSE = c(&quot;firstSEmax&quot;,&quot;Tibs2001SEmax&quot;,&quot;globalSEmax&quot;,&quot;firstmax&quot;, &quot;globalmax&quot;)[5L]

# Method to be used for selecting the optimum number of clusters.
cluster_method = c(&quot;sil&quot;,&quot;gap&quot;,&quot;fix&quot;)[2L]

# Minimum number of valid points for running a PCA.
n_pca_min = 500L</code></pre>
<p>The following tibble object sets colours and shapes for categorical
traits that will be used for analysis. Only the classes included in this
list will be displayed. This tibble should contain the following
columns:</p>
<ul>
<li><strong>TraitID</strong>. The trait ID to which the categories
correspond to. This must be the same ID used by TRY. Additionally, you
should include two rows with TraitID set no <code>NA_integer_</code>.
These rows will have special settings for unknown classes and for the
global model.</li>
<li><strong>Class</strong>. This is the new simplified class for plots
and analyses. In case you want to direct multiple original classes to
fewer simplified classes, use the same name in this column multiple
times. For the special rows, set one of them to “UKN” and the other to
“ALL”, for entries that could not be classified and one for the full
model.</li>
<li><strong>TRYClass</strong>. The input class categories from TRY,
after the primary harmonisation by script TidyTraitAllomDB.Rmd.</li>
<li><strong>Colour</strong>. Colour to be used for this class. If
multiple <code>TRYClass</code> entries point to the same
<code>Class</code> for a given trait ID, only the first value of
<code>Colour</code> for that <code>Class</code> will be considered.</li>
<li><strong>Symbol</strong>. Symbol to be used for this class. If
multiple <code>TRYClass</code> entries point to the same
<code>Class</code> for a given trait ID, only the first value of
<code>Symbol</code> for that <code>Class</code> will be considered.</li>
<li><strong>XYUse</strong>. Which column to use for scatter plots.
Options are <code>"Colour"</code>, <code>"Symbol"</code>, or
<code>NA_character_</code>. Make sure the values are the same for all
rows belonging to the same TraitID, and that both <code>"Colour"</code>
and <code>"Symbol"</code> are not used for two or more traits.</li>
</ul>
<pre class="r"><code># Phenology information
CategInfo = tidyr::tribble( ~TraitID, ~Class, ~TRYClass                     ,   ~Colour, ~Symbol, ~XYUse       , ~Order
                          ,         22L,   &quot;C3&quot;, &quot;C3&quot;                       , &quot;#007E89&quot;,     17L, NA_character_, NA_integer_
                          ,         22L,   &quot;C4&quot;, &quot;C4&quot;                       , &quot;#FCA2AE&quot;,      5L, NA_character_, NA_integer_
                          ,         22L,  &quot;CAM&quot;, &quot;CAM&quot;                      , &quot;#B6899C&quot;,      8L, NA_character_, NA_integer_
                          ,         28L,  &quot;ZOO&quot;, &quot;Zoochory&quot;                 , &quot;#AED5E3&quot;,      9L, NA_character_, NA_integer_
                          ,         28L,  &quot;ZOO&quot;, &quot;Ornithochory&quot;             , &quot;#AED5E3&quot;,      9L, NA_character_, NA_integer_
                          ,         28L,  &quot;ZOO&quot;, &quot;Mammalochory&quot;             , &quot;#AED5E3&quot;,      9L, NA_character_, NA_integer_
                          ,         28L,  &quot;AUT&quot;, &quot;Autochory&quot;                , &quot;#FCA2AE&quot;,     13L, NA_character_, NA_integer_
                          ,         28L,  &quot;HYD&quot;, &quot;Hydrochory&quot;               , &quot;#008B96&quot;,     18L, NA_character_, NA_integer_
                          ,         28L,  &quot;ANE&quot;, &quot;Anemochory&quot;               , &quot;#E72521&quot;,     16L, NA_character_, NA_integer_
                          ,         37L,  &quot;EVG&quot;, &quot;Evergreen&quot;                , &quot;#008B96&quot;,     18L, &quot;Colour&quot;     , 1L
                          ,         37L,  &quot;BVD&quot;, &quot;Brevi-deciduous&quot;          , &quot;#AED5E3&quot;,     13L, &quot;Colour&quot;     , 2L
                          ,         37L,  &quot;SMD&quot;, &quot;Semi-deciduous&quot;           , &quot;#FDBF6F&quot;,      9L, &quot;Colour&quot;     , 3L
                          ,         37L,  &quot;DRD&quot;, &quot;Deciduous (not specified)&quot;, &quot;#E72521&quot;,     16L, &quot;Colour&quot;     , 4L
                          ,         38L,  &quot;NWD&quot;, &quot;Non-woody&quot;                , &quot;#008B96&quot;,     18L, NA_character_, 1L
                          ,         38L,  &quot;SWD&quot;, &quot;Semi-woody&quot;               , &quot;#7570B3&quot;,      9L, NA_character_, 2L
                          ,         38L,  &quot;WDY&quot;, &quot;Woody&quot;                    , &quot;#E72521&quot;,     16L, NA_character_, 3L
                          ,         42L,  &quot;HBG&quot;, &quot;Grass-Herb&quot;               , &quot;#E6AB02&quot;,      4L, &quot;Symbol&quot;     , NA_integer_
                          ,         42L,  &quot;LIA&quot;, &quot;Liana&quot;                    , &quot;#7570B3&quot;,     17L, &quot;Symbol&quot;     , NA_integer_
                          ,         42L,  &quot;PLM&quot;, &quot;Palm&quot;                     , &quot;#66A61E&quot;,     18L, &quot;Symbol&quot;     , NA_integer_
                          ,         42L,  &quot;SHB&quot;, &quot;Shrub&quot;                    , &quot;#D95F02&quot;,      8L, &quot;Symbol&quot;     , NA_integer_
                          ,         42L,  &quot;TRE&quot;, &quot;Tree&quot;                     , &quot;#1B9E77&quot;,     16L, &quot;Symbol&quot;     , NA_integer_
                          ,         42L,  &quot;VNE&quot;, &quot;Vine&quot;                     , &quot;#222222&quot;,     13L, &quot;Symbol&quot;     , NA_integer_
                          ,         42L,  &quot;XPH&quot;, &quot;Xerophyte&quot;                , &quot;#E7298A&quot;,      6L, &quot;Symbol&quot;     , NA_integer_
                          ,        197L,  &quot;BDT&quot;, &quot;Broadleaf Deciduous Tree&quot; , &quot;#1B9E77&quot;,     16L, NA_character_, NA_integer_
                          ,        197L,  &quot;BET&quot;, &quot;Broadleaf Evergreen Tree&quot; , &quot;#66C2A5&quot;,     10L, NA_character_, NA_integer_
                          ,        197L,  &quot;C3G&quot;, &quot;C3 Grass&quot;                 , &quot;#E6AB02&quot;,      3L, NA_character_, NA_integer_
                          ,        197L,  &quot;C4G&quot;, &quot;C4 Grass&quot;                 , &quot;#FC8D62&quot;,      4L, NA_character_, NA_integer_
                          ,        197L,  &quot;ESH&quot;, &quot;Evergreen Shrub&quot;          , &quot;#7570B3&quot;,      2L, NA_character_, NA_integer_
                          , NA_integer_,  &quot;UKN&quot;, &quot;Unknown&quot;                  , &quot;#AAAAAA&quot;,      0L, NA_character_, NA_integer_
                          , NA_integer_,  &quot;ALL&quot;, &quot;All data&quot;                 , &quot;#161616&quot;,     15L, NA_character_, NA_integer_
                          )#end tribble
CntCategInfo = nrow(CategInfo)</code></pre>
<p>Set up some flags to skip plotting sets of figures if they are not
needed</p>
<pre class="r"><code>plot_violin         = c(FALSE,TRUE)[1L] # Violin plots for different groups?
plot_abund_map      = c(FALSE,TRUE)[2L] # Maps with trait abundance?
plot_stat_cluster   = c(FALSE,TRUE)[2L] # Plot statistics for generating the optimal number of clusters?
plot_wgt_cluster    = c(FALSE,TRUE)[2L] # Plot weights for cluster analysis?
plot_pca_cluster    = c(FALSE,TRUE)[2L] # Plot PCA highlighting the clusters?
plot_radar_cluster  = c(FALSE,TRUE)[2L] # Plot radar diagrams of all traits by cluster?
plot_sma_trait      = c(FALSE,TRUE)[2L] # Plot SMA for photosynthesis traits?
plot_sma_photo      = c(FALSE,TRUE)[2L] # Plot SMA for photosynthesis traits?
plot_global_distrib = c(FALSE,TRUE)[2L] # Plot global trait distribution?
plot_categ_distrib  = c(FALSE,TRUE)[2L] # Plot trait distribution by category?
plot_categ_ridge    = c(FALSE,TRUE)[2L] # Plot trait distribution by category using ridge plots?</code></pre>
<p>General plot options for <code>ggplot</code></p>
<pre class="r"><code>gg_device        = c(&quot;pdf&quot;) # Output devices to use (Check ggsave for acceptable formats)
gg_depth         = 300      # Plot resolution (dpi)
gg_ptsz          = 24       # Font size
gg_width         = 9.0      # Plot width for non-map plots (units below)
gg_height        = 7.2      # Plot height for non-map plots (units below)
gg_units         = &quot;in&quot;     # Units for plot size
gg_screen        = TRUE     # Show plots on screen as well?
gg_tfmt          = &quot;%Y&quot;     # Format for time 
gg_ncolours      = 129      # Number of node colours for heat maps.
gg_fleg          = 1./6.    # Fraction of plotting area dedicated for legend
ndevice = length(gg_device)</code></pre>
<p>The following block defines some settings for the trait abundance
maps.</p>
<ul>
<li><strong>n_map_min</strong>. Minimum number of valid points to
consider for maps.</li>
<li><strong>n_map_bin</strong>. Number of bins for the count by location
(the more bins, the finer the resolution)</li>
<li><strong>map_trans</strong>. Transformation for the count. Most
traits tend to be highly clustered around a few places, and applying a
variable transformation may make sense. Any transformation typically
applicable to <code>ggplot</code> works. If no transformation is sought,
set <code>map_trans="identity"</code>.</li>
<li><strong>map_range</strong>. Range for the maps, in case a fixed
range is sought. This is a vector of 2 (minimum and maximum). If you
want to use the default values, set them to <code>NA_real_</code>. For
completely unbounded values, set both values to
<code>NA_real_</code>.</li>
</ul>
<pre class="r"><code>n_map_min  = 30L           # Minimum number of points for maps.
n_map_bin  = 30L           # Number of map bins
map_trans  = &quot;log10&quot;       # Transformation for the bin count
map_colour = &quot;viridis&quot;     # Colour palette, it must be compatible with scale_fill_continuous
map_range  = c(10L,10000L) # Fixed ranged for map counts (Vector with minimum and maximum). For unbounded counts, set minimum, maximum or both to NA_real_</code></pre>
<!-- =================================================================================== -->
<!-- =================================================================================== -->
<!-- =================================================================================== -->
<!-- =================================================================================== -->
<!-- =================================================================================== -->
<!--                                                                                     -->
<!--               CHANGES BEYOND THIS POINT ARE ONLY FOR CODE DEVELOPMENT               -->
<!--                                                                                     -->
<!-- =================================================================================== -->
<!-- =================================================================================== -->
<!-- =================================================================================== -->
<!-- =================================================================================== -->
<!-- =================================================================================== -->
</div>
<div id="main-script" class="section level1">
<h1>Main script</h1>
<p><strong>Note:</strong> Code changes beyond this point are only needed
if you are developing the notebook.</p>
<div id="initial-settings." class="section level2">
<h2>Initial settings.</h2>
<p>First, we load the list of host land model variables that we may
consider for the comparison.</p>
<pre class="r"><code>source(file.path(util_path,&quot;load.everything.r&quot;),chdir=TRUE)</code></pre>
<p>Load all countries and Brazilian states to include in the plot.</p>
<pre class="r"><code># Load countries and Brazilian states
all_countries = sf::st_as_sf(maps::map(&quot;world2&quot;,plot=FALSE,fill=TRUE,wrap=c(-180,180)))
br_states     = sf::st_as_sf(st_read(br_state_shp))</code></pre>
<p>Load the harmonised trait data set, stored in file
<code>rdata_TidyTRY</code>. This is the output of script
<code>TidyTraitAllomDB.Rmd</code> so make sure to run that
pre-processing first.</p>
<pre class="r"><code># Set subset of TRY entries.
use_suffix   = paste(use_realm,use_lifeclass         ,sep=&quot;_&quot;)

# File name with the tidy data set of individual trait observations.
rdata_TidyTRY = file.path(rdata_path,paste0(&quot;TidyTRY_&quot; ,use_suffix,&quot;.RData&quot;)) 

# Check that the file exists and load it.
if (file.exists(rdata_TidyTRY)){
   # Load data.
   cat0(&quot; + Load data from file: &quot;,basename(rdata_TidyTRY),&quot;.&quot;)
   dummy = load(rdata_TidyTRY)
}else{
   # File not found, stop the script
   cat0(&quot; + File &quot;,basename(rdata_TidyTRY),&quot; not found!&quot;)
   cat0(&quot;   This script requires pre-processing and subsetting TRY observations.&quot;)
   cat0(&quot; - Run script \&quot;TidyTraitAllomDB.Rmd\&quot; before running this script, and set: &quot;)
   cat0(&quot;      use_realm     = \&quot;&quot;,use_realm    ,&quot;\&quot;&quot;)
   cat0(&quot;      use_lifeclass = \&quot;&quot;,use_lifeclass,&quot;\&quot;&quot;)
   cat0(&quot;   in the TidyTRY preamble.&quot;)
   stop(&quot; RData object not found.&quot;)
}#end if (file.exists(rdata_TidyTRY))</code></pre>
<p>Define which variables are used for the X axis</p>
<pre class="r"><code>#    Find the local trait name consistent with the TidyTRY object. For most traits, we use 
# the trait ID, however for leaf texture and xylem loss of conductivity, we use the names
# because the same ID is split into multiple variables.
if (xsma_TraitID %in% c(2L,719L,3479L)){
   xsma_idx   = match(names(xsma_TraitID),try_trait$Name)
}else{
   xsma_idx   = match(xsma_TraitID,try_trait$TraitID)
}#end if (xsma_TraitID %in% c(2L,719L,3479L))
xphoto_idx = match(xphoto_TraitID,try_trait$TraitID)

# Make sure the indices are valid
if (any(is.na(c(xsma_idx,xphoto_idx)))){
   cat0(&quot; + Invalid settings for trait indices for SMA models&quot;)
   cat0(&quot;   xsma_TraitID exists in \&quot;try_trait\&quot;   = &quot;,! is.na(xsma_TraitID  ))
   cat0(&quot;   xphoto_TraitID exists in \&quot;try_trait\&quot; = &quot;,! is.na(xphoto_TraitID))
   stop(&quot; + Make sure \&quot;xsma_TraitID\&quot; and \&quot;xphoto_TraitID\&quot; are valid Trait IDs.&quot;)   
}else if (! all(c(try_trait$SMA[xsma_idx],try_trait$Photo[xphoto_idx]))){
   cat0(&quot; + Invalid settings for trait indices for SMA models&quot;)
   cat0(&quot;   Valid xsma_TraitID is a SMA variable     = &quot;, try_trait$SMA  [xsma_idx  ])
   cat0(&quot;   Valid xphoto_TraitID is a Photo variable = &quot;, try_trait$Photo[xphoto_idx])
   stop(&quot; + Make sure \&quot;xsma_TraitID\&quot; and \&quot;xphoto_TraitID\&quot; are valid Trait IDs.&quot;)  
}else{
   # Set the names for SMA and Photosynthesis tests.
   xsma_name   = try_trait$Name[xsma_idx]
   xphoto_name = try_trait$Name[xphoto_idx]
}#end if (any(is.na(c(xsma_idx,xphoto_idx))))</code></pre>
<p>Define files and paths for input and output. We also create the
output paths.</p>
<pre class="r"><code># Build suffix for model fittings.
base_suffix    = paste(use_suffix ,fit_taxon  ,sep=&quot;_&quot;)
trait_suffix   = paste(base_suffix,xsma_name  ,sep=&quot;_&quot;)
photo_suffix   = paste(base_suffix,xphoto_name,sep=&quot;_&quot;)

# Build RData object file names for the imputed data, cluster analysis, the standardised major axis 
# models using a reference trait and across photosynthesis parameters, and the fitted distributions.
rdata_impute      = file.path(rdata_path,paste0(&quot;Imputed_&quot;    ,base_suffix ,&quot;.RData&quot;))
rdata_cluster     = file.path(rdata_path,paste0(&quot;Cluster_&quot;    ,base_suffix ,&quot;.RData&quot;))
rdata_TidyCluster = file.path(rdata_path,paste0(&quot;TidyCluster_&quot;,base_suffix ,&quot;.RData&quot;))
rdata_SMA_trait   = file.path(rdata_path,paste0(&quot;SMA_Trait_&quot;  ,trait_suffix,&quot;.RData&quot;)) 
rdata_SMA_photo   = file.path(rdata_path,paste0(&quot;SMA_Photo_&quot;  ,photo_suffix,&quot;.RData&quot;))
rdata_corr_trait  = file.path(rdata_path,paste0(&quot;Corr_Trait_&quot; ,base_suffix ,&quot;.RData&quot;))
rdata_distr       = file.path(rdata_path,paste0(&quot;Distr_Trait_&quot;,base_suffix ,&quot;.RData&quot;))

# Build file name for summaries by genus and species, and summary distribution.
species_summ    = file.path(summ_path,paste0(&quot;TRY_SpeciesSumm_&quot;   ,use_suffix  ,&quot;.csv&quot;))
genus_summ      = file.path(summ_path,paste0(&quot;TRY_GenusSumm_&quot;     ,use_suffix  ,&quot;.csv&quot;))
distr_summ      = file.path(summ_path,paste0(&quot;TRY_InfoDistr_&quot;     ,base_suffix ,&quot;.csv&quot;))
SMA_summ        = file.path(summ_path,paste0(&quot;TRY_InfoSMA_&quot;       ,trait_suffix,&quot;.csv&quot;))
SMAPhoto_summ   = file.path(summ_path,paste0(&quot;TRY_InfoSMA_&quot;       ,photo_suffix,&quot;.csv&quot;))
corr_summ       = file.path(summ_path,paste0(&quot;TRY_InfoCorr_&quot;      ,base_suffix ,&quot;.csv&quot;))
cluster_medoid  = file.path(summ_path,paste0(&quot;TRY_ClusterMedoid_&quot; ,base_suffix ,&quot;.csv&quot;))
cluster_medians = file.path(summ_path,paste0(&quot;TRY_ClusterMedians_&quot;,base_suffix ,&quot;.csv&quot;))


# Build output directory for trait, allometry, and photosynthesis fits.
violin_path  = file.path(plot_path,paste0(&quot;Trait_&quot;,base_suffix ),&quot;ViolinPlot&quot;)
abund_path   = file.path(plot_path,paste0(&quot;Trait_&quot;,base_suffix ),&quot;AbundMap&quot;  )
trsma_path   = file.path(plot_path,paste0(&quot;Trait_&quot;,trait_suffix),&quot;SMAPlot&quot;   )
trdist_path  = file.path(plot_path,paste0(&quot;Trait_&quot;,base_suffix ),&quot;DistrPlot&quot; )
trridge_path = file.path(plot_path,paste0(&quot;Trait_&quot;,base_suffix ),&quot;RidgePlot&quot; )
trpca_path   = file.path(plot_path,paste0(&quot;Trait_&quot;,base_suffix ),&quot;PCAPlot&quot;   )
photo_path   = file.path(plot_path,paste0(&quot;Photo_&quot;,photo_suffix),&quot;SMAPlot&quot;   )

# Make sure directories are set.
dummy = dir.create(path=summ_path      ,showWarnings=FALSE,recursive=TRUE)
dummy = dir.create(path=violin_path    ,showWarnings=FALSE,recursive=TRUE)
dummy = dir.create(path=abund_path     ,showWarnings=FALSE,recursive=TRUE)
dummy = dir.create(path=trsma_path     ,showWarnings=FALSE,recursive=TRUE)
dummy = dir.create(path=trdist_path    ,showWarnings=FALSE,recursive=TRUE)
dummy = dir.create(path=trridge_path   ,showWarnings=FALSE,recursive=TRUE)
dummy = dir.create(path=trpca_path     ,showWarnings=FALSE,recursive=TRUE)
dummy = dir.create(path=photo_path     ,showWarnings=FALSE,recursive=TRUE)</code></pre>
<p>Define the labels for titles:</p>
<pre class="r"><code># Label for life-form/phylogenetic level
LabelLife = switch( use_lifeclass
                  , FlowerTrees  = &quot;flowering trees&quot;
                  , Shrubs       = &quot;shrubs&quot;
                  , Grasses      = &quot;grasses&quot;
                  , FlowerPlants = &quot;flowering plants&quot;
                  , Pinopsida    = &quot;conifers&quot;
                  , SeedPlants   = &quot;seed plants&quot;
                  , Plantae      = &quot;plants&quot;
                  , stop(&quot;Unrecognised life-form/phylogenetic level.&quot;)
                  )#end switch

# Label for floristic realm
LabelRealm = switch( use_realm
                   , NeoTropical = &quot;Neotropical&quot;
                   , PanTropical = &quot;Pantropical&quot;
                   , stop(&quot;Unrecognised realm.&quot;)
                   )#end switch

# Label for taxonomic level of aggregation
LabelTaxon = switch( fit_taxon
                   , Individual = &quot;individual observations&quot;
                   , Species    = &quot;species averages&quot;
                   , Genus      = &quot;genus averages&quot;
                   , stop(&quot;Unrecognised realm.&quot;)
                   )#end switch

# Build sub-title
LabelSubtitle = paste0(LabelRealm,&quot; &quot;,LabelLife,&quot;: &quot;,LabelTaxon)</code></pre>
<p>Find confidence quantiles based on the confidence range.</p>
<pre class="r"><code># Find lower and upper confidence bands
SMA_ConfLwr = 0.5 - 0.5 * SMA_ConfInt
SMA_ConfUpr = 0.5 + 0.5 * SMA_ConfInt

# Find the significance level to consider SMA fits significant
SMA_Alpha = 1. - SMA_ConfInt</code></pre>
<p>For some plots, we use a square image so it looks nicer. Define the
size as the average between height and width.</p>
<pre class="r"><code># Find size for square plots
gg_square = sqrt(gg_width*gg_height)</code></pre>
<p>Here we decide whether or not to eliminate traits that are known to
be highly photo-plastic and may have not been collected from sunny
leaves. If filtering, we use the following logic:</p>
<ul>
<li>If the measurement came from open-canopy biomes or anthromes and the
sun/shade condition is not provided, we assume measurements are from sun
leaves.</li>
<li>If the measurement came from closed-canopy biomes and the sun/shade
condition is not provided, we assume measurements are from shade
leaves.</li>
<li>If the measurement sun/shade condition is provided and is
<code>03 - Mostly Sun-Exposed</code> or assumed from sun leaves, then
the measurement is kept.</li>
<li>If the growth form is shrub and the biome is from closed-canopy
biomes, we retain the measurements as these plants are likely under
storey specialists, unlikely to be ever sun exposed.</li>
</ul>
<pre class="r"><code># Remove trait values from shaded individuals in case this is a sun trait.
if (plastic_sun_only){
   cat0(&quot;   - Remove trait information for shaded leaves (when trait has light plasticity).&quot;)
   PlasticTraits = names(TidyTRY)[names(TidyTRY) %in% try_trait$Name[try_trait$LightPlastic]]
   SunShade      = try_ancil$Name[try_ancil$DataID  %in% c( 210L, 443L, 766L,2111L)]
   Biome         = try_ancil$Name[try_ancil$DataID  %in% c( 193L, 202L)            ]
   GrowthForm    = try_trait$Name[try_trait$TraitID %in% c(  42L)                  ]
   Raunkiaer     = try_trait$Name[try_trait$TraitID %in% c( 343L)                  ]

   EmptyChar     = rep(NA_character_,nrow(TidyTRY))
   if(length(SunShade  ) == 0L){SunShade   = EmptyChar}else{SunShade   = TidyTRY[[SunShade  ]]}
   if(length(Biome     ) == 0L){Biome      = EmptyChar}else{Biome      = TidyTRY[[Biome     ]]}
   if(length(GrowthForm) == 0L){GrowthForm = EmptyChar}else{GrowthForm = TidyTRY[[GrowthForm]]}
   if(length(Raunkiaer ) == 0L){Raunkiaer  = EmptyChar}else{Raunkiaer  = TidyTRY[[Raunkiaer ]]}

   # Save logical variables that will help setting conditions for keeping/discarding data.
   IsSun    = SunShade %in% &quot;03 - Mostly Sun-Exposed&quot;
   IsShade  = SunShade %in% c(&quot;01 - Mostly Shaded&quot;,&quot;02 - Partially Shaded&quot;)
   IsOpen   = ( grepl(pattern=&quot;Desert&quot;   ,x=Biome)
              | grepl(pattern=&quot;Grassland&quot;,x=Biome)
              | grepl(pattern=&quot;Scrubland&quot;,x=Biome)
              | grepl(pattern=&quot;Savannah&quot; ,x=Biome)
              | grepl(pattern=&quot;Tundra&quot;   ,x=Biome)
              | grepl(pattern=&quot;Pastures&quot; ,x=Biome)
              )#end IsOpen
   IsClosed = grepl(pattern=&quot;Moist Forest&quot;,x=Biome)
   IsShrub  = ( ( GrowthForm %in% c(&quot;SHB&quot;,&quot;Shrub&quot;) )
              | ( Raunkiaer  %in% c(&quot;Microphanerophyte&quot;,&quot;Nanophanerophyte&quot;) )
              )#end IsShrub

   # Filter photo-plastic traits
   for (w in seq_along(PlasticTraits)){
      # Select trait
      PlasticNow            = PlasticTraits[w]
      
      # Remove observations that are not (presumably) from sun leaves.
      Keep                  = IsSun | ( IsOpen &amp; (! IsShade) ) | ( IsClosed &amp; IsShrub )
      TidyTRY[[PlasticNow]] = ifelse(test=Keep,yes=TidyTRY[[PlasticNow]],no=NA)
   }#end for (w in PlasticTraits)
}#end if (plastic_sun_only)</code></pre>
<p>Here we decide whether or not to keep entries from treatments (and if
so, which levels are still acceptable). Note that this filter is only
applied to numerical traits, categorical and ordered traits may still be
kept.</p>
<pre class="r"><code># Add dummy value that is not valid in case treatment level options is empty.
if (length(use_treat_level) == 0L){UseTreatLevel = -1L}else{UseTreatLevel=use_treat_level}

# Remove trait values from treatments that are considered too artificial.
if (! all(is.na(use_treat_level))){
   cat0(&quot;   - Keep only natural data and data from allowed treatments.&quot;)

   # Find variable with treatment information
   TreatmentID = c(238L, 308L, 319L, 324L, 363L, 490L, 4052L, 4695L)
   Treatment   = try_ancil$Name[try_ancil$DataID %in% TreatmentID]
   EmptyChar   = rep(NA_character_,nrow(TidyTRY))
   if(length(Treatment) == 0L){TreatValue = EmptyChar}else{TreatValue = TidyTRY[[Treatment]]}

   # Decide whether or not to keep the levels of each entry.
   TreatLevel  = as.integer(gsub(pattern=&quot;\\ .*&quot;,replacement=&quot;&quot;,x=TreatValue))
   KeepLevel   = is.na(TreatValue) | ( TreatLevel %in% UseTreatLevel)

   # List numeric traits for removal.      
   IsNumeric     = try_trait$Type %in% &quot;numeric&quot;
   NumericTraits = names(TidyTRY)[names(TidyTRY) %in% try_trait$Name[IsNumeric]]

   # Loop through the numerical traits and delete information.   
   for (w in seq_along(NumericTraits)){
      # Select trait
      NumericNow            = NumericTraits[w]
      TidyTRY[[NumericNow]] = ifelse(test=KeepLevel,yes=TidyTRY[[NumericNow]],no=NA)
   }#end for (w in PlasticTraits)
}#end if (! any(is.na(use_treat_level)))</code></pre>
<p>Here we decide whether or not to eliminate entries from plants that
are unlikely to be woody (sensu latu)</p>
<pre class="r"><code># Remove trait values from shaded individuals in case this is a sun trait.
if (! use_woody_level %in% &quot;all_plants&quot;){
   cat0(&quot;   - Remove trait information for individuals that are non-woody.&quot;)
   Woodiness     = try_trait$Name[try_trait$TraitID %in% 38L]
   GrowthForm    = try_trait$Name[try_trait$TraitID %in% 42L]
   WoodDens      = try_trait$Name[try_trait$TraitID %in%  4L]
   AnyWoodiness  = length(Woodiness ) &gt; 0L
   AnyGrowthForm = length(GrowthForm) &gt; 0L
   AnyWoodDens   = length(WoodDens  ) &gt; 0L
   AllTrue       = rep(TRUE,times=nrow(TidyTRY))

   WoodyLevels  = switch( EXPR          = use_woody_level
                        , tree_only     = c(&quot;WDY&quot;,&quot;Woody&quot;)
                        , woody_ss_free = c(&quot;WDY&quot;,&quot;Woody&quot;)
                        , woody_ss_all  = c(&quot;WDY&quot;,&quot;Woody&quot;)
                        , woody_sl_free = c(&quot;WDY&quot;,&quot;Woody&quot;,&quot;SWD&quot;,&quot;Semi-woody&quot;)
                        , woody_sl_all  = c(&quot;WDY&quot;,&quot;Woody&quot;,&quot;SWD&quot;,&quot;Semi-woody&quot;)
                        )#end switch
   GrowthLevels = switch( EXPR          = use_woody_level
                        , tree_only     = &quot;Tree&quot;
                        , woody_ss_free = c(&quot;Tree&quot;,&quot;Shrub&quot;)
                        , woody_ss_all  = c(&quot;Hemiepiphyte&quot;,&quot;Liana&quot;,&quot;Shrub&quot;,&quot;Tree&quot;)
                        , woody_sl_free = c(&quot;Palm&quot;,&quot;Shrub&quot;,&quot;Tree&quot;)
                        , woody_sl_all  = c(&quot;Hemiepiphyte&quot;,&quot;Liana&quot;,&quot;Palm&quot;,&quot;Shrub&quot;,&quot;Tree&quot;)
                        )#end switch
   ClassLevels  = switch( EXPR           = use_woody_level
                        , tree_only      = c(&quot;Magnoliopsida&quot;)
                        , woody_ss_free  = c(&quot;Magnoliopsida&quot;)
                        , woody_ss_all   = c(&quot;Magnoliopsida&quot;)
                        , woody_sl_free  = c(&quot;Magnoliopsida&quot;,&quot;Liliopsida&quot;)
                        , woody_sl_all   = c(&quot;Magnoliopsida&quot;,&quot;Liliopsida&quot;)
                        )#end switch

   IsWoodiness   = if(AnyWoodiness ){TidyTRY[[Woodiness ]] %in% WoodyLevels }else{AllTrue}
   IsGrowth      = if(AnyGrowthForm){TidyTRY[[GrowthForm]] %in% GrowthLevels}else{! AllTrue}
   FineWoodDens  = if(AnyWoodDens  ){is.finite(TidyTRY[[WoodDens]])}else{! AllTrue}
   KeepClass     = TidyTRY$Class %in% ClassLevels
   MissWoodiness = if(AnyWoodiness ){is.na(TidyTRY[[Woodiness ]])}else{AllTrue}
   MissGrowth    = if(AnyGrowthForm){is.na(TidyTRY[[GrowthForm]])}else{AllTrue}
   AssumeWoody   = MissWoodiness &amp; MissGrowth &amp; FineWoodDens 
   
   KeepWoody     = IsWoodiness &amp; ( IsGrowth | AssumeWoody ) 
   TidyTRY       = TidyTRY[KeepClass &amp; KeepWoody,,drop=FALSE]
}#end if (plastic_sun_only)</code></pre>
</div>
<div id="simplify-categories-for-a-few-traits" class="section level2">
<h2>Simplify categories for a few traits</h2>
<p>For some categorical traits, we further simplify the categories to
reduce dimensionality and mitigate the variability in definition of some
categories across authors. We also check whether or not to turn some of
the categorical variables into ordered variables.</p>
<pre class="r"><code># List of traits considered categorical (the list may need updates/expansion.)
CategTraitID    = sort(unique(CategInfo$TraitID))
CategTraitID    = CategTraitID[CategTraitID %in% try_trait$TraitID]
CntCategList    = length(CategTraitID)

# Loop through categorical traits and assign all individuals from the same species to the commonest class
for (w in sequence(CntCategList)){
   # Select categorical trait
   TraitIDNow = CategTraitID[w]
   z          = match(TraitIDNow,try_trait$TraitID)
      
   # This should not happen...
   if (! is.finite(z)) stop(paste0(&quot; Unrecognised Trait ID: &quot;,TraitIDNow,&quot;.&quot;))
   
   # Handy aliases
   NameNow       = try_trait$Name      [z]
   DescNow       = try_trait$Desc      [z]
   cat0(&quot; + Simplify categorical trait: &quot;,DescNow,&quot; (&quot;,NameNow,&quot;).&quot;)

   # Select only the lines that are associated with this trait
   InfoNow   = CategInfo %&gt;% filter(TraitID %in% TraitIDNow)

   # Map values to the new categories and discard data not associated with any category of interest
   Index              = match(TidyTRY[[NameNow]],InfoNow$TRYClass)
   Fine               = ! is.na(Index)
   TidyTRY[[NameNow]] = ifelse( test = Fine, yes = InfoNow$Class[Index], no = NA_character_)

   # If order has been provided for all categories, we turn the variable into ordered.
   if (all(! is.na(InfoNow$Order))){
      UseOrder           = order(InfoNow$Order)
      UseLevels          = unique(InfoNow$Class[UseOrder])
      TidyTRY[[NameNow]] = ordered(x=TidyTRY[[NameNow]],levels=UseLevels)
   }#end if (all(is.finite(InfoNow$Order)))
}#end for (z in sequence(CntCategList))</code></pre>
</div>
<div id="aggregate-data-by-species-and-genus" class="section level2">
<h2>Aggregate data by species and genus</h2>
<p>Here we summarise data by species and genus, and create csv files
with the summaries. We remove most ancillary variables as they are more
related to observations than species.</p>
<p>The aggregation is carried out differently depending on whether the
trait is numeric or categorical:</p>
<ul>
<li><strong>Numerical traits</strong>. We weight observations by the
number of counts, to ensure data reported as averages based on many
individuals have a higher leverage in the species/genus averages.</li>
<li><strong>Categorical traits</strong>. We only allow one input for
each species and each author. This is an imperfect solution to avoid
giving too much leverage for an author that contributed with single
observations of multiple individuals of the same species for things like
leaf phenology or growth form (which are typically based on observing
species behaviour as a whole).</li>
</ul>
<pre class="r"><code># Load some files which will likely be updated as the code is developed.
source(file.path(util_path,&quot;numutils.r&quot;),chdir=TRUE)

# Summarise data sets by species
cat0(&quot; + Find traits by species and genus:&quot;)
# List of variables to keep after merging
Lon        = try_ancil$Name[try_ancil$DataID %in% c(60L,4705L,4707L)     ]
Lat        = try_ancil$Name[try_ancil$DataID %in% c(59L,4704L,4706L)     ]
Alt        = try_ancil$Name[try_ancil$DataID %in% c(61L)                 ]
Country    = try_ancil$Name[try_ancil$DataID %in% c(1412L)               ]
Continent  = try_ancil$Name[try_ancil$DataID %in% c(1413L)               ]
Biome      = try_ancil$Name[try_ancil$DataID %in% c(193L,202L)           ]
SunShade   = try_ancil$Name[try_ancil$DataID %in% c(210L,443L,766L,2111L)]
TraitKeep  = try_trait$Name[! try_trait$Allom]
AncilKeep  = try_ancil$Name[try_ancil$Impute | try_ancil$Cluster]
VarKeep    = c(&quot;Author&quot;,&quot;ScientificName&quot;,&quot;Genus&quot;,&quot;Family&quot;,&quot;Order&quot;,&quot;Class&quot;,&quot;Phylum&quot;
              ,Lon,Lat,Alt,Country,Continent,TraitKeep,Biome,SunShade,AncilKeep)
VarKeep    = VarKeep[! duplicated(VarKeep)]

# Define some functions that will help handling duplicates and invalid numbers without changing the variable type.
ignoreDuplicates = function(x){ans=x; ans[duplicated(ans)] = NA; return(ans)}
replaceNaN       = function(x){ans=x; ans[is.nan    (ans)] = NA; return(ans)}


# When we aggregate data by species, we use a different approach depending
SpeciesTRY = TidyTRY %&gt;%
   filter( (! Genus %in% &quot;Ignotum&quot;) &amp; (! grepl(pattern=&quot;[0-9]&quot;,x=ScientificName)))                         %&gt;%
   group_by(Author,ScientificName)                                                                         %&gt;%
   mutate( across( where(is.ordered) | where(is.factor) | where(is.character), ~ ignoreDuplicates(x=.x)))  %&gt;%
   ungroup()                                                                                               %&gt;%
   mutate( ScientificName = factor(ScientificName,levels=sort(unique(ScientificName))))                    %&gt;%
   group_by(ScientificName)                                                                                %&gt;%
   summarise( across(where(is.double ) &amp; ! Count, ~ weighted.mean (x=as.numeric(.x),w=Count,na.rm=TRUE))
            , across(where(is.integer)          , ~ weightedMedian(x=.x            ,w=Count,na.rm=TRUE))
            , across(where(is.ordered)          , ~ orderedMedian (x=.x                    ,na.rm=TRUE))
            , across(where(is.factor )          , ~ commonest     (x=.x                    ,na.rm=TRUE))
            , across(where(is.logical)          , ~ commonest     (x=.x                    ,na.rm=TRUE))
            , across(where(is.Date)             , ~ commonest     (x=.x                    ,na.rm=TRUE))
            , across(where(is.character)        , ~ commonest     (x=.x                    ,na.rm=TRUE))) %&gt;%
   ungroup()                                                                                               %&gt;%
   mutate( ScientificName = as.character(ScientificName))                                                  %&gt;%
   mutate( across( everything(), ~replaceNaN(x=.x) ) )                                                     %&gt;%
   mutate( across( where(is.double), ~ signif(.x,digits=4L) ) )                                            %&gt;%
   select_at(vars(VarKeep))                                                                                %&gt;%
   arrange(Family,Genus,ScientificName)                                                                    %&gt;%
   select(! Author)


# Summarise data sets by genus
cat0(&quot; + Find traits by genus:&quot;)
GenusTRY = TidyTRY                                                                                         %&gt;%
   filter( (! grepl(pattern=&quot;^Ignotum&quot;,x=Genus) ) )                                                        %&gt;%
   group_by(Author,ScientificName)                                                                         %&gt;%
   mutate( across( where(is.ordered) | where(is.factor) | where(is.character), ~ ignoreDuplicates(x=.x)))  %&gt;%
   ungroup()                                                                                               %&gt;%
   group_by(ScientificName)                                                                                %&gt;%
   mutate( Genus = factor(Genus,levels=sort(unique(Genus))))                                               %&gt;%
   group_by(Genus)                                                                                         %&gt;%
   summarise( across(where(is.double ) &amp; ! Count, ~ weighted.mean (x=as.numeric(.x),w=Count,na.rm=TRUE))
            , across(where(is.integer)          , ~ weightedMedian(x=.x            ,w=Count,na.rm=TRUE))
            , across(where(is.ordered)          , ~ orderedMedian (x=.x                    ,na.rm=TRUE))
            , across(where(is.factor )          , ~ commonest     (x=.x                    ,na.rm=TRUE))
            , across(where(is.logical)          , ~ commonest     (x=.x                    ,na.rm=TRUE))
            , across(where(is.Date)             , ~ commonest     (x=.x                    ,na.rm=TRUE))
            , across(where(is.character)        , ~ commonest     (x=.x                    ,na.rm=TRUE)))  %&gt;%
   ungroup()                                                                                               %&gt;%
   mutate( Genus = as.character(Genus))                                                                    %&gt;%
   mutate( across( everything(), ~replaceNaN(x=.x) ) )                                                     %&gt;%
   mutate( across( where(is.double), ~ signif(.x,digits=4L) ) )                                            %&gt;%
   select_at(vars(VarKeep))                                                                                %&gt;%
   arrange(Family,Genus)                                                                                   %&gt;%
   select(! c(ScientificName))</code></pre>
</div>
<div id="fill-categorical-information-based-on-species"
class="section level2">
<h2>Fill categorical information based on species</h2>
<p>For traits and ancillary variables that should be treated as
categorical or intrinsic species characteristics, we fill in all
observations with the commonest value for any species. This will help
distinguishing data points, for example, between evergreen and
deciduous. Just to be very cautious, we run this step after aggregating
by species to avoid any influence on which categories are assigned to
species.</p>
<pre class="r"><code># List of traits considered categorical (the list may need updates/expansion.)
CategTraitID    = sort(unique(CategInfo$TraitID))
CategTraitID    = CategTraitID[CategTraitID %in% try_trait$TraitID]
CntCategList    = length(CategTraitID)

# Loop through categorical traits and assign all individuals from the same species to the commonest class
for (w in sequence(CntCategList)){
   # Select categorical trait
   TraitIDNow = CategTraitID[w]
   z          = match(TraitIDNow,try_trait$TraitID)
      
   # This should not happen...
   if (! is.finite(z)) stop(paste0(&quot; Unrecognised Trait ID: &quot;,TraitIDNow,&quot;.&quot;))
   
   # Handy aliases
   NameNow       = try_trait$Name      [z]
   DescNow       = try_trait$Desc      [z]
   cat0(&quot; + Harmonise categorical trait for all individuals of the same species: &quot;,DescNow,&quot; (&quot;,NameNow,&quot;).&quot;)

   # Create a look-up table for the 
   CategLUT = TidyTRY %&gt;%
      select_at( vars(c(&quot;ScientificName&quot;,NameNow))) %&gt;%
      mutate(ScientificName = factor(ScientificName,levels=sort(unique(ScientificName)))) %&gt;%
      group_by(ScientificName) %&gt;%
      summarise_at(vars(NameNow), ~ commonest(.x,na.rm=TRUE)) %&gt;%
      ungroup %&gt;%
      arrange(ScientificName)

   # Map actual data onto the look up table
   Index                    = match(TidyTRY$ScientificName,CategLUT$ScientificName)
   Miss                     = is.na(TidyTRY[[NameNow]])
   TidyTRY[[NameNow]][Miss] = CategLUT[[NameNow]][Index[Miss]]
}#end for (z in sequence(CntCategList))</code></pre>
</div>
</div>
<div id="global-trait-distribution" class="section level1">
<h1>Global trait distribution</h1>
<p>Here we fit distributions for each trait. We test multiple
distributions and pick the one that yields the lowest. We don’t save
this distribution in an R object because we will fit the distribution by
category after the cluster analysis.</p>
<pre class="r"><code># Load some files which will likely be updated as the code is developed.
source(file.path(util_path,&quot;FindBestDistr.r&quot;),chdir=TRUE)

# Select reference data set for trade-off analysis
DataTRY = switch( EXPR       = fit_taxon
                , Individual = TidyTRY
                , Species    = SpeciesTRY
                , Genus      = GenusTRY
                , stop(&quot;Invalid settings for variable \&quot;fit_taxon\&quot;.&quot;)
                )#end switch
   
# Find out how many traits we will seek to fit a distribution
cat0(&quot; + Fit trait distribution&quot;)
xTraitDistr   = with(try_trait, which( (Type %in% &quot;numeric&quot;) &amp; (! Allom)          ) )
xAncilDistr   = with(try_ancil, which( (Type %in% &quot;numeric&quot;) &amp; (Impute | Cluster) ) )
CntTraitDistr = length(xTraitDistr)
CntAncilDistr = length(xAncilDistr)
CntDistr      = CntTraitDistr + CntAncilDistr 
   

# Save objects for distribution plots:
# GlobDistr is the tibble with the coefficients and goodness-of-fit metrics
GlobDistr  = tibble( x          = c(try_trait$Name[xTraitDistr],try_ancil$Name[xAncilDistr])
                   , xLwr       = rep(NA_real_     ,times=CntDistr)
                   , xUpr       = rep(NA_real_     ,times=CntDistr)
                   , Class      = rep(&quot;ALL&quot;        ,times=CntDistr)
                   , TraitClass = rep(&quot;All&quot;        ,times=CntDistr)
                   , N          = rep(0L           ,times=CntDistr)
                   , Distrib    = rep(NA_character_,times=CntDistr)
                   , First      = rep(NA_real_     ,times=CntDistr)
                   , SE_First   = rep(NA_real_     ,times=CntDistr)
                   , Second     = rep(NA_real_     ,times=CntDistr)
                   , SE_Second  = rep(NA_real_     ,times=CntDistr)
                   , Third      = rep(NA_real_     ,times=CntDistr)
                   , SE_Third   = rep(NA_real_     ,times=CntDistr)
                   , Mean       = rep(NA_real_     ,times=CntDistr)
                   , StdDev     = rep(NA_real_     ,times=CntDistr)
                   , Skewness   = rep(NA_real_     ,times=CntDistr)
                   , Kurtosis   = rep(NA_real_     ,times=CntDistr)
                   , Median     = rep(NA_real_     ,times=CntDistr)
                   , LogLik     = rep(NA_real_     ,times=CntDistr)
                   , AIC        = rep(NA_real_     ,times=CntDistr)
                   , BIC        = rep(NA_real_     ,times=CntDistr)
                   )#end c


# Loop through the trait variables we will fit distributions
for (x in sequence(CntDistr)){
   # Load settings for the y axis.
   if (x &lt;= CntTraitDistr){
      xIndex   = xTraitDistr[x]
      xName    = try_trait$Name   [xIndex]
      xDesc    = try_trait$Desc   [xIndex]
   }else{
      xIndex   = xAncilDistr[x-CntTraitDistr]
      xName    = try_ancil$Name   [xIndex]
      xDesc    = try_ancil$Desc   [xIndex]
   }#end if (x &lt;= CntTraitDistr)
   cat0(&quot; + Fit the best distribution model for &quot;,xDesc,&quot;.&quot;)

   # Select valid points 
   xSel = is.finite(DataTRY[[xName]])

   # Select univariate data
   if (sum(xSel) &gt; 0L){
      xData  = DataTRY[[xName]][xSel]
      suppressWarnings({xDistr = FindBestDistr(x=xData,nx_min=n_fit_min,verbose=FALSE)})
            
      # Copy summary information to the data table
      xNow = which(GlobDistr$x %in% xName  )
      GlobDistr$xLwr     [xNow] = xDistr$xLwr
      GlobDistr$xUpr     [xNow] = xDistr$xUpr
      GlobDistr$N        [xNow] = xDistr$N
      GlobDistr$Distrib  [xNow] = xDistr$Distr
      GlobDistr$First    [xNow] = xDistr$First
      GlobDistr$SE_First [xNow] = xDistr$SE_First
      GlobDistr$Second   [xNow] = xDistr$Second
      GlobDistr$SE_Second[xNow] = xDistr$SE_Second
      GlobDistr$Third    [xNow] = xDistr$Third
      GlobDistr$SE_Third [xNow] = xDistr$SE_Third
      GlobDistr$LogLik   [xNow] = xDistr$LogLik
      GlobDistr$Mean     [xNow] = xDistr$Mean
      GlobDistr$StdDev   [xNow] = xDistr$StdDev
      GlobDistr$Skewness [xNow] = xDistr$Skewness
      GlobDistr$Kurtosis [xNow] = xDistr$Kurtosis
      GlobDistr$Median   [xNow] = xDistr$Median
      GlobDistr$AIC      [xNow] = xDistr$AIC
      GlobDistr$BIC      [xNow] = xDistr$BIC
   }else{
      cat0(&quot;     * Too few valid points (n=&quot;,sum(xSel),&quot;). Do not fit distribution.&quot;)
   }#end if (sum(xySel) &gt;= n_fit_min)
}#end for (x in sequence(CntDistr))</code></pre>
</div>
<div id="data-imputation" class="section level1">
<h1>Data imputation</h1>
<p>In this step, we use imputation to create a complete set of trait
observations. Because imputation works best only when a small fraction
of the data points are missing, we first tally the availability of each
trait and restrict the imputation and analyses that depend on imputed
data to the traits that are not too sparse.</p>
<pre class="r"><code>update_impute = (  (  ( ! (reload_impute  &amp;&amp; file.exists(rdata_impute )) )
                   &amp;&amp; ( ! (reload_cluster &amp;&amp; file.exists(rdata_cluster)) ) )
                || impute_cluster_test                                     )
if (update_impute){

   # Load some files which will likely be updated as the code is developed.
   source(file.path(util_path,&quot;TRY_ImputeCluster_Utils.r&quot;),chdir=TRUE)

   # Set random seed
   if (is.na(rseed_impute)){
      SeedPrep     = Sys.time()
      rseed_impute = 3600*hour(SeedPrep) + 60*minute(SeedPrep) + floor(second(SeedPrep))
   }#end if (is.na(rseed_impute))
   dummy = set.seed(rseed_impute)


   # Select reference data set for trade-off analysis
   DataTRY = switch( EXPR       = fit_taxon
                   , Individual = TidyTRY
                   , Species    = SpeciesTRY
                   , Genus      = GenusTRY
                   , stop(&quot;Invalid settings for variable \&quot;fit_taxon\&quot;.&quot;)
                   )#end switch

   # List of Taxonomic variables to use
   TaxonAll    = c(&quot;ObservationID&quot;,&quot;ScientificName&quot;,&quot;Genus&quot;,&quot;Family&quot;,&quot;Order&quot;,&quot;Class&quot;,&quot;Phylum&quot;)
   TaxonAll    = TaxonAll[TaxonAll %in% names(DataTRY)]
   TaxonImpute = TaxonAll[-1L]
   TaxonID     = TaxonAll[1L]

   # Pre-select traits that can be used for imputation and cluster analysis. Traits listed as candidates for
   # cluster analysis will be also imputed.
   WhichTraitUse   = c( with( try_trait, which( ( Impute | Cluster ) &amp; ( ! Allom ) ) ) )
   WhichAncilUse   = c( with( try_ancil, which( ( Impute | Cluster )               ) ) )
   EveryCandidate  = unique( c( TaxonImpute
                              , names(DataTRY)[names(DataTRY) %in% try_trait$Name[WhichTraitUse]]
                              , names(DataTRY)[names(DataTRY) %in% try_ancil$Name[WhichAncilUse]]
                              )#end c
                           )#end unique
   TraitNumeric    = names(DataTRY)[names(DataTRY) %in% try_trait$Name[try_trait$Type %in% &quot;numeric&quot;]]
   TraitNumeric    = intersect(TraitNumeric,EveryCandidate)
   AncilNumeric    = names(DataTRY)[names(DataTRY) %in% try_ancil$Name[try_ancil$Type %in% &quot;numeric&quot;]]
   AncilNumeric    = intersect(AncilNumeric,EveryCandidate)
   EveryNumeric    = unique(c(TraitNumeric,AncilNumeric))
   TraitAnyKind    = names(DataTRY)[names(DataTRY) %in% try_trait$Name]

   # Iterate until we obtain a set of traits that have variability, and that all rows have enough observations.
   cat0(&quot; + Keep only rows with sufficient valid traits and traits with sufficient variability&quot;)
   cat0(&quot;   - Initial number of data rows: &quot;,nrow(DataTRY),&quot;.&quot;)
   iterate = TRUE
   itCnt   = 0L
   while (iterate){
      # Update iterate count
      itCnt = itCnt + 1L

      # Count number of data points.
      CntData = nrow(DataTRY)
   

      
      # Identify if there are any traits that do not vary (and thus should not participate in the imputation)
      TraitVar = DataTRY %&gt;% 
         summarise( across(everything()  , ~ findVariability(.x,na.rm=TRUE) ) ) %&gt;%
         select_at(all_of(names(DataTRY))) %&gt;%
         unlist()
            
      # Tally trait data availability and decide whether or not to impute traits
      TallyTRY = DataTRY %&gt;%
         select_at(all_of(EveryCandidate))                %&gt;%
         summarise_all(~ sum(! is.na(.x)))                %&gt;%
         unlist()                                         %&gt;%
         tibble(Name=names(.),Cnt=.)                      %&gt;%
         mutate( Numeric     = Name %in% EveryNumeric
               , Trait       = Name %in% TraitAnyKind
               , Frac        = pmin(1.,Cnt/max(Cnt[Trait &amp; Numeric]))
               , Variability = TraitVar[match(Name,names(TraitVar))]
               , Impute      = ( Frac %ge% f_col_trait_impute      )
                             &amp; ( Variability %gt% f_var_min_impute ) ) %&gt;%
         mutate(Frac=-Frac,Variability=-Variability) %&gt;%
         arrange(Frac,Variability) %&gt;%
         mutate(Frac=-Frac,Variability=-Variability)

      # Alias for traits that will go through imputation.
      EveryImpute = TallyTRY$Name[TallyTRY$Impute]

      # Alias for numeric traits that will go through imputation and must be scaled. 
      NumericImpute      = TallyTRY$Name[TallyTRY$Numeric &amp; TallyTRY$Impute]
      NumericTraitImpute = TallyTRY$Name[TallyTRY$Numeric &amp; TallyTRY$Impute &amp; TallyTRY$Trait]

      # Filter data to keep only those entries with more than the minimum number of numeric traits.
      # (note that we only check the trait, not ancillary variables).
      selKeep = DataTRY %&gt;% 
         select_at(all_of(NumericTraitImpute)) %&gt;%
         apply(MARGIN=1,FUN=function(x,n_min) sum(is.finite(x)) &gt;= n_min,n_min=n_row_numtrait_impute)

      # Exclude data with too few points.
      DataTRY = DataTRY %&gt;% filter(selKeep)

      # Decide whether to iterate or not.
      iterate = (! ( nrow(DataTRY) %eq% CntData ) ) &amp; (itCnt %lt% 10L)

      # Report number of data rows remaining.
      cat0(&quot;   - Iteration &quot;,itCnt,&quot;. Number of data rows: &quot;,nrow(DataTRY),&quot;.&quot;)
   }#end while (iterate)

   # Make sure the data set has converged.
   if ( ! ( nrow(DataTRY) %eq% CntData ) ){
      stop(&quot; Data cleaning did not converge after 10 iterations.&quot;)
   }#end if ( ! ( nrow(DataTRY) %eq% CntData ) )
   
      

   
   # Scale numeric data based on the cumulative distribution function of the fitted distribution
   cat0(&quot; + Scale numeric traits using the fitted distribution.&quot;)
   ScaledTRY = DataTRY                                                         %&gt;%
      select_at(all_of(EveryImpute))                                           %&gt;%
      mutate(across(where(is_character), ~factor(.x,levels=sort(unique(.x)))))
   for (vName in NumericImpute){
      # Select the distribution information
      z       = which(GlobDistr$x %in% vName)
      zDistr  = GlobDistr$Distrib[z]
      zFirst  = GlobDistr$First  [z]
      zSecond = GlobDistr$Second [z]
      zThird  = GlobDistr$Third  [z]
      
      # Use cumulative density function according to the fitted distribution.
      zFun = switch( zDistr
                   , &quot;uniform&quot;       = punif
                   , &quot;normal&quot;        = pnorm
                   , &quot;logistic&quot;      = plogis
                   , &quot;skew-normal&quot;   = sn::psn
                   , &quot;log-normal&quot;    = plnorm
                   , &quot;neglog-normal&quot; = pnlnorm
                   , &quot;weibull&quot;       = pweibull
                   , &quot;gamma&quot;         = pgamma
                   , NA_character_
                   )#end switch
      
      # Decide whether the distribution needs two or three parameters
      if (zDistr %in% &quot;skew-normal&quot;){
         p_vName = zFun(ScaledTRY[[vName]],zFirst,zSecond,zThird)
      }else if (! is.na(zDistr)){
         p_vName = zFun(ScaledTRY[[vName]],zFirst,zSecond)
      }#end if (zDistr %in% &quot;skew-normal&quot;)
      
      # Find the normal distribution equivalent of the value
      ScaledTRY[[vName]] = qnorm(p=p_vName,mean=0.,sd=1.)
   }#end for (v in which(TallyTRY$Numeric &amp; TallyTRY$Impute))

   
   # Subset TRY data set to keep only traits that will go through imputation.
   cat0(&quot; + Run the mixed data imputation algorithm.&quot;)
   ImputeAnswer             = ScaledTRY %&gt;% 
      imputeFAMD(ncp=4L,threshold=1e-4,maxiter=10000)
   ImputeAnswer$originalObs = DataTRY
   ImputedTRY               = as_tibble(ImputeAnswer$completeObs)


   # Go through the imputed tibble and convert it back to the original scale.
   cat0(&quot; + Scale back imputed numeric traits using the fitted distributions.&quot;)
   for (vName in NumericImpute){
      # Select the distribution information
      z       = which(GlobDistr$x %in% vName)
      zDistr  = GlobDistr$Distrib[z]
      zFirst  = GlobDistr$First  [z]
      zSecond = GlobDistr$Second [z]
      zThird  = GlobDistr$Third  [z]

      # Find the equivalent CDF of the normalised quantile.
      p_vName = pnorm(q=ImputedTRY[[vName]],mean=0.,sd=1.)

      # Use quantile function according to the distribution.
      zFun = switch( zDistr
                   , &quot;uniform&quot;       = qunif
                   , &quot;normal&quot;        = qnorm
                   , &quot;logistic&quot;      = qlogis
                   , &quot;skew-normal&quot;   = sn::qsn
                   , &quot;log-normal&quot;    = qlnorm
                   , &quot;neglog-normal&quot; = qnlnorm
                   , &quot;weibull&quot;       = qweibull
                   , &quot;gamma&quot;         = qgamma
                   , NA_character_
                   )#end switch
      
      # Decide whether the distribution needs two or three parameters
      if (zDistr %in% &quot;skew-normal&quot;){
         q_vName = try(zFun(p_vName,zFirst,zSecond,zThird),silent=TRUE)
         if (&quot;try-error&quot; %in% is(q_vName)){
            ImputedTRY[[vName]] = zFun(p_vName,zFirst,zSecond,zThird,solver=&quot;RFB&quot;)
         }else{
            ImputedTRY[[vName]] = q_vName
         }#end if (&quot;try-error&quot; %in% is(q_vName))
      }else if (! is.na(zDistr)){
         ImputedTRY[[vName]] = zFun(p_vName,zFirst,zSecond)
      }#end if (zDistr %in% &quot;skew-normal&quot;)
   }#end for (v in which(TallyTRY$Numeric &amp; TallyTRY$Impute))
   
   
   
   # If any variable was ordered or factor, make them ordered and factors again with the original
   # levels.
   cat0(&quot; + Transform back ordered variables.&quot;)
   WhichOrdered = DataTRY %&gt;% summarise(across(everything(), ~is.ordered(.x))) %&gt;% unlist()
   WhichOrdered = names(WhichOrdered)[WhichOrdered &amp; ( names(WhichOrdered) %in% names(ImputedTRY) )]

   for (NameNow in WhichOrdered){
      ImputedTRY[[NameNow]] = ordered(x=as.character(ImputedTRY[[NameNow]]),levels=levels(DataTRY[[NameNow]]))
   }#end for (NameOrdered %in% WhichOrdered)

   # Remove imputed taxonomic information
   cat0(&quot; + Remove imputed taxonomic information.&quot;)
   ImputedTRY[[TaxonID]] = DataTRY[[TaxonID]]
   ImputedTRY = ImputedTRY                      %&gt;%
      select_at(all_of(c(TaxonID,EveryImpute))) %&gt;%
      arrange_at(all_of(c(TaxonID)))

   # Save imputed data
   if (! impute_cluster_test){
      cat0(&quot; + Save imputed data models to &quot;,basename(rdata_impute))
      dummy = save( list              = c( &quot;ImputeAnswer&quot;,&quot;ImputedTRY&quot;, &quot;TaxonID&quot;, &quot;TallyTRY&quot; )
                  , file              = rdata_impute
                  , compress          = &quot;xz&quot;
                  , compression_level = 9
                  )#end save
      
   }#end if (! impute_cluster_test)
}else{
   # Reload data
   cat0(&quot; + Reload imputed data.&quot;)
   dummy = load(rdata_impute)
}#end if (update_impute)</code></pre>
</div>
<div id="pft-clustering" class="section level1">
<h1>PFT clustering</h1>
<p>Here we perform a cluster analysis to seek a data-driven approach for
defining tropical PFTs. Because we use a mix of continuous and
categorical data, we opt for medoid-based cluster analysis.</p>
<pre class="r"><code>update_cluster = ( update_impute
                 || (! (reload_cluster &amp;&amp; file.exists(rdata_cluster)) )
                 || impute_cluster_test                                 )

if (update_cluster){

   # Load some files which will likely be updated as the code is developed.
   source(file.path(util_path,&quot;clusGapFlex.r&quot;            ),chdir=TRUE)
   source(file.path(util_path,&quot;TRY_ImputeCluster_Utils.r&quot;),chdir=TRUE)

   # Set random seed
   if (is.na(rseed_cluster)){
      SeedPrep     = Sys.time()
      rseed_impute = 3600*hour(SeedPrep) + 60*minute(SeedPred) + floor(second(SeedPrep))
   }#end if (is.na(rseed_cluster))
   dummy = set.seed(rseed_cluster)

   # List taxonomy names. We will exclude them from the cluster analysis
   TaxonAll    = c(&quot;ObservationID&quot;,&quot;ScientificName&quot;,&quot;Genus&quot;,&quot;Family&quot;,&quot;Order&quot;,&quot;Class&quot;,&quot;Phylum&quot;)

   
   # List names to exclude from the cluster analysis
   ExcludeTraitID = try_trait$TraitID[! try_trait$Cluster]
   ExcludeAncilID = try_ancil$DataID [! try_ancil$Cluster]
   ExcludeName    = c( try_trait$Name[try_trait$TraitID %in% ExcludeTraitID]
                     , try_ancil$Name[try_ancil$DataID  %in% ExcludeAncilID]
                     , TaxonAll
                     )#end c
   ExcludeName    = names(ImputedTRY)[names(ImputedTRY) %in% ExcludeName]
      
   # Select the columns that will participate in the cluster analysis
   FilledTRY = ImputedTRY              %&gt;%
      select(! contains(TaxonID))      %&gt;%
      select(! contains(ExcludeName))

   # Select reference data set for trade-off analysis
   OrigTRY    = switch( EXPR       = fit_taxon
                      , Individual = TidyTRY
                      , Species    = SpeciesTRY
                      , Genus      = GenusTRY
                      , stop(&quot;Invalid settings for variable \&quot;fit_taxon\&quot;.&quot;)
                      )#end switch
   OrigTRY = OrigTRY %&gt;% select_at(c(names(FilledTRY)))

   # List of Taxonomic variables to use
   TaxonAll    = c(&quot;ObservationID&quot;,&quot;ScientificName&quot;,&quot;Genus&quot;,&quot;Family&quot;,&quot;Order&quot;,&quot;Class&quot;,&quot;Phylum&quot;)
   TaxonAll    = TaxonAll[TaxonAll %in% names(DataTRY)]
   
   
   # Decide the type of variable and weight for each column
   cat0(&quot; + Find weighting factors for categorical variables.&quot;)
   DataInfo     = tibble( Name     = names(FilledTRY)
                        , Trait    = Name %in% try_trait$Name
                        , Type     = sapply(X=FilledTRY,FUN=findType    )
                        , FracObs  = sapply(X=OrigTRY  ,FUN=fracObserved)
                        , Nlevels  = sapply(X=FilledTRY,FUN=nlevels     )
                        , Entropy  = sapply(X=FilledTRY,FUN=findEntropy )
                        , Evenness = sapply(X=FilledTRY,FUN=findEvenness)
                        )#end tibble
   DataInfo     = DataInfo %&gt;%
      mutate( ObsWeight = pmin(1.,FracObs / max(FracObs[Trait &amp; (Type %in% &quot;numeric&quot;)]))
            , Weight    = ifelse( test = Type %in% c(&quot;factor&quot;)
                                , yes  = ObsWeight * sqrt(Evenness/ (Nlevels-1L))
                                , no   = ifelse( test = Type %in% c(&quot;ordered&quot;)
                                               , yes  = sqrt(Evenness)
                                               , no   = ObsWeight
                                               )#end ifelse
                                )#end ifelse
            , Weight    = Weight / max(Weight)                                   ) %&gt;%
      select(c(Name,Trait,Type,FracObs,ObsWeight,Nlevels,Entropy,Evenness,Weight)) %&gt;%
      arrange(-Weight)


   # Exclude a few other traits that may have very low weight
   ExcludeName = DataInfo$Name[! (DataInfo$Weight %ge% min_weight_cluster)]
   FilledTRY   = FilledTRY %&gt;% select(! contains(ExcludeName))
   OrigTRY     = OrigTRY   %&gt;% select(! contains(ExcludeName))
   DataInfo    = DataInfo  %&gt;% filter(! (Name %in% ExcludeName))

   # Scale numeric data based on the cumulative distribution function of the fitted distribution
   cat0(&quot; + Scale numeric traits using the fitted distribution.&quot;)
   ScaledTRY = FilledTRY
   for (v in which(DataInfo$Type %in% &quot;double&quot;)){
      # Select the distribution information
      vName   = DataInfo$Name[v]
      z       = which(GlobDistr$x %in% vName)
      zDistr  = GlobDistr$Distrib[z]
      zFirst  = GlobDistr$First  [z]
      zSecond = GlobDistr$Second [z]
      zThird  = GlobDistr$Third  [z]
      
      # Fit density according to the distribution.
      zFun = switch( zDistr
                   , &quot;uniform&quot;       = punif
                   , &quot;normal&quot;        = pnorm
                   , &quot;logistic&quot;      = plogis
                   , &quot;skew-normal&quot;   = sn::psn
                   , &quot;log-normal&quot;    = plnorm
                   , &quot;neglog-normal&quot; = pnlnorm
                   , &quot;weibull&quot;       = pweibull
                   , &quot;gamma&quot;         = pgamma
                   , NA_character_
                   )#end switch
      
      # Decide whether the distribution needs two or three parameters
      if (zDistr %in% &quot;skew-normal&quot;){
         p_vName = zFun(FilledTRY[[vName]],zFirst,zSecond,zThird)
      }else if (! is.na(zDistr)){
         p_vName = zFun(FilledTRY[[vName]],zFirst,zSecond)
      }#end if (zDistr %in% &quot;skew-normal&quot;)
      
      # Find the normal distribution equivalent of the value
      ScaledTRY[[vName]] = qnorm(p=p_vName,mean=0.,sd=1.)
   }#end for (v in which(DataInfo$Type %in% &quot;double&quot;))
   
   # Build list of data types for cluster analysis.
   ScaledType = list( asymm    = which(DataInfo$Type %in% &quot;asymm&quot;   )
                    , symm     = which(DataInfo$Type %in% &quot;symm&quot;    )
                    , factor   = which(DataInfo$Type %in% &quot;factor&quot;  )
                    , ordered  = which(DataInfo$Type %in% &quot;ordered&quot; )
                    , logratio = which(DataInfo$Type %in% &quot;logratio&quot;)
                    , ordratio = which(DataInfo$Type %in% &quot;ordratio&quot;)
                    , numeric  = which(DataInfo$Type %in% &quot;numeric&quot; )
                    )#end list
   
   # Find the Gower Distance (dissimilarity matrix.)
   cat0(&quot; + Find the dissimilarity matrix (Gower distance).&quot;)
   DissimilarTRY = cluster::daisy( x       = ScaledTRY
                                 , metric  = &quot;gower&quot;
                                 , type    = ScaledType
                                 , weights = DataInfo$Weight
                                 )#end cluster::daisy
   
   # Set up list with cluster analysis attempts
   cluster_kdigits    = 1L + round(log10(cluster_kmax))
   cluster_kfmt       = paste0(&quot;K_%&quot;,cluster_kdigits,&quot;.&quot;,cluster_kdigits,&quot;i&quot;)
   cluster_klabel     = sprintf(fmt=cluster_kfmt,sequence(cluster_kmax))
   ClusterList        = replicate(n=cluster_kmax,list())
   names(ClusterList) = cluster_klabel
   ClusterInfo        = tibble( k = sequence(cluster_kmax), sil_width = NA_real_, gap = NA_real_, gapSE = NA_real_)
   
   # Set the actual number of Monte Carlo iterations (small number if testing)
   n_mcarlo_cluster_use = if(impute_cluster_test){10L}else{n_mcarlo_cluster}

   
   # Find the optimal number of clusters using the gap statistic.
   cat0(&quot; + Find the optimal number of clusters based on the gap statistic.&quot;)
   ClusterGap = clusGapFlex( x = ScaledTRY
                           , fun_cluster = cluster::pam
                           , metric      = &quot;gower&quot;
                           , stand       = FALSE
                           , type        = ScaledType
                           , weights     = DataInfo$Weight
                           , K_max       = cluster_kmax
                           , d_power     = 2
                           , n_mcarlo    = n_mcarlo_cluster_use
                           , mc_verb     = round(0.1 * n_mcarlo_cluster_use)
                           , verbose     = TRUE
                           , do.swap     = FALSE
                           , pamonce     = 6L
                           )#end clusGapFlex
   ClusterInfo$gap   = ClusterGap$Tab[,&quot;gap&quot;   ]
   ClusterInfo$gapSE = ClusterGap$Tab[,&quot;SE.sim&quot;]


   # Loop through number of clusters and calculate statistics
   cat0(&quot; + Run cluster analysis for multiple number of clusters.&quot;)
   for (k in sequence(cluster_kmax)[-1L]){
      cat0(&quot;   - Seek &quot;,k,&quot; clusters.&quot;)
      ClusterList[[k]]         = cluster::pam(x=DissimilarTRY,k=k,do.swap=FALSE,pamonce=6L)
      ClusterInfo$sil_width[k] = ClusterList[[k]]$silinfo$avg.width
   }#end for (ik in sequence(cluster_nk))


   # Find the optimal number of PFTs based on the silhouette and gap statistics. 
   cat0(&quot; + Save best cluster based on silhouette and gap statistics.&quot;)
   k_use      = ClusterInfo$k &gt;= cluster_kmin
   k_off      = cluster_kmin - 1L 
   k_opt_sil  = k_off + which.max(ClusterInfo$sil_width[k_use])
   k_opt_gap  = k_off + maxSE(f=ClusterInfo$gap[k_use],SE.f=ClusterInfo$gapSE[k_use],SE.factor=1,method=method_gap_maxSE)
   ClusterOpt = list( sil = ClusterList[[k_opt_sil   ]]
                    , gap = ClusterList[[k_opt_gap   ]]
                    , fix = ClusterList[[cluster_kfix]] )

   # Create tibble containing the cluster information
   ClusterTRY = ImputedTRY %&gt;%
      mutate( cluster_gap = factor( x      = ClusterOpt$gap$clustering
                                  , levels = sequence(k_opt_gap)
                                  , labels = ImputedTRY[[TaxonID]][ClusterOpt$gap$id.med]
                                  )#end factor
            , cluster_sil = factor( x      = ClusterOpt$sil$clustering
                                  , levels = sequence(k_opt_sil)
                                  , labels = ImputedTRY[[TaxonID]][ClusterOpt$sil$id.med]
                                  )#end factor
            , cluster_fix = factor( x      = ClusterOpt$fix$clustering
                                  , levels = sequence(cluster_kfix)
                                  , labels = ImputedTRY[[TaxonID]][ClusterOpt$fix$id.med]
                                  )#end factor
            )#end mutate

   # Save data to some R object
   if (! impute_cluster_test){
      cat0(&quot; + Save cluster analysis to &quot;,basename(rdata_cluster),&quot;.&quot;)
      dummy = save( list              = c(&quot;FilledTRY&quot;,&quot;DataInfo&quot;,&quot;ScaledTRY&quot;,&quot;DissimilarTRY&quot;
                                         ,&quot;ClusterInfo&quot;,&quot;ClusterGap&quot;,&quot;ClusterList&quot;,&quot;ClusterOpt&quot;
                                         ,&quot;ClusterTRY&quot;)
                  , file              = rdata_cluster
                  , compress          = &quot;xz&quot;
                  , compression_level = 9
                  )#end save
   }#end if (! impute_cluster_test)

}else{
   # Load cluster analysis
   cat0(&quot; + Reload PFT clustering from &quot;,basename(rdata_cluster),&quot;.&quot;)
   dummy = load(rdata_cluster)
}#end if (update_cluster)</code></pre>
</div>
<div id="revisit-data-to-add-cluster-pfts" class="section level1">
<h1>Revisit data to add Cluster PFTs</h1>
<p>Here we append a column in all data sets to include the Cluster PFT.
We always define the clusters in the <code>TidyTRY</code></p>
<pre class="r"><code>update_tidy_cluster = (  update_cluster
                      || (! file.exists(rdata_TidyCluster))
                      || impute_cluster_test )

if (update_tidy_cluster){

   # Remove Cluster settings from data so this block can be called multiple times
   if (&quot;Cluster&quot; %in% names(TidyTRY   )) TidyTRY    = TidyTRY    %&gt;% select(! Cluster)
   if (&quot;Cluster&quot; %in% names(SpeciesTRY)) SpeciesTRY = SpeciesTRY %&gt;% select(! Cluster)
   if (&quot;Cluster&quot; %in% names(GenusTRY  )) GenusTRY   = GenusTRY   %&gt;% select(! Cluster)
   
   
   # Assign clusters to data sets. We always assign clusters to the &quot;TidyTRY&quot; data set and aggregate to species, genera, and families
   cat0(&quot; + Assign clusters to all available observations.&quot;)
   v_cluster               = paste0(&quot;cluster_&quot;,cluster_method)
   TidyIdx                 = match(TidyTRY[[TaxonID]],ClusterTRY[[TaxonID]])
   TidyTRY$Cluster         = ClusterTRY[[v_cluster]][TidyIdx]
   AbbrCluster             = abbreviate(levels(TidyTRY$Cluster))
   levels(TidyTRY$Cluster) = AbbrCluster
   TidyTRY$Cluster         = as.character(TidyTRY$Cluster)

   
   # Aggregate cluster classification to species.
   cat0(&quot; + Aggregate clusters to species.&quot;)
   SpCluster = TidyTRY                                                                    %&gt;%
      mutate(ScientificName = factor(ScientificName,levels=sort(unique(ScientificName)))) %&gt;%
      group_by(ScientificName)                                                            %&gt;%
      summarise( Family  = commonest(Family ,na.rm=TRUE)
               , Genus   = commonest(Genus  ,na.rm=TRUE)
               , Cluster = commonest(Cluster,na.rm=TRUE) )                                %&gt;%
      ungroup()                                                                           %&gt;%
      mutate(ScientificName = as.character(ScientificName))                               %&gt;%
      arrange(Family,Genus,ScientificName)

   # Aggregate cluster classification to genera.
   cat0(&quot; + Aggregate clusters to genera.&quot;)
   GeCluster = TidyTRY                                                                    %&gt;%
      mutate(Genus=factor(Genus,levels=sort(unique(Genus))))                              %&gt;%
      group_by(Genus)                                                                     %&gt;%
      summarise( Family = commonest(Family,na.rm=TRUE)
               , Cluster = commonest(Cluster,na.rm=TRUE) )                                %&gt;%
      ungroup()                                                                           %&gt;%
      mutate(Genus = as.character(Genus))                                                 %&gt;%
      arrange(Family,Genus) 


   # Merge data sets
   cat0(&quot; + Merge data sets.&quot;)
   SpeciesTRY = as_tibble(merge(SpeciesTRY,SpCluster))
   GenusTRY   = as_tibble(merge(GenusTRY  ,GeCluster))

   # Reorganise data.
   cat0(&quot; + Rearrange data columns.&quot;)
   FirstVars    = c(&quot;ObservationID&quot;,&quot;ScientificName&quot;,&quot;Genus&quot;,&quot;Family&quot;,&quot;Order&quot;,&quot;Class&quot;,&quot;Phylum&quot;,&quot;Author&quot;,&quot;Cluster&quot;)
   TidyOrder    = c(FirstVars[FirstVars %in% names(TidyTRY)   ],names(TidyTRY   )[! (names(TidyTRY   ) %in% FirstVars)])
   SpeciesOrder = c(FirstVars[FirstVars %in% names(SpeciesTRY)],names(SpeciesTRY)[! (names(SpeciesTRY) %in% FirstVars)])
   GenusOrder   = c(FirstVars[FirstVars %in% names(GenusTRY  )],names(GenusTRY  )[! (names(GenusTRY  ) %in% FirstVars)])

   TidyTRY    = TidyTRY    %&gt;% select_at(all_of(TidyOrder   ))
   SpeciesTRY = SpeciesTRY %&gt;% select_at(all_of(SpeciesOrder))
   GenusTRY   = GenusTRY   %&gt;% select_at(all_of(GenusOrder  ))

   # Set colours and symbols
   CntCluster     = length(AbbrCluster)
   if (CntCluster %le% 4L){
      ClusterColours = c(&quot;#8B69AE&quot;,&quot;#F8766D&quot;,&quot;#5CCEE5&quot;,&quot;#005566&quot;)
      ClusterColours = ClusterColours[sequence(CntCluster)]
   }else if (CntCluster %le% 5L){
#      ClusterColours = c(&quot;#8B69AE&quot;,&quot;#F8766D&quot;,&quot;#5CCEE5&quot;,&quot;#008AA6&quot;,&quot;#005566&quot;)
      ClusterColours = c(&quot;#8B69AE&quot;,&quot;#F8766D&quot;,&quot;#5CCEE5&quot;,&quot;#005566&quot;,&quot;#8C2A58&quot;)
      ClusterColours = ClusterColours[sequence(CntCluster)]
   }else if (CntCluster %le% 8L){
      ClusterColours = c(&quot;#1B9E77&quot;,&quot;#D95F02&quot;,&quot;#7570B3&quot;,&quot;#8C2A58&quot;,&quot;#66CCAE&quot;,&quot;#E5975C&quot;,&quot;#C8C5E5&quot;,&quot;#F2B6D2&quot;)
      ClusterColours = ClusterColours[sequence(CntCluster)]
   }else{
      ClusterColours = RColorBrewer::brewer.pal(n=max(3L,CntCluster),name=&quot;Paired&quot;)[sequence(CntCluster)]
   }#end if (CntCluster %le% 8L)
   ClusterSymbols = c(16L,4L,13L,17L,6L,7L,0L,5L,2L,3L,1L,14L,10L,18L,9L,8L,12L,15L,11L)[sequence(CntCluster)]


   # Define the order of the clusters for output based on their wood density and leaf phenology   
   WoodDens    = try_trait$Name[try_trait$TraitID %in%                   c(   4L)][1L]
   LeafPhen    = try_trait$Name[try_trait$TraitID %in%             c(  37L,1251L)][1L]
   GrowthForm  = try_trait$Name[try_trait$TraitID %in%             c(  42L,3400L)][1L]
   SLA         = try_trait$Name[try_trait$TraitID %in% c(3086L,3115L,3116L,3117L)][1L]
   NFixer      = try_trait$Name[try_trait$TraitID %in%                   c(   8L)][1L]
   
   SummCluster = TidyTRY %&gt;%
      select(all_of(c(&quot;Cluster&quot;,LeafPhen,GrowthForm,NFixer,WoodDens,SLA))) %&gt;%
      filter(! is.na(Cluster))                           %&gt;%
      mutate(across(all_of(SLA), ~ -1*.x))               %&gt;%
      group_by(Cluster) %&gt;%
      summarise( across(where(is.ordered)  , ~ orderedMedian(.x,na.rm=TRUE) )
               , across(where(is.character), ~ commonest    (.x,na.rm=TRUE) )
               , across(where(is.double   ), ~ mean         (.x,na.rm=TRUE) ) ) %&gt;%
      ungroup() %&gt;%
      arrange(across(all_of(GrowthForm)),across(all_of(LeafPhen),desc),across(all_of(NFixer)),across(all_of(c(WoodDens,SLA)))) %&gt;% 
      mutate(across(all_of(SLA), ~ -1*.x))

   # Re-order the cluster
   ClusterIdx = match(SummCluster$Cluster,AbbrCluster)
   
   # Define settings for plotting data by cluster
   CategCluster = tibble( TraitID  = 0L
                        , Class    = AbbrCluster[ClusterIdx]
                        , TRYClass = levels(ClusterTRY[[v_cluster]])[ClusterIdx]
                        , Colour   = ClusterColours
                        , Symbol   = ClusterSymbols
                        , XYUse    = NA_character_
                        , Order    = NA_integer_
                        )#end tibble

   CategExtra = rbind(CategInfo,CategCluster) %&gt;%
      arrange(TraitID)

   # Save data to some R object
   if (! impute_cluster_test){
      cat0(&quot; + Save tidy data with clusters to &quot;,basename(rdata_TidyCluster),&quot;.&quot;)
      dummy = save( list              = c(&quot;TidyTRY&quot;,&quot;SpeciesTRY&quot;,&quot;GenusTRY&quot;,&quot;try_trait&quot;,&quot;try_ancil&quot;
                                         ,&quot;CategCluster&quot;,&quot;CategExtra&quot;)
                  , file              = rdata_TidyCluster
                  , compress          = &quot;xz&quot;
                  , compression_level = 9
                  )#end save
   }#end if (! impute_cluster_test)
}else{
   # Load cluster analysis
   cat0(&quot; + Reload tidy data with cluster results from &quot;,basename(rdata_TidyCluster),&quot;.&quot;)
   dummy = load(rdata_TidyCluster)
}#end if (rdata_TidyCluster)


# Write CSV files with trait summaries
cat0(&quot; + Write CSV files with summaries by species and genus:&quot;)
dummy = write_csv( x = SpeciesTRY, file = species_summ, na = &quot;&quot;)
dummy = write_csv( x = GenusTRY  , file = genus_summ  , na = &quot;&quot;)</code></pre>
</div>
<div id="summary-of-all-traits-by-cluster" class="section level1">
<h1>Summary of all traits by cluster</h1>
<p>Here we create two files with cluster summaries. The first is a list
of traits for the medoid taxa (only those that participated in the
cluster analysis). The other contains the median (numeric) or commonest
(categorical) of all traits.</p>
<pre class="r"><code>cat0(&quot; + Retrieve data for the medoid species.&quot;)
# Select medoids of the cluster analysis.
iMed              = ClusterOpt[[cluster_method]]$id.med
MedoidTRY         = ClusterTRY[iMed,]

# Add the summarised Cluster name to the output, and order the medoids following the cluster analysis
MedoidTRY$Cluster = CategCluster$Class[match(MedoidTRY$ScientificName,CategCluster$TRYClass)]
MedoidTRY         = MedoidTRY[match(CategCluster$Class,MedoidTRY$Cluster),]

# Arrange output so it&#39;s in the same order as the main data.
ArrangeNames = names(TidyTRY)[names(TidyTRY) %in% names(MedoidTRY)]
MedoidTRY    = MedoidTRY %&gt;% select_at(vars(ArrangeNames))



# Select the appropriate taxonomic level before Creating the median data set using all traits.
cat0(&quot; + Find median values across clusters based on the entire data set:&quot;)
DataTRY   = switch( EXPR       = fit_taxon
                  , Individual = TidyTRY
                  , Species    = SpeciesTRY
                  , Genus      = GenusTRY
                  , stop(&quot;Invalid settings for variable \&quot;fit_taxon\&quot;.&quot;)
                  )#end switch

# Find the median value (or the commonest value) for all traits.
MedianTRY = DataTRY                                                                     %&gt;%
   filter( ! is.na(Cluster))                                                            %&gt;%
   mutate( Cluster = factor(Cluster,levels=CategCluster$Class))                         %&gt;%
   group_by(Cluster)                                                                    %&gt;%
   summarise( across(where(is.double )  , ~ median       (.x,na.rm=TRUE))
            , across(where(is.integer)  , ~ median       (.x,na.rm=TRUE))
            , across(where(is.ordered)  , ~ orderedMedian(.x,na.rm=TRUE))
            , across(where(is.logical)  , ~ commonest    (.x,na.rm=TRUE))
            , across(where(is.character), ~ commonest    (.x,na.rm=TRUE)) )             %&gt;%
   ungroup()                                                                            %&gt;%
   mutate( Cluster = as.character(Cluster))                                             %&gt;%
   mutate( across( where(is.double), ~ signif(.x,digits=4L) ) )                         %&gt;%
   select_at(vars(names(DataTRY)))

# Stop script testing imputation/cluster analysis
if (impute_cluster_test){
   stop( paste(&quot;This is the end of the imputation/cluster analysis tests. No further&quot;
              ,&quot;calculation to be carried out. For a full run of the script, set variable&quot;
              ,&quot;impute_cluster_test=FALSE and run the script again.&quot;))
}#end if (impute_cluster_test)


# Write CSV files with trait summaries
cat0(&quot; + Write CSV files with summaries by species and genus:&quot;)
dummy = write_csv( x = MedoidTRY, file = cluster_medoid , na = &quot;&quot;)
dummy = write_csv( x = MedianTRY, file = cluster_medians, na = &quot;&quot;)</code></pre>
</div>
<div id="trait-distribution" class="section level1">
<h1>Trait distribution</h1>
<p>Here we fit distributions for each trait, separated by the category
that is differentiated by colour. We test multiple distributions and
pick the one that yields the lowest</p>
<pre class="r"><code>if (reload_SMA_trait &amp;&amp; file.exists(rdata_distr)){
   # Reload data
   cat0(&quot; + Reload trait distributions.&quot;)
   dummy = load(rdata_distr)
}else{


   # Load some files which will likely be updated as the code is developed.
   source(file.path(util_path,&quot;FindBestDistr.r&quot;),chdir=TRUE)
   

   # Find the number of sub-classes to test the model
   CategDistr  = CategExtra %&gt;%
      filter( ( (XYUse %in% &quot;Colour&quot;) | (TraitID %in% 0L) ) &amp; (! duplicated(Class))) %&gt;%
      mutate( TraitName = ifelse( test = TraitID %in% 0L, yes = &quot;Cluster&quot;, no = try_trait$Name[match(TraitID,try_trait$TraitID)]))
   CntCategDistr = nrow(CategDistr)+1L
   
    
   # Select reference data set for trade-off analysis
   DataTRY = switch( EXPR       = fit_taxon
                   , Individual = TidyTRY
                   , Species    = SpeciesTRY
                   , Genus      = GenusTRY
                   , stop(&quot;Invalid settings for variable \&quot;fit_taxon\&quot;.&quot;)
                   )#end switch
   
   # Find out how many traits we will seek to fit a distribution
   cat0(&quot; + Fit trait distribution&quot;)
   xFitDistr = which( (try_trait$Type %in% &quot;numeric&quot;) &amp; (! try_trait$Allom))
   CntDistr  = length(xFitDistr)

      
   # Load settings for the x axis.
   yUniq       = c(&quot;ALL&quot;      ,CategDistr$Class  )
   yTraitID    = c(NA_integer_,CategDistr$TraitID)
   yTraitClass = ifelse( test = yTraitID %gt% 0L
                       , yes  = try_trait$Name[match(yTraitID,try_trait$TraitID)]
                       , no   = ifelse(test=yTraitID %eq% 0L,yes=&quot;Cluster&quot;,no=&quot;All&quot;)
                       )#end ifelse

   # Save objects for distribution plots:
   # InfoDistr is the tibble with the coefficients and goodness-of-fit metrics
   InfoDistr  = tibble( x          = rep(try_trait$Name[xFitDistr],each=CntCategDistr)
                      , xLwr       = rep(NA_real_                 ,times=CntDistr*CntCategDistr)
                      , xUpr       = rep(NA_real_                 ,times=CntDistr*CntCategDistr)
                      , Class      = rep(yUniq                    ,times=CntDistr)
                      , TraitClass = rep(yTraitClass              ,times=CntDistr)
                      , N          = rep(0L                       ,times=CntDistr*CntCategDistr)
                      , Distrib    = rep(NA_character_            ,times=CntDistr*CntCategDistr)
                      , First      = rep(NA_real_                 ,times=CntDistr*CntCategDistr)
                      , SE_First   = rep(NA_real_                 ,times=CntDistr*CntCategDistr)
                      , Second     = rep(NA_real_                 ,times=CntDistr*CntCategDistr)
                      , SE_Second  = rep(NA_real_                 ,times=CntDistr*CntCategDistr)
                      , Third      = rep(NA_real_                 ,times=CntDistr*CntCategDistr)
                      , SE_Third   = rep(NA_real_                 ,times=CntDistr*CntCategDistr)
                      , Mean       = rep(NA_real_                 ,times=CntDistr*CntCategDistr)
                      , StdDev     = rep(NA_real_                 ,times=CntDistr*CntCategDistr)
                      , Skewness   = rep(NA_real_                 ,times=CntDistr*CntCategDistr)
                      , Kurtosis   = rep(NA_real_                 ,times=CntDistr*CntCategDistr)
                      , Median     = rep(NA_real_                 ,times=CntDistr*CntCategDistr)
                      , LogLik     = rep(NA_real_                 ,times=CntDistr*CntCategDistr)
                      , AIC        = rep(NA_real_                 ,times=CntDistr*CntCategDistr)
                      , BIC        = rep(NA_real_                 ,times=CntDistr*CntCategDistr)
                      )#end tibble

   # Copy fitted model for all
   xGlob             = which(InfoDistr$Class %in% &quot;ALL&quot;)
   xCopy             = match(InfoDistr$x,GlobDistr$x)[xGlob]
   InfoDistr[xGlob,] = GlobDistr[xCopy,,drop=FALSE]


   # Skip rows that we have already computed.
   yLoop = which(! (InfoDistr$Class %in% &quot;ALL&quot;) )

   
   # Loop through the variables we will fit distributions
   for (x in seq_along(xFitDistr)){
      # Load settings for the y axis.
      xIndex   = xFitDistr[x]
      xTrait   = try_trait$TraitID[xIndex]
      xName    = try_trait$Name   [xIndex]
      xDesc    = try_trait$Desc   [xIndex]
      xUnit    = try_trait$Unit   [xIndex]
      xTrans   = try_trait$Trans  [xIndex]
      cat0(&quot; + Fit the best distribution model for &quot;,xDesc,&quot;.&quot;)

      # Select valid points 
      xSel = is.finite(DataTRY[[xName]])
      
      for (y in yLoop){
         # Select category (or everything)
         yName  = InfoDistr$TraitClass[y]
         if (yName %in% &quot;Cluster&quot;){
            yDesc = &quot;Data-based cluster&quot;
         }else{
            yDesc = try_trait$Desc[match(yName,try_trait$Name)]
         }#end if (yName %in% &quot;Cluster&quot;)
         yCateg = InfoDistr$Class     [y]
         ySel   = DataTRY[[yName]] %in% yCateg
         cat0(&quot;   - &quot;,yDesc,&quot; category: &quot;,yCateg,&quot;.&quot;)

         # Select univariate data
         xySel  = xSel &amp; ySel
         if (sum(xySel) &gt; 0L){
            xData  = DataTRY[[xName]][xSel &amp; ySel]
            suppressWarnings({xDistr = FindBestDistr(x=xData,nx_min=n_fit_min,verbose=FALSE)})
            
            # Copy summary information to the data table
            xy = which( ( InfoDistr$x        %in% xName  ) 
                      &amp; ( InfoDistr$Class    %in% yCateg )
            )#end which
            InfoDistr$xLwr     [xy] = xDistr$xLwr
            InfoDistr$xUpr     [xy] = xDistr$xUpr
            InfoDistr$N        [xy] = xDistr$N
            InfoDistr$Distrib  [xy] = xDistr$Distr
            InfoDistr$First    [xy] = xDistr$First
            InfoDistr$SE_First [xy] = xDistr$SE_First
            InfoDistr$Second   [xy] = xDistr$Second
            InfoDistr$SE_Second[xy] = xDistr$SE_Second
            InfoDistr$Third    [xy] = xDistr$Third
            InfoDistr$SE_Third [xy] = xDistr$SE_Third
            InfoDistr$LogLik   [xy] = xDistr$LogLik
            InfoDistr$Mean     [xy] = xDistr$Mean
            InfoDistr$StdDev   [xy] = xDistr$StdDev
            InfoDistr$Skewness [xy] = xDistr$Skewness
            InfoDistr$Kurtosis [xy] = xDistr$Kurtosis
            InfoDistr$Median   [xy] = xDistr$Median
            InfoDistr$BIC      [xy] = xDistr$BIC
         }else{
            cat0(&quot;     * Too few valid points (n=&quot;,sum(xySel),&quot;). Do not fit distribution.&quot;)
         }#end if (sum(xySel) &gt;= n_fit_min)
      }#end for (y in sequence(CntCategDistr))
   }#end for (x in seq_along(xFitDistr))

      
   # Save SMA models
   cat0(&quot; + Save fitted distributions models to &quot;,basename(rdata_distr))
   dummy = save( list              = c( &quot;InfoDistr&quot; )
               , file              = rdata_distr
               , compress          = &quot;xz&quot;
               , compression_level = 9
               )#end save
}#end if (reload_SMA_trait &amp;&amp; file.exists(rdata_distr))

# Write CSV files with trait summaries
cat0(&quot; + Write CSV file with trait distribution information:&quot;)
dummy = write_csv( x = InfoDistr, file = distr_summ, na = &quot;&quot;)</code></pre>
</div>
<div id="trait-trade-off-relationships-for-most-traits"
class="section level1">
<h1>Trait trade-off relationships for most traits</h1>
<p>In this part, we develop standardised major axis fittings between
most traits, using a selected trait as reference.</p>
<pre class="r"><code># Check whether to reload data or fit SMA.
if (reload_SMA_trait &amp;&amp; file.exists(rdata_SMA_trait)){
   # Reload data
   cat0(&quot; + Reload trait trade-off relationships.&quot;)
   dummy = load(rdata_SMA_trait)
}else{

   # Select reference data set for trade-off analysis
   DataTRY = switch( EXPR       = fit_taxon
                   , Individual = TidyTRY
                   , Species    = SpeciesTRY
                   , Genus      = GenusTRY
                   , stop(&quot;Invalid settings for variable \&quot;fit_taxon\&quot;.&quot;)
                   )#end switch

   # Load settings for the x axis.
   x      = xsma_idx
   xTrait = try_trait$TraitID[x]
   xName  = try_trait$Name   [x]
   xDesc  = try_trait$Desc   [x]
   xUnit  = try_trait$Unit   [x]
   xTrans = try_trait$Trans  [x]

   # Select valid data for the y axis
   xSel = switch( EXPR     = xTrans
                , identity = is.finite(DataTRY[[xName]])
                , log      = DataTRY[[xName]] %gt% 0.
                , neglog   = DataTRY[[xName]] %lt% 0.
                , sqrt     = DataTRY[[xName]] %ge% 0.
                , cbrt     = is.finite(DataTRY[[xName]])
                , stop(paste0(&quot; Invalid transformation for trait &quot;,xName,&quot; (TraitID = &quot;,xTrait,&quot;).&quot;))
                )#end switch

   # Set forward and backward transformation for x variables
   xForFun  = switch( EXPR     = xTrans 
                    , identity = force
                    , log      = log
                    , neglog   = neglog
                    , sqrt     = sqrt
                    , cbrt     = cbrt
                    )#end switch
   xBackFun = switch( EXPR     = xTrans 
                    , identity = force
                    , log      = exp
                    , neglog   = negexp
                    , sqrt     = function(x){x^2}
                    , cbrt     = function(x){x^3}
                    )#end switch

   # Define the range for which we will generate a relationship
   xValue  = xForFun(DataTRY[[xName]])
   xRange  = suppressWarnings(range(xValue,finite=TRUE))
   xPred   = seq(from=xRange[1],to=xRange[2],length.out=n_predict)
   xSave   = xBackFun(xPred)
   CntPred = length(xPred)

   # Find out how many SMA fits we will seek
   yFitSMA = which(try_trait$SMA &amp; (! (try_trait$Name %in% xName)))
   CntSMA  = length(yFitSMA)

   # Find the number of sub-classes to test the model
   CategSMA  = CategExtra %&gt;%
      filter( ( (XYUse %in% &quot;Colour&quot;) | (TraitID %in% 0L) ) &amp; (! duplicated(Class))) %&gt;%
      mutate( TraitName = ifelse( test = TraitID %in% 0L, yes = &quot;Cluster&quot;, no = try_trait$Name[match(TraitID,try_trait$TraitID)]))

   CategALL  = CategExtra[1L,,drop=FALSE] %&gt;%
      mutate( TraitID   = NA_integer_
            , Class     = &quot;ALL&quot;
            , TRYClass  = &quot;All data&quot;
            , Colour    = &quot;#161616&quot;
            , Symbol    = 15L
            , TraitName = &quot;All&quot;
            )#end mutate
   CategUKN  = CategExtra[1L,,drop=FALSE] %&gt;%
      mutate( TraitID   = NA_integer_
            , Class     = &quot;UKN&quot;
            , TRYClass  = &quot;Unknown&quot;
            , Colour    = &quot;#AAAAAA&quot;
            , Symbol    = 0L
            , TraitName = &quot;Unknown&quot;
            )#end mutate
   CategSMA    = rbind(CategSMA,CategUKN,CategALL)
   CntCategSMA = nrow(CategSMA)
   

   # Save objects for SMA predictions:
   # PredSMA is the tibble that will be saved for plotting (back-transformed)
   # InfoSMA is the tibble with the coefficients and goodness-of-fit metrics
   PredSMA  = tibble( xPred      = rep(xPred,times=CntCategSMA)
                    , x          = rep(xSave,times=CntCategSMA)
                    , Class      = rep(CategSMA$Class,each=CntPred)
                    , TraitClass = rep(CategSMA$TraitName,each=CntPred)
                    )#end tibble
   PredSMA  = PredSMA %&gt;%
      rename_at( vars(&quot;x&quot;), ~c(xName))

   InfoSMA  = tibble( x               = rep(xName,times=CntSMA*CntCategSMA)
                    , y               = rep(try_trait$Name[yFitSMA],each=CntCategSMA)
                    , Class           = rep(CategSMA$Class    ,times=CntSMA)
                    , TraitClass      = rep(CategSMA$TraitName,times=CntSMA)
                    , xTrans          = rep(xTrans,times=CntSMA*CntCategSMA)
                    , yTrans          = rep(try_trait$Trans[yFitSMA],each=CntCategSMA)
                    , Intercept       = rep(NA_real_,times=CntSMA*CntCategSMA)
                    , Intercept_LwrCI = rep(NA_real_,times=CntSMA*CntCategSMA)
                    , Intercept_UprCI = rep(NA_real_,times=CntSMA*CntCategSMA)
                    , Slope           = rep(NA_real_,times=CntSMA*CntCategSMA)
                    , Slope_LwrCI     = rep(NA_real_,times=CntSMA*CntCategSMA)
                    , Slope_UprCI     = rep(NA_real_,times=CntSMA*CntCategSMA)
                    , N               = rep(0L      ,times=CntSMA*CntCategSMA)
                    , R2              = rep(NA_real_,times=CntSMA*CntCategSMA)
                    , pValue          = rep(NA_real_,times=CntSMA*CntCategSMA)
                    )#end c

   # Loop through the SMA variables
   for (y in seq_along(yFitSMA)){
      # Load settings for the y axis.
      yIndex   = yFitSMA[y]
      yTrait   = try_trait$TraitID[yIndex]
      yName    = try_trait$Name   [yIndex]
      yDesc    = try_trait$Desc   [yIndex]
      yUnit    = try_trait$Unit   [yIndex]
      yTrans   = try_trait$Trans  [yIndex]
      yNameLwr = paste0(yName,&quot;_Lower&quot;)
      yNameUpr = paste0(yName,&quot;_Upper&quot;)
      cat0(&quot; + Fit the SMA model for &quot;,yDesc,&quot;.&quot;)

      # Select valid data for the y axis
      ySel = switch( EXPR     = yTrans
                   , identity = is.finite(DataTRY[[yName]])
                   , log      = DataTRY[[yName]] %gt% 0.
                   , neglog   = DataTRY[[yName]] %lt% 0.
                   , sqrt     = DataTRY[[yName]] %ge% 0.
                   , cbrt     = is.finite(DataTRY[[yName]])
                   , stop(paste0(&quot; Invalid transformation for trait &quot;,yName,&quot; (TraitID = &quot;,yTrait,&quot;).&quot;))
                   )#end switch

      # Set forward and backward transformation for x variables
      yForFun  = switch( EXPR     = yTrans 
                       , identity = force
                       , log      = log
                       , neglog   = neglog
                       , sqrt     = sqrt
                       , cbrt     = cbrt
                       )#end switch
      yBackFun = switch( EXPR     = yTrans 
                       , identity = force
                       , log      = exp
                       , neglog   = negexp
                       , sqrt     = function(x){x^2}
                       , cbrt     = function(x){x^3}
                       )#end switch
      
      # Initialise predicted variable
      PredSMA  = PredSMA %&gt;%
         mutate( y       = rep(NA_real_,nrow(PredSMA))
               , y_Lower = rep(NA_real_,nrow(PredSMA))
               , y_Upper = rep(NA_real_,nrow(PredSMA))
               )#end mutate

      for (z in sequence(CntCategSMA)){
         # Define trait selection
         zTrait = CategSMA$TraitID[z]
         zCateg = CategSMA$Class  [z]
         if (is.na(zTrait)){
            # No selection, use all available data.
            zName = &quot;All&quot;
            zDesc = &quot;All data&quot;
            zSel  = rep(TRUE,nrow(DataTRY))
         }else if(zTrait %in% 0L){
            # Data-based cluster class
            zName  = CategSMA$TraitName[z]
            zDesc  = &quot;Data-based cluster class&quot;
            zSel   = DataTRY[[zName]] %in% zCateg
         }else{
            zIndex = match(zTrait,try_trait$TraitID)
            zName  = try_trait$Name   [zIndex]
            zDesc  = try_trait$Desc   [zIndex]
            zSel   = DataTRY[[zName]] %in% zCateg
         }#end if (is.na(zTrait))
         cat0(&quot;   - &quot;,zDesc,&quot; category: &quot;,zCateg,&quot;.&quot;)

         # Subset and transform data prior to fitting the SMA
         DataFit = DataTRY %&gt;%
            filter(xSel &amp; ySel &amp; zSel) %&gt;%
            select_at( vars(c(xName,yName))) %&gt;%
            rename_at( vars(c(xName,yName)), ~ c(&quot;x&quot;,&quot;y&quot;)) %&gt;%
            mutate( x  = xForFun(x), y  = yForFun(y) )

         # Find the correlation between variables. This is used to define the expected sign of the 
         # relationship, and to determine whether or not fitting a SMA model 
         DataCorr = cor(DataFit$x,DataFit$y)
         
         # Fit the SMA model only when the 
         if ( (nrow(DataFit) %gt% n_fit_min ) &amp;&amp; (abs(DataCorr) %ge% SMA_AbsCorrMin) ){

            
            # Fit the full model
            SlopeH0  = (2L*as.integer(DataCorr %ge% 0.)-1L)
            FitSMA   = sma(formula=&quot;y~x&quot;,data=DataFit,robust=SMA_Robust,method=&quot;SMA&quot;,slope.test=SlopeH0)
            SummSMA  = FitSMA$groupsummary

            # Copy coefficients to facilitate
            aFit    = coefficients(FitSMA)[1L]
            bFit    = coefficients(FitSMA)[2L]

            # Save the model predictions for the fitted curve.
            pSel            = PredSMA$Class %in% zCateg
            PredSMA$y[pSel] = aFit + bFit * PredSMA$xPred[pSel]
            PredSMA$y[pSel] = aFit + bFit * PredSMA$xPred[pSel]

            # Copy summary information to the data table
            xyz = which( ( InfoSMA$x     %in% xName  ) 
                       &amp; ( InfoSMA$y     %in% yName  )
                       &amp; ( InfoSMA$Class %in% zCateg )
                       )#end which
            InfoSMA$Intercept      [xyz] = SummSMA$Int
            InfoSMA$Intercept_LwrCI[xyz] = SummSMA$Int_lowCI
            InfoSMA$Intercept_UprCI[xyz] = SummSMA$Int_highCI
            InfoSMA$Slope          [xyz] = SummSMA$Slope
            InfoSMA$Slope_LwrCI    [xyz] = SummSMA$Slope_lowCI
            InfoSMA$Slope_UprCI    [xyz] = SummSMA$Slope_highCI
            InfoSMA$N              [xyz] = SummSMA$n
            InfoSMA$R2             [xyz] = SummSMA$r2
            InfoSMA$pValue         [xyz] = SummSMA$pval

            # Find confidence bands. Sometimes the bootstrap samples may be really off, especially
            # when not fitting a robust model. We check that confidence bands are not outside the 
            # expected value. If not, then we keep trying until it works.
            Iterate = TRUE
            Success = FALSE
            it      = 0L
            while (Iterate &amp;&amp; (it %lt% SMA_MaxIter)){
               # Update iteration count.
               it = it + 1L
               cat0(&quot;     * Find confidence bands. (attempt &quot;,it,&quot;).&quot;)

               BootSMA  = DataFit %&gt;%
                  modelr::bootstrap(n=n_boot, id = &quot;BootID&quot;) %&gt;%
                  group_by(BootID) %&gt;%
                  mutate( .
                        , FitSMA=map(strap, ~ sma(formula=&quot;y~x&quot;,data=.,method=&quot;SMA&quot;,robust=SMA_Robust,slope.test=SlopeH0))
                        ) %&gt;% #end mutate
                  ungroup() %&gt;%
                  mutate( .
                        , Intercept = map_dbl(FitSMA, ~coefficients(.)[1L])
                        , Slope     = map_dbl(FitSMA, ~coefficients(.)[2L])
                        ) %&gt;% #end mutate
                  do ( data.frame( yPred = .$Intercept + .$Slope * PredSMA$xPred[pSel]
                                 , xPred = PredSMA$xPred[pSel]                         ) ) %&gt;%
                  ungroup() %&gt;%
                  group_by(.,xPred) %&gt;%
                  summarise( y_Lower = quantile(yPred,probs=SMA_ConfLwr,na.rm=TRUE,names=FALSE)
                           , y_Upper = quantile(yPred,probs=SMA_ConfUpr,na.rm=TRUE,names=FALSE)
                           ) %&gt;% #end summarise
                  ungroup()
               
               # Copy to the model main structure
               PredSMA$y_Lower[pSel] = BootSMA$y_Lower 
               PredSMA$y_Upper[pSel] = BootSMA$y_Upper 
               
               # Sanity check
               MessSMA = PredSMA %&gt;%
                  filter( is.finite(y) &amp; (! y %wr% c(y_Lower,y_Upper)))

               # Check whether or not to iterate
               Success = nrow(MessSMA) %eq% 0L
               Iterate = (! Success) &amp;&amp; (it %lt% SMA_MaxIter)
            }#end while (iterate)

            if (nrow(MessSMA) %gt% 0L) stop(paste0(&quot;Failed to find reasonable confidence range after &quot;,SMA_MaxIter,&quot; attempts!&quot;))
            
         }else if (abs(DataCorr) %lt% SMA_AbsCorrMin){
            cat0(&quot;     * Correlation &quot;,round(DataCorr,2),&quot; is too low to fit a model.&quot;)
         }else{
            cat0(&quot;     * Not enought points to fit a model.&quot;)
         }#end if (nrow(FitSMA) %gt% n_fit_min)

      }#end for (z in sequence(CntCategSMA))

      
      # Back-transform the fitted curve, and rename variable
      PredSMA = PredSMA %&gt;%
         mutate(y=yBackFun(y), y_Lower = yBackFun(y_Lower), y_Upper = yBackFun(y_Upper)) %&gt;%
         rename_at( vars(c(&quot;y&quot;,&quot;y_Lower&quot;,&quot;y_Upper&quot;)), ~ c(yName,yNameLwr,yNameUpr))
      
      IsOdd   = ( is.finite(PredSMA[[yName]])
                &amp; (! PredSMA[[yName]] %wr% c(PredSMA[[yNameLwr]],PredSMA[[yNameUpr]]) ) )
      MessSMA = PredSMA %&gt;% filter(IsOdd)
      if (nrow(MessSMA) %gt% 0L) stop(&quot;Expected values outside confidence range after back-transformation. Odd!&quot;)

      # 
   }#end for (y in yloop)

      
   # Save SMA models
   cat0(&quot; + Save SMA models to &quot;,basename(rdata_SMA_trait))
   dummy = save( list              = c( &quot;DataTRY&quot;,&quot;PredSMA&quot;,&quot;InfoSMA&quot;, &quot;CategSMA&quot;)
               , file              = rdata_SMA_trait
               , compress          = &quot;xz&quot;
               , compression_level = 9
               )#end save
}#end if (reload_SMA_trait &amp;&amp; file.exists(rdata_SMA_trait))


# Write CSV files with trait summaries
cat0(&quot; + Write CSV file with SMA information:&quot;)
dummy = write_csv( x = InfoSMA, file = SMA_summ, na = &quot;&quot;)</code></pre>
<p>Because photosynthetic traits have limited measurements and tend to
be correlated, we fit standardised major axis fittings that are specific
to photosynthetic traits. Similar to the general SMA fitting, we pick
one photosynthesis trait as reference.</p>
<pre class="r"><code># Check whether to reload data or fit SMA.
if (reload_SMA_photo &amp;&amp; file.exists(rdata_SMA_photo)){
   # Reload data
   cat0(&quot; + Reload trait trade-off relationships for photosynthetic traits.&quot;)
   dummy = load(rdata_SMA_photo)
}else{

   # Select reference data set for trade-off analysis
   DataTRY = switch( EXPR       = fit_taxon
                   , Individual = TidyTRY
                   , Species    = SpeciesTRY
                   , Genus      = GenusTRY
                   , stop(&quot;Invalid settings for variable \&quot;fit_taxon\&quot;.&quot;)
                   )#end switch

   # Load settings for the x axis.
   x      = xphoto_idx
   xTrait = try_trait$TraitID[x]
   xName  = try_trait$Name   [x]
   xDesc  = try_trait$Desc   [x]
   xUnit  = try_trait$Unit   [x]
   xTrans = try_trait$Trans  [x]

   # Select valid data for the y axis
   xSel = switch( EXPR     = xTrans
                , identity = is.finite(DataTRY[[xName]])
                , log      = DataTRY[[xName]] %gt% 0.
                , neglog   = DataTRY[[xName]] %lt% 0.
                , sqrt     = DataTRY[[xName]] %ge% 0.
                , cbrt     = is.finite(DataTRY[[xName]])
                , stop(paste0(&quot; Invalid transformation for trait &quot;,xName,&quot; (TraitID = &quot;,xTrait,&quot;).&quot;))
                )#end switch

   # Set forward and backward transformation for x variables
   xForFun  = switch( EXPR     = xTrans 
                    , identity = force
                    , log      = log
                    , neglog   = neglog
                    , sqrt     = sqrt
                    , cbrt     = cbrt
                    )#end switch
   xBackFun = switch( EXPR     = xTrans 
                    , identity = force
                    , log      = exp
                    , neglog   = negexp
                    , sqrt     = function(x){x^2}
                    , cbrt     = function(x){x^3}
                    )#end switch

   # Define the range for which we will generate a relationship
   xValue  = xForFun(DataTRY[[xName]])
   xRange  = suppressWarnings(range(xValue,finite=TRUE))
   xPred   = seq(from=xRange[1],to=xRange[2],length.out=n_predict)
   xSave   = xBackFun(xPred)
   CntPred = length(xPred)

   # Find out how many SMA fits we will seek
   yFitPhoto = which(try_trait$SMA &amp; try_trait$Photo &amp; (! (try_trait$Name %in% xName)))
   CntPhoto  = length(yFitPhoto)

   # Find the number of sub-classes to test the model
   CategPhoto  = CategExtra %&gt;%
      filter( ( (XYUse %in% &quot;Colour&quot;) | (TraitID %in% 0L) ) &amp; (! duplicated(Class))) %&gt;%
      mutate( TraitName = ifelse( test = TraitID %in% 0L, yes = &quot;Cluster&quot;, no = try_trait$Name[match(TraitID,try_trait$TraitID)]))

   CategALL  = CategExtra[1L,,drop=FALSE] %&gt;%
      mutate( TraitID   = NA_integer_
            , Class     = &quot;ALL&quot;
            , TRYClass  = &quot;All data&quot;
            , Colour    = &quot;#161616&quot;
            , Symbol    = 15L
            , TraitName = &quot;All&quot;
            )#end mutate
   CategUKN  = CategExtra[1L,,drop=FALSE] %&gt;%
      mutate( TraitID   = NA_integer_
            , Class     = &quot;UKN&quot;
            , TRYClass  = &quot;Unknown&quot;
            , Colour    = &quot;#AAAAAA&quot;
            , Symbol    = 0L
            , TraitName = &quot;Unknown&quot;
            )#end mutate
   CategPhoto    = rbind(CategPhoto,CategUKN,CategALL)
   CntCategPhoto = nrow(CategPhoto)
   

   # Save objects for SMA predictions for photosynthesis parameters:
   # PredPhoto is the tibble that will be saved for plotting (back-transformed)
   # InfoPhoto is the tibble with the coefficients and goodness-of-fit metrics
   PredPhoto  = tibble( xPred      = rep(xPred,times=CntCategSMA)
                      , x          = rep(xSave,times=CntCategSMA)
                      , Class      = rep(CategSMA$Class,each=CntPred)
                      , TraitClass = rep(CategSMA$TraitName,each=CntPred)
                      )#end tibble
   PredPhoto  = PredPhoto %&gt;%
      rename_at( vars(&quot;x&quot;), ~c(xName))

   InfoPhoto  = tibble( x               = rep(xName,times=CntPhoto*CntCategPhoto)
                      , y               = rep(try_trait$Name[yFitPhoto],each=CntCategPhoto)
                      , Class           = rep(CategPhoto$Class    ,times=CntPhoto)
                      , TraitClass      = rep(CategPhoto$TraitName,times=CntPhoto)
                      , xTrans          = rep(xTrans,times=CntPhoto*CntCategPhoto)
                      , yTrans          = rep(try_trait$Trans[yFitPhoto],each=CntCategPhoto)
                      , Intercept       = rep(NA_real_,times=CntPhoto*CntCategPhoto)
                      , Intercept_LwrCI = rep(NA_real_,times=CntPhoto*CntCategPhoto)
                      , Intercept_UprCI = rep(NA_real_,times=CntPhoto*CntCategPhoto)
                      , Slope           = rep(NA_real_,times=CntPhoto*CntCategPhoto)
                      , Slope_LwrCI     = rep(NA_real_,times=CntPhoto*CntCategPhoto)
                      , Slope_UprCI     = rep(NA_real_,times=CntPhoto*CntCategPhoto)
                      , N               = rep(0L      ,times=CntPhoto*CntCategPhoto)
                      , R2              = rep(NA_real_,times=CntPhoto*CntCategPhoto)
                      , pValue          = rep(NA_real_,times=CntPhoto*CntCategPhoto)
                      )#end c

   # Loop through the SMA (Photosynthesis) variables
   for (y in seq_along(yFitPhoto)){
      # Load settings for the y axis.
      yIndex   = yFitPhoto[y]
      yTrait   = try_trait$TraitID[yIndex]
      yName    = try_trait$Name   [yIndex]
      yDesc    = try_trait$Desc   [yIndex]
      yUnit    = try_trait$Unit   [yIndex]
      yTrans   = try_trait$Trans  [yIndex]
      yNameLwr = paste0(yName,&quot;_Lower&quot;)
      yNameUpr = paste0(yName,&quot;_Upper&quot;)
      cat0(&quot; + Fit the SMA (Photosynthesis) model for &quot;,yDesc,&quot;.&quot;)

      # Select valid data for the y axis
      ySel = switch( EXPR     = yTrans
                   , identity = is.finite(DataTRY[[yName]])
                   , log      = DataTRY[[yName]] %gt% 0.
                   , neglog   = DataTRY[[yName]] %lt% 0.
                   , sqrt     = DataTRY[[yName]] %ge% 0.
                   , cbrt     = is.finite(DataTRY[[yName]])
                   , stop(paste0(&quot; Invalid transformation for trait &quot;,yName,&quot; (TraitID = &quot;,yTrait,&quot;).&quot;))
                   )#end switch

      # Set forward and backward transformation for x variables
      yForFun  = switch( EXPR     = yTrans 
                       , identity = force
                       , log      = log
                       , neglog   = neglog
                       , sqrt     = sqrt
                       , cbrt     = cbrt
                       )#end switch
      yBackFun = switch( EXPR     = yTrans 
                       , identity = force
                       , log      = exp
                       , neglog   = negexp
                       , sqrt     = function(x){x^2}
                       , cbrt     = function(x){x^3}
                       )#end switch
      
      # Initialise predicted variable
      PredPhoto  = PredPhoto %&gt;%
         mutate( y       = rep(NA_real_,nrow(PredPhoto))
               , y_Lower = rep(NA_real_,nrow(PredPhoto))
               , y_Upper = rep(NA_real_,nrow(PredPhoto))
               )#end mutate

      for (z in sequence(CntCategPhoto)){
         # Define trait selection
         zTrait = CategPhoto$TraitID[z]
         zCateg = CategPhoto$Class  [z]
         if (is.na(zTrait)){
            # No selection, use all available data.
            zName = &quot;All&quot;
            zDesc = &quot;All data&quot;
            zSel  = rep(TRUE,nrow(DataTRY))
         }else if(zTrait %in% 0L){
            # Data-based cluster class
            zName  = CategPhoto$TraitName[z]
            zDesc  = &quot;Data-based cluster class&quot;
            zSel   = DataTRY[[zName]] %in% zCateg
         }else{
            zIndex = match(zTrait,try_trait$TraitID)
            zName  = try_trait$Name   [zIndex]
            zDesc  = try_trait$Desc   [zIndex]
            zSel   = DataTRY[[zName]] %in% zCateg
         }#end if (is.na(zTrait))
         cat0(&quot;   - &quot;,zDesc,&quot; category: &quot;,zCateg,&quot;.&quot;)

         # Subset and transform data prior to fitting the SMA (Photosynthesis)
         DataFit = DataTRY %&gt;%
            filter(xSel &amp; ySel &amp; zSel) %&gt;%
            select_at( vars(c(xName,yName))) %&gt;%
            rename_at( vars(c(xName,yName)), ~ c(&quot;x&quot;,&quot;y&quot;)) %&gt;%
            mutate( x  = xForFun(x), y  = yForFun(y) )

         # Find the correlation between variables. This is used to define the expected sign of the 
         # relationship, and to determine whether or not fitting a SMA model (Photosynthesis)
         DataCorr = cor(DataFit$x,DataFit$y)
         
         # Fit the SMA model (Photosynthesis) only when there are enough data points
         if ( (nrow(DataFit) %gt% n_fit_min ) &amp;&amp; (abs(DataCorr) %ge% SMA_AbsCorrMin) ){

            
            # Fit the full model
            SlopeH0    = (2L*as.integer(DataCorr %ge% 0.)-1L)
            FitPhoto   = sma(formula=&quot;y~x&quot;,data=DataFit,robust=SMA_Robust,method=&quot;SMA&quot;,slope.test=SlopeH0)
            SummPhoto  = FitPhoto$groupsummary

            # Copy coefficients to facilitate
            aFit    = coefficients(FitPhoto)[1L]
            bFit    = coefficients(FitPhoto)[2L]

            # Save the model predictions for the fitted curve.
            pSel            = PredPhoto$Class %in% zCateg
            PredPhoto$y[pSel] = aFit + bFit * PredPhoto$xPred[pSel]
            PredPhoto$y[pSel] = aFit + bFit * PredPhoto$xPred[pSel]

            # Copy summary information to the data table
            xyz = which( ( InfoPhoto$x     %in% xName  ) 
                       &amp; ( InfoPhoto$y     %in% yName  )
                       &amp; ( InfoPhoto$Class %in% zCateg )
                       )#end which
            InfoPhoto$Intercept      [xyz] = SummPhoto$Int
            InfoPhoto$Intercept_LwrCI[xyz] = SummPhoto$Int_lowCI
            InfoPhoto$Intercept_UprCI[xyz] = SummPhoto$Int_highCI
            InfoPhoto$Slope          [xyz] = SummPhoto$Slope
            InfoPhoto$Slope_LwrCI    [xyz] = SummPhoto$Slope_lowCI
            InfoPhoto$Slope_UprCI    [xyz] = SummPhoto$Slope_highCI
            InfoPhoto$N              [xyz] = SummPhoto$n
            InfoPhoto$R2             [xyz] = SummPhoto$r2
            InfoPhoto$pValue         [xyz] = SummPhoto$pval

            # Find confidence bands. Sometimes the bootstrap samples may be really off, especially
            # when not fitting a robust model. We check that confidence bands are not outside the 
            # expected value. If not, then we keep trying until it works.
            Iterate = TRUE
            Success = FALSE
            it      = 0L
            while (Iterate &amp;&amp; (it %lt% SMA_MaxIter)){
               # Update iteration count.
               it = it + 1L
               cat0(&quot;     * Find confidence bands. (attempt &quot;,it,&quot;).&quot;)

               BootPhoto  = DataFit %&gt;%
                  modelr::bootstrap(n=n_boot, id = &quot;BootID&quot;) %&gt;%
                  group_by(BootID) %&gt;%
                  mutate( .
                        , FitPhoto=map(strap, ~ sma(formula=&quot;y~x&quot;,data=.,method=&quot;SMA&quot;,robust=SMA_Robust,slope.test=SlopeH0))
                        ) %&gt;% #end mutate
                  ungroup() %&gt;%
                  mutate( .
                        , Intercept = map_dbl(FitPhoto, ~coefficients(.)[1L])
                        , Slope     = map_dbl(FitPhoto, ~coefficients(.)[2L])
                        ) %&gt;% #end mutate
                  do ( data.frame( yPred = .$Intercept + .$Slope * PredPhoto$xPred[pSel]
                                 , xPred = PredPhoto$xPred[pSel]                         ) ) %&gt;%
                  ungroup() %&gt;%
                  group_by(.,xPred) %&gt;%
                  summarise( y_Lower = quantile(yPred,probs=SMA_ConfLwr,na.rm=TRUE,names=FALSE)
                           , y_Upper = quantile(yPred,probs=SMA_ConfUpr,na.rm=TRUE,names=FALSE)
                           ) %&gt;% #end summarise
                  ungroup()
               
               # Copy to the model main structure
               PredPhoto$y_Lower[pSel] = BootPhoto$y_Lower 
               PredPhoto$y_Upper[pSel] = BootPhoto$y_Upper 
               
               # Sanity check
               MessPhoto = PredPhoto %&gt;%
                  filter( is.finite(y) &amp; (! y %wr% c(y_Lower,y_Upper)))

               # Check whether or not to iterate
               Success = nrow(MessPhoto) %eq% 0L
               Iterate = (! Success) &amp;&amp; (it %lt% SMA_MaxIter)
            }#end while (iterate)

            if (nrow(MessPhoto) %gt% 0L) stop(paste0(&quot;Failed to find reasonable confidence range after &quot;,SMA_MaxIter,&quot; attempts!&quot;))
            
         }else if (abs(DataCorr) %lt% SMA_AbsCorrMin){
            cat0(&quot;     * Correlation &quot;,round(DataCorr,2),&quot; is too low to fit a model.&quot;)
         }else{
            cat0(&quot;     * Not enought points to fit a model.&quot;)
         }#end if (nrow(FitPhoto) %gt% n_fit_min)

      }#end for (z in sequence(CntCategPhoto))

      
      # Back-transform the fitted curve, and rename variable
      PredPhoto = PredPhoto %&gt;%
         mutate(y=yBackFun(y), y_Lower = yBackFun(y_Lower), y_Upper = yBackFun(y_Upper)) %&gt;%
         rename_at( vars(c(&quot;y&quot;,&quot;y_Lower&quot;,&quot;y_Upper&quot;)), ~ c(yName,yNameLwr,yNameUpr))
      
      IsOdd   = ( is.finite(PredPhoto[[yName]])
                &amp; (! PredPhoto[[yName]] %wr% c(PredPhoto[[yNameLwr]],PredPhoto[[yNameUpr]]) ) )
      MessPhoto = PredPhoto %&gt;% filter(IsOdd)
      if (nrow(MessPhoto) %gt% 0L) stop(&quot;Expected values outside confidence range after back-transformation. Odd!&quot;)

      # 
   }#end for (y in yloop)

      
   # Save SMA models (photosynthesis)
   cat0(&quot; + Save SMA models (Photosynthesis) to &quot;,basename(rdata_SMA_photo))
   dummy = save( list              = c( &quot;DataTRY&quot;,&quot;PredPhoto&quot;,&quot;InfoPhoto&quot;, &quot;CategPhoto&quot;)
               , file              = rdata_SMA_photo
               , compress          = &quot;xz&quot;
               , compression_level = 9
               )#end save
}#end if (reload_SMA_photo &amp;&amp; file.exists(rdata_SMA_photo))



# Write CSV files with trait summaries
cat0(&quot; + Write CSV file with SMA information for photosynthesis traits.&quot;)
dummy = write_csv( x = InfoPhoto, file = SMAPhoto_summ, na = &quot;&quot;)</code></pre>
<p>In this part, we find rank correlation amongst traits.</p>
<pre class="r"><code># Check whether to reload data or find correlation matrix again.
if (reload_corr_trait &amp;&amp; file.exists(rdata_corr_trait)){
   # Reload data
   cat0(&quot; + Reload trait trade-off relationships.&quot;)
   dummy = load(rdata_corr_trait)
}else{

   # Select reference data set for trade-off analysis
   DataTRY = switch( EXPR       = fit_taxon
                   , Individual = TidyTRY
                   , Species    = SpeciesTRY
                   , Genus      = GenusTRY
                   , stop(&quot;Invalid settings for variable \&quot;fit_taxon\&quot;.&quot;)
                   )#end switch

   # Find out how many SMA fits we will seek
   xyFindCorr        = which(try_trait$SMA)
   xyCombCorr        = as_tibble(data.frame(t(combn(x=xyFindCorr,m=2))))
   names(xyCombCorr) = c(&quot;xIndex&quot;,&quot;yIndex&quot;)
   CntComb           = nrow(xyCombCorr)

   # Find the number of sub-classes to test the model
   CategCorr  = CategExtra %&gt;%
      filter( ( (XYUse %in% &quot;Colour&quot;) | (TraitID %in% 0L) ) &amp; (! duplicated(Class))) %&gt;%
      mutate( TraitName = ifelse( test = TraitID %in% 0L, yes = &quot;Cluster&quot;, no = try_trait$Name[match(TraitID,try_trait$TraitID)]))

   CategALL  = CategExtra[1L,,drop=FALSE] %&gt;%
      mutate( TraitID   = NA_integer_
            , Class     = &quot;ALL&quot;
            , TRYClass  = &quot;All data&quot;
            , Colour    = &quot;#161616&quot;
            , Symbol    = 15L
            , TraitName = &quot;All&quot;
            )#end mutate
   CategUKN  = CategExtra[1L,,drop=FALSE] %&gt;%
      mutate( TraitID   = NA_integer_
            , Class     = &quot;UKN&quot;
            , TRYClass  = &quot;Unknown&quot;
            , Colour    = &quot;#AAAAAA&quot;
            , Symbol    = 0L
            , TraitName = &quot;Unknown&quot;
            )#end mutate
   CategCorr    = rbind(CategCorr,CategUKN,CategALL)
   CntCategCorr = nrow(CategCorr)
   

   # Save objects for correlations:
   CorrTRY  = tibble( xName       = rep(try_trait$Name[xyCombCorr$xIndex],times=CntCategCorr)
                    , yName       = rep(try_trait$Name[xyCombCorr$yIndex],times=CntCategCorr)
                    , zName       = rep(CategCorr$TraitName,each=CntComb)
                    , Class       = rep(CategCorr$Class    ,each=CntComb)
                    , Correlation = rep(NA_real_   ,times=CntComb*CntCategCorr)
                    , pValue      = rep(NA_real_   ,times=CntComb*CntCategCorr)
                    , nPairs      = rep(NA_integer_,times=CntComb*CntCategCorr)
                    )#end tibble
      
   # List trait categories that should be compared.
   zLoop = which(! (CategCorr$Class %in% &quot;UKN&quot;))
   
   # Loop through trait combinations
   for (xy in sequence(CntComb)){
      # Load traits to be correlated
      xIndex = xyCombCorr$xIndex[xy]
      yIndex = xyCombCorr$yIndex[xy]
      xName  = try_trait$Name[xIndex]
      xDesc  = try_trait$Desc[xIndex]
      yName  = try_trait$Name[yIndex]
      yDesc  = try_trait$Desc[yIndex]
      cat0(&quot; + Find correlation between &quot;,xDesc,&quot; and &quot;,yDesc,&quot;.&quot;)
      
      # Loop through trait classes (plus the special case of correlating everything)
      for (z in zLoop){
         # Find the trait class
         zName  = CategCorr$TraitName[z]
         zClass = CategCorr$Class    [z]
         if (zName %in% &quot;All&quot;){
            DataCorr = DataTRY                                %&gt;%
               filter_at(vars(c(xName,yName)), ~ ! is.na(.x)) %&gt;%
               select_at(c(xName,yName))
         }else{
            DataCorr = DataTRY                                %&gt;%
               filter_at(vars(c(zName)), ~ .x %in% zClass)    %&gt;%
               filter_at(vars(c(xName,yName)), ~ ! is.na(.x)) %&gt;%
               select_at(c(xName,yName))
         }#end if (zName %in% &quot;All&quot;)

         # Select entry from correlation table.
         xyzSel  = which((CorrTRY$xName %in% xName) &amp; (CorrTRY$yName %in% yName) &amp; (CorrTRY$Class %in% zClass))

         # Find the number of points available for correlation 
         CntCorr                = nrow(DataCorr)
         CorrTRY$nPairs[xyzSel] = CntCorr
         

         # Find correlation then save the statistic and the p-value.
         if (CntCorr %gt% n_kendall_min){
            CorrNow                     = Kendall::Kendall( x =DataCorr[[xName]], y = DataCorr[[yName]])
            CorrTRY$Correlation[xyzSel] = CorrNow$tau
            CorrTRY$pValue     [xyzSel] = CorrNow$sl
         }#end if (CntCorr %gt% n_kendall_min)
         
      }#end for (z in zLoop)
   }#end for (xy in sequence(CntComb))

      
   # Save SMA models
   cat0(&quot; + Save correlation table to &quot;,basename(rdata_corr_trait))
   dummy = save( list              = c( &quot;CorrTRY&quot;)
               , file              = rdata_corr_trait
               , compress          = &quot;xz&quot;
               , compression_level = 9
               )#end save
}#end if (reload_corr_trait &amp;&amp; file.exists(rdata_corr_trait))

# Write CSV files with trait summaries
cat0(&quot; + Write CSV file with correlation information:&quot;)
CorrShow = CorrTRY %&gt;% filter(pValue %le% pmax_kendall_show)
dummy    = write_csv( x = CorrShow, file = corr_summ, na = &quot;&quot;)</code></pre>
</div>
<div id="overview-plots" class="section level1">
<h1>Overview plots</h1>
<div id="trait-abundance-maps" class="section level2">
<h2>Trait abundance maps</h2>
<p>First, we plot spatial maps of the trait abundance, using the
prescribed bin size and transformation (because data may be highly
concentrated on a few points, it may be a good idea to apply square root
or logarithmic transformation). These are always done at the individual
level, because they do not depend on matches between traits.</p>
<pre class="r"><code># Make sure the data set has coordinates
Lon = try_ancil$Name[try_ancil$DataID %in% c(60L,4705L,4707L)]
Lat = try_ancil$Name[try_ancil$DataID %in% c(59L,4704L,4706L)]
if (plot_abund_map &amp;&amp; all(c(length(Lon),length(Lat)) %eq% 1L)){
   # Plot data. Find grid limits
   TraitLoop = sequence(nrow(try_trait))
   LimitLon  = range(TidyTRY[[Lon]],finite=TRUE)
   LimitLat  = range(TidyTRY[[Lat]],finite=TRUE)
   XYWidth   = min(c(diff(LimitLon),diff(LimitLat))) / n_map_bin

   # Create a dummy tibble with missing values around the edge to fix hexagon size
   LimitWest  = LimitLon[1] - 0.08 * diff (LimitLon)   
   LimitEast  = LimitLon[2] + 0.08 * diff (LimitLon)   
   LimitSouth = LimitLat[1] - 0.08 * diff (LimitLat)
   LimitNorth = LimitLat[2] + 0.08 * diff (LimitLat)
   EdgeLon    = seq(from=LimitWest ,to=LimitEast ,length.out=n_map_bin)
   EdgeLat    = seq(from=LimitSouth,to=LimitNorth,length.out=n_map_bin)
   EdgeWest   = rep(LimitWest ,times=n_map_bin)
   EdgeEast   = rep(LimitEast ,times=n_map_bin)
   EdgeSouth  = rep(LimitSouth,times=n_map_bin)
   EdgeNorth  = rep(LimitNorth,times=n_map_bin)
   
   EmptyTemplate = tibble( x = c(EdgeWest,EdgeLon  ,EdgeEast,EdgeLon  )
                         , y = c(EdgeLat ,EdgeNorth,EdgeLat ,EdgeSouth)
                         , z = NA_character_
                         )#end tibble
}else{
   TraitLoop = sequence(0L)
}#end if (all(c(length(Lon),length(Lat))) %gt% 0L)

# Loop through traits with potential geo-referenced data
gg_map = list()
for (tr in TraitLoop){
   # Select trait
   TraitName  = try_trait$Name [tr]
   TraitDesc  = try_trait$Desc [tr]
   TraitUnit  = try_trait$Unit [tr]
   TraitType  = try_trait$Type [tr]
   
   

   # Exclude rows that are not georeferenced or do not have valid data for the current trait,
   # and check if there are enough points for drawing the map.
   AbundTRY   = TidyTRY %&gt;%
      select_at(vars(c(Lon,Lat,TraitName))) %&gt;%
      filter_at(vars(c(Lon,Lat,TraitName)), all_vars(! is.na(.)))
   CntTrait  = nrow(AbundTRY)
   TraitPlot = CntTrait %ge% n_map_min


   
   
   # Plot the map if there are enough points
   if (TraitPlot){
      # Make empty template compatible with the current data
      Empty = EmptyTemplate %&gt;%
         mutate(z = as(z,TraitType)) %&gt;%
         rename_at(vars(x,y,z), ~c(Lon,Lat,TraitName))

      # Append empty template to data so hexagons look all the same.
      AbundTRY = bind_rows(AbundTRY,Empty)
      
      cat0(&quot; + Plot abundance maps of &quot;,TraitDesc,&quot; (&quot;,TraitName,&quot;).&quot;)
      gg_now = ggplot()
      gg_now = gg_now + geom_sf(data=br_states,fill=&quot;transparent&quot;,colour=&quot;grey20&quot;,linetype=&quot;dashed&quot;,size=.15,show.legend=FALSE)
      gg_now = gg_now + geom_sf(data=all_countries,fill=&quot;transparent&quot;,colour=&quot;black&quot;,linetype=&quot;solid&quot;,size=.30,show.legend=FALSE)
      gg_now = gg_now + coord_sf(xlim=LimitLon,ylim=LimitLat)
      gg_now = gg_now + geom_bin_2d(data=AbundTRY,aes_string(x=Lon,y=Lat),binwidth=c(XYWidth,XYWidth))
      gg_now = gg_now + scale_fill_continuous(type = map_colour,direction=-1,trans=map_trans,limits=map_range,oob=squish)

      # Add annotation
      gg_now = gg_now + labs ( x        = element_blank()
                             , y        = element_blank()
                             , title    = TraitDesc
                             , subtitle = paste0(&quot;Observation abundance (n=&quot;,CntTrait,&quot;)&quot;)
                             )#end labs

      # Axis theme settings
      gg_now = gg_now + theme_grey( base_size      = gg_ptsz
                                  , base_family    = &quot;Helvetica&quot;
                                  , base_line_size = 0.5
                                  , base_rect_size = 0.5
                                  )#end theme_grey
      gg_now = gg_now + theme( axis.text.x       = element_text( size   = gg_ptsz*0.8
                                                               , margin = unit(rep(0.35,times=4),&quot;char&quot;)
                                                               )#end element_text
                             , axis.text.y       = element_text( size   = gg_ptsz*0.8
                                                               , margin = unit(rep(0.35,times=4),&quot;char&quot;)
                                                               )#end element_text
                             , axis.ticks.length = unit(-0.2,&quot;char&quot;)
                             , axis.title.y      = element_text( size = gg_ptsz * 0.6)
                             , legend.title      = element_text( size = gg_ptsz * 0.6)
                             , plot.margin       = unit(c(0,0,0,0), &quot;mm&quot;)
                             )#end theme
      
      #Stash map
      gg_map[[TraitName]] = gg_now

      #Save map to file
      DeviceLoop = sequence(ndevice)
      for (d in DeviceLoop){
         h_output = paste0(&quot;AbundMap-&quot;,TraitName,&quot;-&quot;,base_suffix,&quot;.&quot;,gg_device[d])
         dummy    = ggsave( filename = h_output
                          , plot     = gg_now
                          , device   = gg_device[d]
                          , path     = abund_path
                          , units    = gg_units
                          , dpi      = gg_depth
                          , width    = gg_width
                          , height   = gg_height
                          )#end ggsave
      }#end for (d in device_loop)
   }#end if (TraitPlot)

}#end for (tr in TraitLoop)

# If sought, plot images on screen
cnt_gg_map = length(gg_map)
if (gg_screen &amp;&amp; (cnt_gg_map %gt% 0L)){
   gg_show = sort(sample.int(n=cnt_gg_map,size=min(cnt_gg_map,3L),replace=FALSE))
   gg_map[gg_show]
}#end if (gg_screen &amp;&amp; (length(gg_map) %gt% 0L))</code></pre>
<p><img src="TraitTradeOffs_files/figure-html/plot-geohex-1.png" width="768" /><img src="TraitTradeOffs_files/figure-html/plot-geohex-2.png" width="768" /><img src="TraitTradeOffs_files/figure-html/plot-geohex-3.png" width="768" /></p>
</div>
<div id="violin-plots" class="section level2">
<h2>Violin plots</h2>
<p>Here we plot violin diagrams segregated by multiple categorical
variables.</p>
<pre class="r"><code># Select reference data set for trade-off analysis
DataTRY = switch( EXPR       = fit_taxon
                , Individual = TidyTRY
                , Species    = SpeciesTRY
                , Genus      = GenusTRY
                , stop(&quot;Invalid settings for variable \&quot;fit_taxon\&quot;.&quot;)
                )#end switch

# Select categories we are interested in plotting.
CategTraitID    = sort(unique(CategExtra$TraitID))
CategTraitID    = CategTraitID[CategTraitID %in% c(0L,try_trait$TraitID)]
CntCategList    = length(CategTraitID)

# Loop through categorical traits and assign all individuals from the same species to the commonest class
gg_violin = list()
CategLoop = if(plot_violin){sequence(CntCategList)}else{sequence(0L)}
#  Loop through the categories
for (w in CategLoop){

   # Select categorical trait
   CategIDNow = CategTraitID[w]
   if (CategIDNow %in% 0L){
      # Handy aliases
      CategName = &quot;Cluster&quot;
      CategDesc = &quot;Trait-based clusters&quot;
   }else{
      # Find settings from try_trait
      z          = match(CategIDNow,try_trait$TraitID)
      if (! is.finite(z)) stop(paste0(&quot; Unrecognised categorical trait ID: &quot;,CategIDNow,&quot;.&quot;))
      
      # Handy aliases
      CategName = try_trait$Name[z]
      CategDesc = try_trait$Desc[z]
   }#end if (CategIDNow %in% 0L)
   cat0(&quot; + Plot violin diagrams grouped by &quot;,CategDesc,&quot; (&quot;,CategName,&quot;).&quot;)

   # Select only the lines that are associated with this trait AND are not duplicated.
   InfoNow = CategExtra               %&gt;% 
      filter(TraitID %in% CategIDNow) %&gt;%
      filter(! duplicated(Class))
   CntInfoNow = nrow(InfoNow)
   
   # Filter input data to exclude missing categories
   ViolinTRY = DataTRY %&gt;%
      filter_at(vars(CategName), ~ ! is.na(.x)) %&gt;%
      mutate_at(vars(CategName), ~ factor(.x,levels=InfoNow$Class))
   
   # Make sure there is anything to plot 
   IsPlot = which((try_trait$Type %in% &quot;numeric&quot;) &amp; (! try_trait$Allom) &amp; (try_trait$Name %in% names(ViolinTRY))) 

   # Loop through all traits, and compare evergreens with drought deciduous.
   for (tr in IsPlot){
      # Select trait
      TraitName  = try_trait$Name [tr]
      TraitDesc  = try_trait$Desc [tr]
      TraitUnit  = try_trait$Unit [tr]
      TraitTrans = try_trait$Trans[tr]
      TraitTrans = switch( EXPR     = try_trait$Trans[tr]
                         , log      = &quot;log10&quot;
                         , neglog   = &quot;neglog10&quot;
                         , try_trait$Trans[tr]
                         )#end switch

      # Ensure that trait is numeric and has valid values for at least 2 categories.
      TraitRange = ViolinTRY %&gt;% 
         group_by_at(vars(CategName)) %&gt;%
         summarise_at(vars(TraitName), ~ range(.x,finite=TRUE)) %&gt;%
         ungroup()
      TraitFine  = ViolinTRY %&gt;% 
         group_by_at(vars(CategName)) %&gt;%
         summarise_at(vars(TraitName), ~ sum(is.finite(.x)) %ge% n_violin_min) %&gt;%
         ungroup()
      TraitPlot   = sum(TraitFine[[TraitName]]) %ge% 2L

      # Exclude data from categories with too few data points
      CategIgnore  = as.integer(TraitFine[[CategName]])[! TraitFine[[TraitName]]]
      Discard      = as.integer(ViolinTRY[[CategName]]) %in% CategIgnore
      ViolinTRY[[TraitName]][Discard] = NA_real_
      
      # We only plot this if this trait has anything to be plotted.
      if (TraitPlot){
         # Run Tukey&#39;s HSD test for phenological groups
         TraitFormula = as.formula(paste0(TraitName,&quot; ~ &quot;,CategName))
         TraitAOV     = aov(TraitFormula,data=ViolinTRY)
         TraitGroup   = HSD.test(TraitAOV,trt=CategName,group=TRUE)$groups
         TraitOrder   = InfoNow$Class[InfoNow$Class %in% rownames(TraitGroup)]
         TraitGroup   = TraitGroup[TraitOrder,,drop=FALSE]

         # Set y axis range, apply an offset for Tukey&#39;s HSD tests
         TraitYLim   = range(TraitRange[[TraitName]],finite=TRUE)
         TraitYLwr   = TraitYLim[1L]
         TraitYUpr   = TraitYLim[2L]
         if (TraitTrans %in% &quot;identity&quot;){
            TraitYOff = 0.1 * (TraitYUpr - TraitYLwr)
            TraitYUpr = TraitYUpr + TraitYOff
         }else if (TraitTrans %in% &quot;log10&quot;){
            TraitYLwr = log10(TraitYLwr)
            TraitYUpr = log10(TraitYUpr)
            TraitYOff = 0.1 * (TraitYUpr - TraitYLwr)
            TraitYLwr = 10^TraitYLwr
            TraitYUpr = 10^(TraitYUpr+TraitYOff)
         }else if (TraitTrans %in% &quot;neglog&quot;){
            TraitYLwr = -log10(-TraitYLwr)
            TraitYUpr = -log10(-TraitYUpr)
            TraitYOff =  0.1 * (TraitYUpr - TraitYLwr)
            TraitYLwr = -10^(-TraitYLwr)
            TraitYUpr = -10^(-TraitYUpr-TraitYOff)
         }else if (TraitTrans %in% &quot;sqrt&quot;){
            TraitYLwr = sqrt(TraitYLwr)
            TraitYUpr = sqrt(TraitYUpr)
            TraitYOff = 0.1 * (TraitYUpr - TraitYLwr)
            TraitYLwr = TraitYLwr^2
            TraitYUpr = (TraitYUpr+TraitYOff)^2
         }else if (TraitTrans %in% &quot;cbrt&quot;){
            TraitYLwr = cbrt(TraitYLwr)
            TraitYUpr = cbrt(TraitYUpr)
            TraitYOff = 0.1 * (TraitYUpr - TraitYLwr)
            TraitYLwr = TraitYLwr^3
            TraitYUpr = (TraitYUpr+TraitYOff)^3
         }#end if (TraitTrans %in% &quot;identity&quot;)
         TraitYLim   = c(TraitYLwr,TraitYUpr)
         TraitTukey  = tibble( x      = match(rownames(TraitGroup),InfoNow$Class)
                             , y      = rep(x=TraitYUpr,times=nrow(TraitGroup))
                             , labels = TraitGroup$groups
                             )#end tibble
         
         # Create named vector for phenology classes: this is needed to ensure colours are consistent.
         ViolinLabel  = InfoNow$Class ; names(ViolinLabel ) = InfoNow$Class
         ViolinColour = InfoNow$Colour; names(ViolinColour) = InfoNow$Class
         
         # Add violins
         gg_now = ggplot(data=ViolinTRY,aes_string(x=CategName,y=TraitName,fill=CategName))
         gg_now = gg_now + scale_x_discrete(labels=ViolinLabel)
         gg_now = gg_now + scale_y_continuous(limits=TraitYLim,trans=TraitTrans)
         gg_now = gg_now + geom_violin(trim=TRUE,show.legend = FALSE,kernel=&quot;optcosine&quot;,n=2048L)
         gg_now = gg_now + scale_fill_manual(values=ViolinColour)
         gg_now = gg_now + geom_boxplot(width=0.05,fill=&quot;grey23&quot;,colour=&quot;white&quot;,outlier.shape=NA,show.legend = FALSE)
         gg_now = gg_now + geom_text( data        = TraitTukey
                                    , mapping     = aes(x=x,y=y,label=labels)
                                    , hjust       = 0.5
                                    , vjust       = 1
                                    , family      = &quot;Helvetica&quot;
                                    , size        = 0.5 * gg_ptsz
                                    , inherit.aes = FALSE
                                    )#end geom_text
         gg_now = gg_now + ggtitle(TraitDesc)
         gg_now = gg_now + xlab(element_blank())
         gg_now = gg_now + ylab(desc.unit(desc=NULL,unit=untab[[TraitUnit]],twolines=FALSE))
         gg_now = gg_now + theme_grey( base_size = gg_ptsz, base_family = &quot;Helvetica&quot;,base_line_size = 0.5,base_rect_size =0.5)
         gg_now = gg_now + theme( axis.text.x = element_text( size   = gg_ptsz
                                                            , margin = unit(rep(0.10,times=4),&quot;cm&quot;)
                                                            , angle  = 30
                                                            , hjust  = 1
                                                            , vjust  = 1
                                                            )#end element_text
                                , axis.text.y       = element_text( size   = gg_ptsz
                                                                  , margin = unit(rep(0.35,times=4),&quot;cm&quot;)
                                                                  )#end element_text
                                , axis.title.y      = element_text( size = gg_ptsz)
                                , plot.title        = element_text( size = gg_ptsz)
                                , axis.ticks.length = unit(-0.25,&quot;cm&quot;)
                                )#end theme
         
         # Save plots.
         DeviceLoop = sequence(ndevice)
         for (d in DeviceLoop){
            h_output = paste0(&quot;Violin-&quot;,CategName,&quot;-&quot;,TraitName,&quot;-&quot;,base_suffix,&quot;.&quot;,gg_device[d])
            dummy    = ggsave( filename = h_output
                             , plot     = gg_now
                             , device   = gg_device[d]
                             , path     = violin_path
                             , units    = gg_units
                             , dpi      = gg_square
                             , width    = gg_square
                             , height   = gg_height
                             )#end ggsave
         }#end for (d in device_loop)
         
         # Copy gg information to the list
         gg_name = paste0(CategName,&quot;_&quot;,TraitName)
         gg_violin[[gg_name]] = gg_now
      }#end if (t_plot)
   }#end for (tr in sequence(n_trait))
}# for (z in sequence(CntCategList))

# If sought, plot images on screen
cnt_gg_violin = length(gg_violin)
if (gg_screen &amp;&amp; (cnt_gg_violin %gt% 0L)){
   gg_show = sort(sample.int(n=cnt_gg_violin,size=min(cnt_gg_violin,3L),replace=FALSE))
   gg_violin[gg_show]
}#end if (gg_screen &amp;&amp; (length(gg_violin) %gt% 0L))</code></pre>
</div>
<div id="gap-statistics-and-silhouette-plots" class="section level2">
<h2>Gap statistics and silhouette plots</h2>
<p>Here we plot the gap statistics and silhouette plots, which are
helpful for defining the ideal number of clusters.</p>
<pre class="r"><code>if (plot_stat_cluster){
   cat0(&quot; + Plot optimal cluster analysis diagrams.&quot;)

   # Initialise list with GGPlots
   gg_see = list()
   
   # Create metrics for error plots
   InfoPlot = ClusterInfo %&gt;%
      mutate( gap_lwr = gap - gapSE
            , gap_upr = gap + gapSE
            )#end mutate

   # Retrieve the optimal number of clusters for each method.
   k_opt_sil = length(ClusterOpt$sil$medoids)
   k_opt_gap = length(ClusterOpt$gap$medoids)

   InfoSil = InfoPlot        %&gt;% 
      filter(k==k_opt_sil)   %&gt;%
      mutate(Label=paste0(&quot;k[O*p*t]==&quot;,k_opt_sil))
   InfoGap = InfoPlot        %&gt;% 
      filter(k==k_opt_gap)   %&gt;%
      mutate(Label=paste0(&quot;k[O*p*t]==&quot;,k_opt_gap))

   # First, we plot the silhouette score
   cat0(&quot;   - Silhouette score.&quot;)
   gg_sil = ggplot(data=InfoPlot,aes(x=k,y=sil_width))
   gg_sil = gg_sil + geom_line(colour=&quot;#3A6FB0&quot;,size=1.2)
   gg_sil = gg_sil + geom_point(shape=16L,colour=&quot;#3A6FB0&quot;,size=2.0)
   gg_sil = gg_sil + geom_point( data        = InfoSil
                               , mapping     = aes(x=k,y=sil_width)
                               , shape       = 15L
                               , colour      = &quot;#C53F2D&quot;
                               , size        = 3.0
                               , inherit.aes = FALSE
                               )#end geom_point
   gg_sil = gg_sil + geom_text( data        = InfoSil
                              , mapping     = aes(x=k,y=sil_width,label=Label)
                              , colour      = &quot;#C53F2D&quot;
                              , hjust       = -0.1
                              , vjust       =  1.1
                              , family      = &quot;Helvetica&quot;
                              , parse       = TRUE
                              , size        = 0.25 * gg_ptsz
                              , inherit.aes = FALSE
                              )#end geom_text
   gg_sil = gg_sil + labs( title    = &quot;Silhouette analysis&quot;
                         , subtitle = &quot;Optimal number (red) is the maximum score&quot;
                         , x        = &quot;Number of clusters&quot;
                         , y        = &quot;Silhouette score&quot;
                         )#end labs
   gg_sil = gg_sil + theme_grey( base_size = gg_ptsz, base_family = &quot;Helvetica&quot;,base_line_size = 0.5,base_rect_size =0.5)
   gg_sil = gg_sil + theme( axis.text.x = element_text( size   = gg_ptsz
                                                      , margin = unit(rep(0.35,times=4),&quot;cm&quot;)
                                                      )#end element_text
                          , axis.text.y       = element_text( size   = gg_ptsz
                                                            , margin = unit(rep(0.35,times=4),&quot;cm&quot;)
                                                            )#end element_text
                          , axis.title.y      = element_text( size = gg_ptsz)
                          , plot.title        = element_text( size = gg_ptsz)
                          , plot.subtitle     = element_text( size = 0.7*gg_ptsz)
                          , axis.ticks.length = unit(-0.25,&quot;cm&quot;)
                          )#end theme

   # Copy the plot to the list
   gg_see$sil = gg_sil

   # Save plot in every format requested.
   for (d in sequence(ndevice)){
      f_output = paste0(&quot;Silhouette_&quot;,base_suffix,&quot;.&quot;,gg_device[d])
      dummy    = ggsave( filename = f_output
                       , plot     = gg_sil
                       , device   = gg_device[d]
                       , path     = trpca_path
                       , width    = gg_width
                       , height   = gg_height
                       , units    = gg_units
                       , dpi      = gg_depth
                       )#end ggsave
   }#end for (o in sequence(nout))



   # First, we plot the gap statistics
   cat0(&quot;   - Gap statistics.&quot;)
   gg_gap = ggplot(data=InfoPlot,aes(x=k,y=gap,ymin=gap_lwr,ymax=gap_upr))
   gg_gap = gg_gap + geom_line(colour=&quot;#3A6FB0&quot;,size=0.75)
   gg_gap = gg_gap + geom_point(shape=16L,colour=&quot;#3A6FB0&quot;,size=2.0)
   gg_gap = gg_gap + geom_errorbar(colour=&quot;#3A6FB0&quot;,linewidth=0.75,width=1./6.)
   gg_gap = gg_gap + geom_point( data        = InfoGap
                               , mapping     = aes(x=k,y=gap)
                               , shape       = 15L
                               , colour      = &quot;#C53F2D&quot;
                               , size        = 3.0
                               , inherit.aes = FALSE
                               )#end geom_point
   gg_gap = gg_gap + geom_errorbar( data        = InfoGap
                                  , mapping     = aes(x=k,ymin=gap_lwr,ymax=gap_upr)
                                  , colour      = &quot;#C53F2D&quot;
                                  , linewidth   = 0.75
                                  , width       = 1./6.
                                  , inherit.aes = FALSE
                                  )#end geom_point
   gg_gap = gg_gap + geom_text( data        = InfoGap
                              , mapping     = aes(x=k,y=gap,label=Label)
                              , colour      = &quot;#C53F2D&quot;
                              , hjust       = -0.1
                              , vjust       = -0.1
                              , family      = &quot;Helvetica&quot;
                              , parse       = TRUE
                              , size        = 0.25 * gg_ptsz
                              , inherit.aes = FALSE
                              )#end geom_text
   gg_gap = gg_gap + labs( title    = &quot;Gap analysis&quot;
                         , subtitle = &quot;Optimal number (red) based on first maximum above SE&quot;
                         , x        = &quot;Number of clusters&quot;
                         , y        = &quot;Gap Statistic&quot;
                         )#end labs
   gg_gap = gg_gap + theme_grey( base_size = gg_ptsz, base_family = &quot;Helvetica&quot;,base_line_size = 0.5,base_rect_size =0.5)
   gg_gap = gg_gap + theme( axis.text.x = element_text( size   = gg_ptsz
                                                      , margin = unit(rep(0.35,times=4),&quot;cm&quot;)
                                                      )#end element_text
                          , axis.text.y       = element_text( size   = gg_ptsz
                                                            , margin = unit(rep(0.35,times=4),&quot;cm&quot;)
                                                            )#end element_text
                          , axis.title.y      = element_text( size = gg_ptsz)
                          , plot.title        = element_text( size = gg_ptsz)
                          , plot.subtitle     = element_text( size = 0.7*gg_ptsz)
                          , axis.ticks.length = unit(-0.25,&quot;cm&quot;)
                          )#end theme

   # Copy the plot to the list
   gg_see$gap = gg_gap

   # Save plot in every format requested.
   for (d in sequence(ndevice)){
      f_output = paste0(&quot;GapStatistic&quot;,base_suffix,&quot;.&quot;,gg_device[d])
      dummy    = ggsave( filename = f_output
                       , plot     = gg_gap
                       , device   = gg_device[d]
                       , path     = trpca_path
                       , width    = gg_square
                       , height   = gg_square
                       , units    = gg_units
                       , dpi      = gg_depth
                       )#end ggsave
   }#end for (o in sequence(nout))

   if (gg_screen) gg_see

}#end if (plot_stat_cluster)</code></pre>
<p><img src="TraitTradeOffs_files/figure-html/try-gap-statistics-1.png" width="768" /><img src="TraitTradeOffs_files/figure-html/try-gap-statistics-2.png" width="768" /></p>
</div>
<div id="weighting-factors-for-cluster-analysis" class="section level2">
<h2>Weighting factors for cluster analysis</h2>
<p>Here we plot the gap statistics and silhouette plots, which are
helpful for defining the ideal number of clusters.</p>
<pre class="r"><code>if (plot_wgt_cluster){
   cat0(&quot; + Plot weighting factors for cluster analysis.&quot;)

   # Arrange data set for showing weights
   WeightTRY = DataInfo %&gt;% 
      arrange(Weight) %&gt;%
      mutate( TraitID = try_trait$TraitID[match(Name,try_trait$Name)]
            , Desc    = try_trait$Desc[match(Name,try_trait$Name)]
            , Desc    = ifelse(test = Name %in% &quot;ScientificName&quot;  ,yes=&quot;Species&quot;,no=Desc)
            , Desc    = ifelse(test = Name %in% &quot;Genus&quot;           ,yes=&quot;Genus&quot;,no=Desc)
            , Desc    = ifelse(test = Name %in% &quot;Family&quot;          ,yes=&quot;Family&quot;,no=Desc)
            , Desc    = ifelse(test = Name %in% &quot;Order&quot;           ,yes=&quot;Order (Taxonomy)&quot; ,no=Desc)
            , Desc    = ifelse(test = Name %in% &quot;Class&quot;           ,yes=&quot;Class (Taxonomy)&quot; ,no=Desc)
            , Desc    = ifelse(test = Name %in% &quot;Phylum&quot;          ,yes=&quot;Phylum&quot; ,no=Desc)
            , Desc    = factor(Desc,levels=Desc)
            , Type    = ifelse(test = Type %in% c(&quot;factor&quot;   ), yes = &quot;categorical&quot;, no = Type)
            , Type    = ifelse(test = Type %in% c(&quot;character&quot;), yes = &quot;categorical&quot;, no = Type)
            , Type    = ifelse(test = Type %in% c(&quot;integer&quot;  ), yes = &quot;ordered&quot;    , no = Type)
            , Type    = str_to_sentence(Type)
            , Type    = factor(Type,levels=sort(unique(Type))))

   CntTypes = nlevels(WeightTRY$Type)
   colTypes = RColorBrewer::brewer.pal(n=max(3L,CntTypes),name=&quot;Paired&quot;)[sequence(CntTypes)]
   names(colTypes) = levels(WeightTRY$Type)




   # First, we plot the gap statistics
   gg_wgt = ggplot(data=WeightTRY,aes(x=Weight,y=Desc,colour=Type,fill=Type))
   gg_wgt = gg_wgt + geom_col(width=0.8)
   gg_wgt = gg_wgt + scale_fill_manual(values=colTypes)
   gg_wgt = gg_wgt + scale_colour_manual(values=colTypes)
   gg_wgt = gg_wgt + labs( title    = &quot;Dissimilarity matrix weights&quot;
                         , subtitle = &quot;Weigths relative to maximum&quot;
                         , x        = element_blank()
                         , y        = element_blank()
                         )#end labs
   gg_wgt = gg_wgt + theme_grey( base_size = gg_ptsz, base_family = &quot;Helvetica&quot;,base_line_size = 0.5,base_rect_size =0.5)
   gg_wgt = gg_wgt + theme( axis.text.x = element_text( size   = gg_ptsz
                                                      , margin = unit(rep(0.35,times=4),&quot;cm&quot;)
                                                      )#end element_text
                          , axis.text.y       = element_text( size   = 0.7*gg_ptsz
                                                            , margin = unit(rep(0.35,times=4),&quot;cm&quot;)
                                                            )#end element_text
                          , axis.title.y      = element_text( size = 0.8*gg_ptsz)
                          , plot.title        = element_text( size = 0.8*gg_ptsz)
                          , plot.subtitle     = element_text( size = 0.6*gg_ptsz)
                          , axis.ticks.length = unit(-0.25,&quot;cm&quot;)
                          , legend.position   = &quot;bottom&quot;
                          , legend.direction  = &quot;horizontal&quot;
                          )#end theme

   # Save plot in every format requested.
   for (d in sequence(ndevice)){
      f_output = paste0(&quot;WeightCluster&quot;,base_suffix,&quot;.&quot;,gg_device[d])
      dummy    = ggsave( filename = f_output
                       , plot     = gg_wgt
                       , device   = gg_device[d]
                       , path     = trpca_path
                       , width    = gg_square
                       , height   = gg_square
                       , units    = gg_units
                       , dpi      = gg_depth
                       )#end ggsave
   }#end for (o in sequence(nout))

   if (gg_screen) gg_wgt
}#end if (plot_wgt_cluster)</code></pre>
<p><img src="TraitTradeOffs_files/figure-html/try-weight-cluster-1.png" width="768" /></p>
</div>
<div id="principal-component-analysis-with-numeric-traits"
class="section level2">
<h2>Principal component analysis with numeric traits</h2>
<p>Here we run a principal component analysis (PCA) with the traits that
are numeric. PCA requires complete data sets, so we must run an
imputation approach first. Mind that imputation works best when only a
small fraction of the data points is missing. It is very unlikely that
this assumption will hold valid at regional or global scale in the
tropics.</p>
<pre class="r"><code>cat0(&quot; + Run the principal component analysis.&quot;)
selTrait  = (try_trait$Type %in% &quot;numeric&quot;) &amp; try_trait$Cluster &amp; (try_trait$Name %in% names(ClusterTRY))
TraitUse  = names(ClusterTRY)[names(ClusterTRY)   %in% try_trait$Name[selTrait]]
TraitSkip = names(ClusterTRY)[! names(ClusterTRY) %in% TraitUse]
WhichUse  = match(TraitUse,try_trait$Name)
DataUse   = ClusterTRY %&gt;% select_at(all_of(TraitUse ))
DataSkip  = ClusterTRY %&gt;% select_at(all_of(TraitSkip))



# Find the number of sub-classes to test the model
CategPCA  = CategInfo %&gt;%
   filter((XYUse %in% &quot;Colour&quot;) &amp; (! duplicated(Class)))
CntCategPCA = nrow(CategPCA)+1L

# Transform variables ahead of the PCA
cat0(&quot;   - Transform variables prior to running the PCA.&quot;)
for (v in WhichUse){
   # Handy aliases
   vName   = try_trait$Name      [v]
   vDesc   = try_trait$Desc      [v]
   z       = which(GlobDistr$x %in% vName)
   zDistr  = GlobDistr$Distrib[z]
   zFirst  = GlobDistr$First  [z]
   zSecond = GlobDistr$Second [z]
   zThird  = GlobDistr$Third  [z]
   
   # Pick cumulative distribution function according to the distribution.
   zFun = switch( zDistr
                , &quot;uniform&quot;       = punif
                , &quot;normal&quot;        = pnorm
                , &quot;logistic&quot;      = plogis
                , &quot;skew-normal&quot;   = sn::psn
                , &quot;log-normal&quot;    = plnorm
                , &quot;neglog-normal&quot; = pnlnorm
                , &quot;weibull&quot;       = pweibull
                , &quot;gamma&quot;         = pgamma
                , NA_character_
                )#end switch
   # Decide whether the distribution needs two or three parameters
   if (zDistr %in% &quot;skew-normal&quot;){
      p_vName = zFun(ClusterTRY[[vName]],zFirst,zSecond,zThird)
   }else if (! is.na(zDistr)){
      p_vName = zFun(ClusterTRY[[vName]],zFirst,zSecond)
   }#end if (zDistr %in% &quot;skew-normal&quot;)
      
   # Find the normal distribution equivalent of the value
   DataUse[[vName]] = qnorm(p=p_vName,mean=0.,sd=1.)
   DataUse[[vName]] = ifelse( test = is.finite(DataUse[[vName]])
                            , yes  = DataUse[[vName]]
                            , no   = NA_real_
                            )#end ifelse
}#end for  (z in WhichUse)

# Select data with a sufficient number of data sets
SampUse = DataUse %&gt;%
   summarise(across(everything(), ~ sum(is.finite(.x))))
SdevUse = DataUse %&gt;%
   summarise(across(everything(), ~ sd(.x,na.rm=TRUE)))
SampUse = names(SampUse)[SampUse %ge% n_pca_min]
SdevUse = names(SdevUse)[SdevUse %ge% 0.       ]
KeepUse = intersect(SampUse,SdevUse)

# Keep columns with data
DataUse = DataUse %&gt;%
   select_at(vars(KeepUse))

# Remove rows without valid data
ValidUse = apply(X=DataUse,MARGIN=1,FUN=function(x) all(is.finite(x)))
DataUse  = DataUse [ValidUse,,drop=FALSE]
DataSkip = DataSkip[ValidUse,,drop=FALSE]


# Run principal component analysis
DataPCA = DataUse %&gt;%
   scale() %&gt;%
   prcomp()

# Expand the imputed data to include categorical variables
DataUse = as_tibble(cbind(DataUse,DataSkip))

# Decide whether to plot 
pca_cluster_loop = if(plot_pca_cluster){sequence(4L)}else{sequence(0L)}

gg_pca = list()
for (cc in pca_cluster_loop){
   # Set categories for the PCA points
   zTrait            = unique(CategPCA$TraitID[! is.na(CategPCA$TraitID)])
   z                 = match(zTrait,try_trait$TraitID)
   zName             = try_trait$Name   [z]
   zDesc             = try_trait$Desc   [z]
   zUniq             = CategPCA$Class
   zSize             = length(zUniq)
   pchClasses        = CategPCA$Symbol
   names(pchClasses) = CategPCA$Class

   if (cc %in% 1L){
      # Use categories for colours as well
      cName             = zName
      cDesc             = zDesc
      cUniq             = zUniq
      cSize             = zSize
      colClasses        = CategPCA$Colour
      names(colClasses) = CategPCA$Class
   }else{
      # Use clusters
      cType             = c(&quot;gap&quot;,&quot;sil&quot;,&quot;fix&quot;)[cc-1L]
      cName             = paste0(&quot;cluster_&quot;,cType)
      cDesc             = paste0(&quot;Clustered PFT: &quot;,c(&quot;Gap statistic&quot;,&quot;Silhouette&quot;,&quot;Fixed&quot;))[cc-1L]
      if ( ( cType == cluster_method ) &amp;&amp; ( &quot;CategCluster&quot; %in% ls(envir=.GlobalEnv) ) ){
         DataUse[[cName]]  = factor(x=as.character(DataUse[[cName]]),levels=CategCluster$TRYClass)
         cUniq             = CategCluster$TRYClass
         cSize             = nrow(CategCluster)
         colClasses        = CategCluster$Colour
         names(colClasses) = CategCluster$TRYClass
      }else{
         cUniq             = levels(DataUse[[cName]])
         cSize             = nlevels(DataUse[[cName]])
         cPalette          = if(cSize %gt% 6L){&quot;Paired&quot;}else{&quot;Dark2&quot;}
         colClasses        = RColorBrewer::brewer.pal(n=cSize,name=cPalette)
         names(colClasses) = cUniq
      }#end if ( ( cType == cluster_method ) &amp;&amp; ( &quot;CategCluster&quot; %in% ls(envir=.GlobalEnv) ) )
   }#end if (cc %in% 1L)
   zTitle = paste0(&quot;PCA points by &quot;,tolower(cDesc))

   # Set the PCA plot
   gg_now = autoplot( object                = DataPCA
                    , data                  = DataUse
                    , colour                = cName
                    , shape                 = zName
                    , size                  = 1.0
                    , loadings              = TRUE
                    , loadings.colour       = &quot;grey40&quot;
                    , loadings.label        = c(FALSE,TRUE)[2L]
                    , loadings.label.size   = 4
                    , loadings.label.colour = &quot;black&quot;
                    , loadings.label.family = &quot;Helvetica&quot;
                    )#end autoplot
   gg_now = gg_now + scale_colour_manual  (values=colClasses,name=NULL)
   gg_now = gg_now + scale_shape_manual   (values=pchClasses,name=NULL)
   gg_now = gg_now + labs( title    = zTitle, subtitle = LabelSubtitle)
   gg_now = gg_now + theme_grey( base_size = gg_ptsz, base_family = &quot;Helvetica&quot;,base_line_size = 0.5,base_rect_size =0.5)
   gg_now = gg_now + theme( axis.text.x       = element_text( size = gg_ptsz, margin = unit(rep(0.35,times=4),&quot;cm&quot;))
                          , axis.text.y       = element_text( size = gg_ptsz, margin = unit(rep(0.35,times=4),&quot;cm&quot;))
                          , plot.title        = element_text( size = gg_ptsz)
                          , plot.subtitle     = element_text( size = 0.7*gg_ptsz)
                          , axis.ticks.length = unit(-0.25,&quot;cm&quot;)
                          , legend.position   = &quot;bottom&quot;
                          , legend.direction  = &quot;horizontal&quot;
                          )#end theme
   gg_now = gg_now + guides(colour=guide_legend(nrow=cSize),shape=guide_legend(nrow=zSize))
   # Save plot in every format requested.
   for (d in sequence(ndevice)){
      f_output = paste0(&quot;PCAPlot_&quot;,cName,&quot;_&quot;,base_suffix,&quot;.&quot;,gg_device[d])
      dummy    = ggsave( filename = f_output
                       , plot     = gg_now
                       , device   = gg_device[d]
                       , path     = trpca_path
                       , width    = gg_square
                       , height   = gg_square
                       , units    = gg_units
                       , dpi      = gg_depth
                       )#end ggsave
   }#end for (o in sequence(nout))
   
   # Append plot to the list
   gg_pca[[cName]] = gg_now
}#end for (cc in sequence(4L))


# Show plots
if (length(gg_pca) %gt% 0L &amp; gg_screen) gg_pca</code></pre>
<p><img src="TraitTradeOffs_files/figure-html/try-set-princomp-1.png" width="768" /><img src="TraitTradeOffs_files/figure-html/try-set-princomp-2.png" width="768" /><img src="TraitTradeOffs_files/figure-html/try-set-princomp-3.png" width="768" /><img src="TraitTradeOffs_files/figure-html/try-set-princomp-4.png" width="768" /></p>
</div>
<div id="plot-the-medoid-of-all-variables-used-in-the-cluster-analysis"
class="section level2">
<h2>Plot the medoid of all variables used in the cluster analysis</h2>
<p>Here we plot the medoid of each cluster for all traits included as a
radial plot, which is obtained by finding the equivalent value of the
CDF for each trait.</p>
<pre class="r"><code>if (plot_radar_cluster){
   cat0(&quot; + Plot radar plot for medoids.&quot;)
   # Retrieve medoid values and select traits that are numeric and have a global distribution.
   HasDistrib = names(MedoidTRY)[names(MedoidTRY) %in% GlobDistr$x   ]
   IsTrait    = names(MedoidTRY)[names(MedoidTRY) %in% try_trait$Name]
   NormalLoop = sort(intersect(HasDistrib,IsTrait))
   KeepMedoid = unique(c(&quot;Cluster&quot;,NormalLoop))
   
      
   RadarTRY = MedoidTRY %&gt;%
      select(all_of(KeepMedoid))

   # Loop through the numeric variables and find the CDF.
   for (v in seq_along(NormalLoop)){
      # Retrieve information for this variable
      vName   = NormalLoop[v]
      vIndex  = match(vName,GlobDistr$x)
      vDistr  = GlobDistr$Distrib[vIndex]
      vFirst  = GlobDistr$First  [vIndex]
      vSecond = GlobDistr$Second [vIndex]
      vThird  = GlobDistr$Third  [vIndex]

      # Fit the cumulative density function according to the distribution.
      vFun = switch( vDistr
                   , &quot;uniform&quot;       = punif
                   , &quot;normal&quot;        = pnorm
                   , &quot;logistic&quot;      = plogis
                   , &quot;skew-normal&quot;   = sn::psn
                   , &quot;log-normal&quot;    = plnorm
                   , &quot;neglog-normal&quot; = pnlnorm
                   , &quot;weibull&quot;       = pweibull
                   , &quot;gamma&quot;         = pgamma
                   , NA_character_
                   )#end switch

      # Decide whether the distribution needs two or three parameters
      if (vDistr %in% &quot;skew-normal&quot;){
         RadarTRY[[vName]] = vFun(RadarTRY[[vName]],vFirst,vSecond,vThird)
      }else if (! is.na(zDistr)){
         RadarTRY[[vName]] = vFun(RadarTRY[[vName]],vFirst,vSecond)
      }#end if (zDistr %in% &quot;skew-normal&quot;)

      # Delete NaN values
      RadarTRY[[vName]] = ifelse( test = is.finite(RadarTRY[[vName]])
                                , yes  = RadarTRY[[vName]]
                                , no   = NA_real_
                                )#end ifelse
   }#end for (v in seq_along(NormalLoop))

   # Create a table abbreviations
   NormalAbbr        = letters[seq_along(NormalLoop)]
   names(NormalAbbr) = NormalLoop

   # List of classes for ordering the clusters. We add &quot;All&quot; as a dummy cluster
   CategUse   = CategExtra %&gt;% filter((TraitID %in% 0) | (Class %in% &quot;ALL&quot;))
   orderCateg = c(nrow(CategUse),sequence(nrow(CategUse)-1L))
   CategUse   = CategUse[orderCateg,]

   # Append a column with all, which will be used as a legend
   AppendTRY = RadarTRY[1L,,drop=FALSE] %&gt;%
      mutate( across(where(is.numeric), ~ NA_real_ * .x)
            , Cluster = CategUse$Class[1L])

   RadarTRY = rbind(AppendTRY,RadarTRY)
   

   
   # Reshape RadarTRY so the variables become a categorical variable
   RadarPlot = RadarTRY %&gt;%
      pivot_longer(all_of(NormalLoop),names_to=&quot;Variable&quot;,values_to=&quot;CumDistr&quot;) %&gt;%
      mutate( Cluster  = factor(x=Cluster,levels=CategUse$Class)
            , Variable = factor(x=Variable,levels=NormalLoop,labels=NormalAbbr) )


   
   
   gg_radar = ggplot( data = RadarPlot, mapping = aes(x=Variable,y=CumDistr,group=Cluster) )
   gg_radar = gg_radar + facet_wrap( ~Cluster, nrow=2L)
   gg_radar = gg_radar + geom_polygon(colour=&quot;#1F78B4&quot;,fill=&quot;#A6CEE3&quot;,alpha=0.7,linewidth=I(1.2))
   gg_radar = gg_radar + geom_hline(yintercept=c(0.25,0.5,0.75),colour=&quot;black&quot;,linetype=&quot;dotted&quot;,linewidth=I(0.3))
   gg_radar = gg_radar + geom_hline(yintercept=c(1.0),colour=&quot;black&quot;,linetype=&quot;solid&quot;,linewidth=I(0.3))
   gg_radar = gg_radar + scale_y_continuous(limits=c(0.,1.0),breaks=c(0.,0.25,0.5,0.75,1.0))
   gg_radar = gg_radar + coord_curvedpolar()
   
   gg_radar = gg_radar + labs( x        = element_blank()
                             , y        = element_blank()
                             , title    = &quot;Relative traits for the cluster medoids&quot;
                             , subtitle = LabelSubtitle
                             )#end labs
   gg_radar = gg_radar + theme_grey( base_size = gg_ptsz, base_family = &quot;Helvetica&quot;,base_line_size = 0.5,base_rect_size =0.5)
   gg_radar = gg_radar + theme( axis.text.x       = element_text( size = gg_ptsz, margin = unit(rep(0.35,times=4),&quot;cm&quot;))
                              , axis.text.y       = element_blank()
                              , axis.ticks.y      = element_blank()
                              , plot.title        = element_text( size = gg_ptsz)
                              , plot.subtitle     = element_text( size = 0.7*gg_ptsz)
                              , axis.ticks.length = unit(-0.25,&quot;cm&quot;)
                              , legend.position   = &quot;bottom&quot;
                              , legend.direction  = &quot;horizontal&quot;
                              )#end theme
   # Save plot in every format requested.
   for (d in sequence(ndevice)){
      f_output = paste0(&quot;RadarPlot_Faceted_&quot;,base_suffix,&quot;.&quot;,gg_device[d])
      dummy = ggsave( filename = f_output
                    , plot     = gg_radar
                    , device   = gg_device[d]
                    , path     = trpca_path
                    , width    = gg_width
                    , height   = gg_height
                    , units    = gg_units
                    , dpi      = gg_depth
                    )#end ggsave
   }#end for (o in sequence(nout))

   # If sought, plot images on screen
   if (gg_screen) gg_radar
}#end if (plot_radar_cluster)</code></pre>
<p><img src="TraitTradeOffs_files/figure-html/plot-medoid-radar-1.png" width="768" /></p>
</div>
<div id="plot-trait-trade-off-relationships" class="section level2">
<h2>Plot trait trade-off relationships</h2>
<p>In this part, we plot the standardised major axis fit for all trait
pairs, accounting for trait variation flagged as “colour”, in addition
to the trade-offs distinguished by data-based clusters.</p>
<pre class="r"><code># Select reference data set for trade-off analysis
DataTRY = switch( EXPR       = fit_taxon
                , Individual = TidyTRY
                , Species    = SpeciesTRY
                , Genus      = GenusTRY
                , stop(&quot;Invalid settings for variable \&quot;fit_taxon\&quot;.&quot;)
                )#end switch

# Load settings for the x axis.
x      = xsma_idx
xTrait = try_trait$TraitID[x]
xName  = try_trait$Name   [x]
xDesc  = try_trait$Desc   [x]
xUnit  = try_trait$Unit   [x]
xTrans = try_trait$Trans  [x]
xTPlot = switch( EXPR = xTrans, log = &quot;log10&quot;, neglog=&quot;neglog10&quot;,xTrans)

# Select valid data for the y axis
xSel = switch( EXPR     = xTrans
             , identity = is.finite(DataTRY[[xName]])
             , log      = DataTRY[[xName]] %gt% 0.
             , neglog   = DataTRY[[xName]] %lt% 0.
             , sqrt     = DataTRY[[xName]] %ge% 0.
             , cbrt     = is.finite(DataTRY[[xName]])
             , stop(paste0(&quot; Invalid transformation for trait &quot;,xName,&quot; (TraitID = &quot;,xTrait,&quot;).&quot;))
             )#end switch


   
# Find out how many SMA fits we will seek
yPlotSMA = which(try_trait$SMA &amp; (! (try_trait$Name %in% xName)))
CntSMA   = length(yPlotSMA)


# Initialise the list of plots
gg_SMA = list()

# Find the number of traits for plotting the model
CategSel    = is.finite(CategSMA$TraitID) &amp; plot_sma_trait
CategTrait  = sort(unique(CategSMA$TraitID[CategSel]))
for (ct in seq_along(CategTrait)){
   # Load settings for the classes.
   zTrait = CategTrait[ct]
   if (zTrait %in% 0L){
      zName  = &quot;Cluster&quot;
      zDesc  = &quot;Data-based cluster class&quot;
   }else{
      z      = match(zTrait,try_trait$TraitID)
      zName  = try_trait$Name   [z]
      zDesc  = try_trait$Desc   [z]
   }#end if (zTrait %in% 0L)
   zTitle = paste0(&quot;SMA model by &quot;,tolower(zDesc))

   # Set path for this group of plots.
   categ_trsma_path = file.path(trsma_path,zName)
   
      
   # Select categories for this trait type.
   CategNow = CategExtra %&gt;%
      filter( (TraitID %in% zTrait) | is.na(TraitID)) %&gt;%
      filter((! duplicated(Class)))

   CntCategNow = nrow(CategNow)


   # Loop through the SMA variables
   for (y in sequence(CntSMA)){
      # Load settings for the y axis.
      yIndex = yPlotSMA[y]
      yTrait = try_trait$TraitID[yIndex]
      yName  = try_trait$Name   [yIndex]
      yLower = paste0(yName,&quot;_Lower&quot;)
      yUpper = paste0(yName,&quot;_Upper&quot;)
      yDesc  = try_trait$Desc   [yIndex]
      yUnit  = try_trait$Unit   [yIndex]
      yTrans = try_trait$Trans  [yIndex]
      yTPlot = switch( EXPR = yTrans, log = &quot;log10&quot;, neglog=&quot;neglog10&quot;,yTrans)
      
      # Select valid data for the y axis
      ySel = switch( EXPR     = yTrans
                   , identity = is.finite(DataTRY[[yName]])
                   , log      = DataTRY[[yName]] %gt% 0.
                   , neglog   = DataTRY[[yName]] %lt% 0.
                   , sqrt     = DataTRY[[yName]] %ge% 0.
                   , cbrt     = is.finite(DataTRY[[yName]])
                   , stop(paste0(&quot; Invalid transformation for trait &quot;,yName,&quot; (TraitID = &quot;,yTrait,&quot;).&quot;))
                   )#end switch

      # Subset data 
      DataPlot = DataTRY %&gt;%
         filter(xSel &amp; ySel) %&gt;%
         select_at(vars(c(xName,yName,zName))) %&gt;%
         mutate_at( vars(c(zName)), ~ifelse(.x %in% CategNow$Class,.x,&quot;UKN&quot;)) %&gt;%
         mutate_at( vars(c(zName)), ~factor(.x,levels=CategNow$Class))
      PlotSMA  = nrow(DataPlot) %ge% n_fit_min

      # Append dummy data with category ALL so legends can be merged.
      DataDummy = DataPlot[rep(1L,times=CntCategNow),,drop=FALSE] %&gt;%
         mutate(across(c(xName,yName), ~ c(NA_real_))) %&gt;%
         mutate(across(c(zName), ~ factor(CategNow$Class,levels=CategNow$Class) ) )
      DataPlot    = rbind(DataPlot,DataDummy)
      CntDataPlot = nrow(DataPlot)

      # Plot only the variables with meaningful data
      if (PlotSMA){
         cat0(&quot; + Plot the trait trade-offs (and SMA fits) for &quot;,yDesc,&quot;, by &quot;,zDesc,&quot;.&quot;)

         
         # Set path for this group of plots.
         dummy = dir.create(categ_trsma_path,recursive=TRUE,showWarnings=FALSE)
 

         # Find limits for plots.   
         xLimit = range(DataPlot[[xName]],finite=TRUE)
         yLimit = range(DataPlot[[yName]],finite=TRUE)
         
         
         # Subset predicted data, so the range is consistent with the subset data:
         pSel     = ( ( (PredSMA[[xName]] %wr% xLimit) | is.na(PredSMA[[xName]]) )
                    &amp; ( (PredSMA[[yName]] %wr% yLimit) | is.na(PredSMA[[yName]]) )
                    &amp; (PredSMA$TraitClass %in% c(&quot;All&quot;,&quot;Unknown&quot;,zName)) )
         PredPlot = PredSMA %&gt;% 
            filter(pSel)    %&gt;%
            mutate(Class = factor(Class,levels = CategNow$Class)) %&gt;%
            rename_at( vars(c(&quot;Class&quot;)), ~ c(zName)) %&gt;%
            select_at(vars(c(xName,yName,zName)))
         PlotFit  = any(is.finite(PredPlot[[yName]]))

         
         # Subset SMA summary   
         InfoPlot = InfoSMA %&gt;%
            filter( (x %in% xName) &amp; (y %in% yName) &amp; ( TraitClass %in% c(&quot;All&quot;,zName) ) ) %&gt;%
            select( ! TraitClass) %&gt;%
            rename_at( vars(c(&quot;Class&quot;)), ~ c(zName)) %&gt;%
            add_row(&quot;{zName}&quot; := &quot;UKN&quot;) %&gt;%
            mutate( across(c(zName), ~ factor(.x,levels = CategNow$Class))) %&gt;%
            mutate( across(c(&quot;x&quot;,&quot;y&quot;,&quot;xTrans&quot;,&quot;yTrans&quot;), ~ ifelse(test=is.na(.x),yes=commonest(.x,na.rm=TRUE),no=.x))
                  , N      = ifelse(test=is.na(N),yes=0L,no=N)
                  , Line   = cut(pValue,breaks=c(0,0.001,0.01,0.05,0.10,1),labels=FALSE)
                  , Line   = ifelse( test = is.na(Line)
                                   , yes  = &quot;blank&quot;
                                   , no   = c(&quot;solid&quot;,&quot;dotdash&quot;,&quot;dashed&quot;,&quot;dotted&quot;,&quot;blank&quot;)[Line]
                                   )#end ifelse
                  )#end mutate
         
         # Set categories for colours, lines and symbols
         colClasses        = CategNow$Colour
         names(colClasses) = CategNow$Class
         pchClasses        = CategNow$Symbol
         names(pchClasses) = CategNow$Class
         ltyClasses        = InfoPlot$Line
         names(ltyClasses) = InfoPlot[[zName]]
         ltyClasses        = ltyClasses[match(names(pchClasses),names(ltyClasses))]
         
         
         # Build the plot
         gg_now = ggplot()
         gg_now = gg_now + geom_point(data=DataPlot,aes_string(x=xName,y=yName,colour=zName,shape=zName),size=1.9)
         gg_now = gg_now + scale_colour_manual  (values=colClasses)
         gg_now = gg_now + scale_shape_manual   (values=pchClasses)
         if (PlotFit){
            #gg_now = gg_now + geom_ribbon(data=PredPlot,aes_string(x=xName,ymin=yLower,ymax=yUpper,fill=zName),alpha=0.35,colour=&quot;transparent&quot;)
            gg_now = gg_now + scale_fill_manual(values=colClasses)
            gg_now = gg_now + geom_line(data=PredPlot,aes_string(x=xName,y=yName,colour=zName,linetype=zName),size=1.25,inherit.aes = FALSE)
            gg_now = gg_now + scale_linetype_manual(values=ltyClasses)
            gg_now = gg_now + labs( x        = desc.unit(desc=xDesc,unit=untab[[xUnit]])
                                  , y        = desc.unit(desc=yDesc,unit=untab[[yUnit]])
                                  , colour   = element_blank()
                                  , fill     = element_blank()
                                  , shape    = element_blank()
                                  , linetype = element_blank()
                                  , title    = zTitle
                                  , subtitle = LabelSubtitle
                                  )#end labs
         }else{
            gg_now = gg_now + labs( x        = desc.unit(desc=xDesc,unit=untab[[xUnit]])
                                  , y        = desc.unit(desc=yDesc,unit=untab[[yUnit]])
                                  , colour   = element_blank()
                                  , shape    = element_blank()
                                  , title    = zTitle
                                  , subtitle = LabelSubtitle
                                  )#end labs
         }#end if (PlotFit)
         gg_now = gg_now + theme_grey( base_size = gg_ptsz, base_family = &quot;Helvetica&quot;,base_line_size = 0.5,base_rect_size =0.5)
         gg_now = gg_now + theme( axis.text.x       = element_text( size = gg_ptsz, margin = unit(rep(0.35,times=4),&quot;cm&quot;))
                                , axis.text.y       = element_text( size = gg_ptsz, margin = unit(rep(0.35,times=4),&quot;cm&quot;))
                                , plot.title        = element_text( size = gg_ptsz)
                                , plot.subtitle     = element_text( size = 0.7*gg_ptsz)
                                , axis.ticks.length = unit(-0.25,&quot;cm&quot;)
                                , legend.position   = &quot;bottom&quot;
                                , legend.direction  = &quot;horizontal&quot;
                                )#end theme
         gg_now = gg_now + scale_x_continuous(trans=xTPlot,limits=xLimit)
         gg_now = gg_now + scale_y_continuous(trans=yTPlot,limits=yLimit)
         #      gg_now = gg_now + coord_trans(x=xTPlot,y=yTPlot,xlim=xLimit,ylim=yLimit)
         
         # Save plot in every format requested.
         for (d in sequence(ndevice)){
            f_output = paste0(&quot;SMAPlot_&quot;,yName,&quot;_by-&quot;,zName,&quot;_&quot;,trait_suffix,&quot;.&quot;,gg_device[d])
            dummy    = ggsave( filename = f_output
                             , plot     = gg_now
                             , device   = gg_device[d]
                             , path     = categ_trsma_path
                             , width    = gg_square
                             , height   = gg_square
                             , units    = gg_units
                             , dpi      = gg_depth
                             )#end ggsave
         }#end for (o in sequence(nout))
         
         # Write plot settings to the list.
         yzName           = paste0(yName,&quot;_&quot;,zName)
         gg_SMA[[yzName]] = gg_now
      }else{
         cat0(&quot; + Skip plot for &quot;,yDesc,&quot; by &quot;,zDesc,&quot;: too few valid points.&quot;)

      }#end if (PlotSMA)
   }#end for (y in yloop)
}#end for (z in seq_along(CategTrait))

# If sought, plot images on screen
cnt_gg_SMA = length(gg_SMA)
if (gg_screen &amp;&amp; (cnt_gg_SMA %gt% 0L)){
   gg_show = sort(sample.int(n=cnt_gg_SMA,size=min(cnt_gg_SMA,3L),replace=FALSE))
   gg_SMA[gg_show]
}#end if (gg_screen &amp;&amp; (length(gg_SMA) %gt% 0L))</code></pre>
<p><img src="TraitTradeOffs_files/figure-html/plot-sma-trait-1.png" width="768" /><img src="TraitTradeOffs_files/figure-html/plot-sma-trait-2.png" width="768" /><img src="TraitTradeOffs_files/figure-html/plot-sma-trait-3.png" width="768" /></p>
<p>And in this block, we do the same for the photosynthetic traits.</p>
<pre class="r"><code># Select reference data set for trade-off analysis
DataTRY = switch( EXPR       = fit_taxon
                , Individual = TidyTRY
                , Species    = SpeciesTRY
                , Genus      = GenusTRY
                , stop(&quot;Invalid settings for variable \&quot;fit_taxon\&quot;.&quot;)
                )#end switch

# Load settings for the x axis.
x      = xphoto_idx
xTrait = try_trait$TraitID[x]
xName  = try_trait$Name   [x]
xDesc  = try_trait$Desc   [x]
xUnit  = try_trait$Unit   [x]
xTrans = try_trait$Trans  [x]
xTPlot = switch( EXPR = xTrans, log = &quot;log10&quot;, neglog=&quot;neglog10&quot;,xTrans)

# Select valid data for the y axis
xSel = switch( EXPR     = xTrans
             , identity = is.finite(DataTRY[[xName]])
             , log      = DataTRY[[xName]] %gt% 0.
             , neglog   = DataTRY[[xName]] %lt% 0.
             , sqrt     = DataTRY[[xName]] %ge% 0.
             , cbrt     = is.finite(DataTRY[[xName]])
             , stop(paste0(&quot; Invalid transformation for trait &quot;,xName,&quot; (TraitID = &quot;,xTrait,&quot;).&quot;))
             )#end switch


   
# Find out how many SMA (Photosynthesis) fits we will seek
yPlotPhoto = which(try_trait$SMA &amp; try_trait$Photo &amp; (! (try_trait$Name %in% xName)))
CntPhoto   = length(yPlotPhoto)

# Initialise the list of plots
gg_Photo = list()

# Find the number of traits for plotting the model
CategSel    = is.finite(CategPhoto$TraitID) &amp; plot_sma_photo
CategTrait  = sort(unique(CategPhoto$TraitID[CategSel]))
for (ct in seq_along(CategTrait)){
   # Load settings for the classes.
   zTrait = CategTrait[ct]
   if (zTrait %in% 0L){
      zName  = &quot;Cluster&quot;
      zDesc  = &quot;Data-based cluster class&quot;
   }else{
      z      = match(zTrait,try_trait$TraitID)
      zName  = try_trait$Name   [z]
      zDesc  = try_trait$Desc   [z]
   }#end if (zTrait %in% 0L)
   zTitle = paste0(&quot;SMA model by &quot;,tolower(zDesc))

   # Set path for this group of plots.
   categ_photo_path = file.path(photo_path,zName)
   
      
   # Select categories for this trait type.
   CategNow = CategExtra %&gt;%
      filter( (TraitID %in% zTrait) | is.na(TraitID)) %&gt;%
      filter((! duplicated(Class)))

   CntCategNow = nrow(CategNow)


   # Loop through the SMA (Photosynthesis) variables
   for (y in sequence(CntPhoto)){
      # Load settings for the y axis.
      yIndex = yPlotPhoto[y]
      yTrait = try_trait$TraitID[yIndex]
      yName  = try_trait$Name   [yIndex]
      yLower = paste0(yName,&quot;_Lower&quot;)
      yUpper = paste0(yName,&quot;_Upper&quot;)
      yDesc  = try_trait$Desc   [yIndex]
      yUnit  = try_trait$Unit   [yIndex]
      yTrans = try_trait$Trans  [yIndex]
      yTPlot = switch( EXPR = yTrans, log = &quot;log10&quot;, neglog=&quot;neglog10&quot;,yTrans)
      
      # Select valid data for the y axis
      ySel = switch( EXPR     = yTrans
                   , identity = is.finite(DataTRY[[yName]])
                   , log      = DataTRY[[yName]] %gt% 0.
                   , neglog   = DataTRY[[yName]] %lt% 0.
                   , sqrt     = DataTRY[[yName]] %ge% 0.
                   , cbrt     = is.finite(DataTRY[[yName]])
                   , stop(paste0(&quot; Invalid transformation for trait &quot;,yName,&quot; (TraitID = &quot;,yTrait,&quot;).&quot;))
                   )#end switch

      # Subset data 
      DataPlot = DataTRY %&gt;%
         filter(xSel &amp; ySel) %&gt;%
         select_at(vars(c(xName,yName,zName))) %&gt;%
         mutate_at( vars(c(zName)), ~ifelse(.x %in% CategNow$Class,.x,&quot;UKN&quot;)) %&gt;%
         mutate_at( vars(c(zName)), ~factor(.x,levels=CategNow$Class))
      PlotPhoto  = nrow(DataPlot) %ge% n_fit_min

      # Append dummy data with category ALL so legends can be merged.
      DataDummy = DataPlot[rep(1L,times=CntCategNow),,drop=FALSE] %&gt;%
         mutate(across(c(xName,yName), ~ c(NA_real_))) %&gt;%
         mutate(across(c(zName), ~ factor(CategNow$Class,levels=CategNow$Class) ) )
      DataPlot    = rbind(DataPlot,DataDummy)
      CntDataPlot = nrow(DataPlot)

      # Plot only the variables with meaningful data
      if (PlotPhoto){
         cat0(&quot; + Plot the trait trade-offs (and SMA fits) for &quot;,yDesc,&quot;, by &quot;,zDesc,&quot;.&quot;)

         
         # Set path for this group of plots.
         dummy = dir.create(categ_photo_path,recursive=TRUE,showWarnings=FALSE)
 

         # Find limits for plots.   
         xLimit = range(DataPlot[[xName]],finite=TRUE)
         yLimit = range(DataPlot[[yName]],finite=TRUE)
         
         
         # Subset predicted data, so the range is consistent with the subset data:
         pSel     = ( ( (PredPhoto[[xName]] %wr% xLimit) | is.na(PredPhoto[[xName]]) )
                    &amp; ( (PredPhoto[[yName]] %wr% yLimit) | is.na(PredPhoto[[yName]]) )
                    &amp; (PredPhoto$TraitClass %in% c(&quot;All&quot;,&quot;Unknown&quot;,zName)) )
         PredPlot = PredPhoto %&gt;% 
            filter(pSel)    %&gt;%
            mutate(Class = factor(Class,levels = CategNow$Class)) %&gt;%
            rename_at( vars(c(&quot;Class&quot;)), ~ c(zName)) %&gt;%
            select_at(vars(c(xName,yName,zName)))
         PlotFit  = any(is.finite(PredPlot[[yName]]))

         
         # Subset SMA (Photosynthesis) summary   
         InfoPlot = InfoPhoto %&gt;%
            filter( (x %in% xName) &amp; (y %in% yName) &amp; ( TraitClass %in% c(&quot;All&quot;,zName) ) ) %&gt;%
            select( ! TraitClass) %&gt;%
            rename_at( vars(c(&quot;Class&quot;)), ~ c(zName)) %&gt;%
            add_row(&quot;{zName}&quot; := &quot;UKN&quot;) %&gt;%
            mutate( across(c(zName), ~ factor(.x,levels = CategNow$Class))) %&gt;%
            mutate( across(c(&quot;x&quot;,&quot;y&quot;,&quot;xTrans&quot;,&quot;yTrans&quot;), ~ ifelse(test=is.na(.x),yes=commonest(.x,na.rm=TRUE),no=.x))
                  , N      = ifelse(test=is.na(N),yes=0L,no=N)
                  , Line   = cut(pValue,breaks=c(0,0.001,0.01,0.05,0.10,1),labels=FALSE)
                  , Line   = ifelse( test = is.na(Line)
                                   , yes  = &quot;blank&quot;
                                   , no   = c(&quot;solid&quot;,&quot;dotdash&quot;,&quot;dashed&quot;,&quot;dotted&quot;,&quot;blank&quot;)[Line]
                                   )#end ifelse
                  )#end mutate
         
         # Set categories for colours, lines and symbols
         colClasses        = CategNow$Colour
         names(colClasses) = CategNow$Class
         pchClasses        = CategNow$Symbol
         names(pchClasses) = CategNow$Class
         ltyClasses        = InfoPlot$Line
         names(ltyClasses) = InfoPlot[[zName]]
         ltyClasses        = ltyClasses[match(names(pchClasses),names(ltyClasses))]
         
         
         # Build the plot
         gg_now = ggplot()
         gg_now = gg_now + geom_point(data=DataPlot,aes_string(x=xName,y=yName,colour=zName,shape=zName),size=1.6)
         gg_now = gg_now + scale_colour_manual  (values=colClasses)
         gg_now = gg_now + scale_shape_manual   (values=pchClasses)
         if (PlotFit){
            #gg_now = gg_now + geom_ribbon(data=PredPlot,aes_string(x=xName,ymin=yLower,ymax=yUpper,fill=zName),alpha=0.35,colour=&quot;transparent&quot;)
            gg_now = gg_now + scale_fill_manual(values=colClasses)
            gg_now = gg_now + geom_line(data=PredPlot,aes_string(x=xName,y=yName,colour=zName,linetype=zName),size=1.25,inherit.aes = FALSE)
            gg_now = gg_now + scale_linetype_manual(values=ltyClasses)
            gg_now = gg_now + labs( x        = desc.unit(desc=xDesc,unit=untab[[xUnit]])
                                  , y        = desc.unit(desc=yDesc,unit=untab[[yUnit]])
                                  , colour   = element_blank()
                                  , fill     = element_blank()
                                  , shape    = element_blank()
                                  , linetype = element_blank()
                                  , title    = zTitle
                                  , subtitle = LabelSubtitle
                                  )#end labs
         }else{
            gg_now = gg_now + labs( x        = desc.unit(desc=xDesc,unit=untab[[xUnit]])
                                  , y        = desc.unit(desc=yDesc,unit=untab[[yUnit]])
                                  , colour   = element_blank()
                                  , shape    = element_blank()
                                  , title    = zTitle
                                  , subtitle = LabelSubtitle
                                  )#end labs
         }#end if (PlotFit)
         gg_now = gg_now + theme_grey( base_size = gg_ptsz, base_family = &quot;Helvetica&quot;,base_line_size = 0.5,base_rect_size =0.5)
         gg_now = gg_now + theme( axis.text.x       = element_text( size = gg_ptsz, margin = unit(rep(0.35,times=4),&quot;cm&quot;))
                                , axis.text.y       = element_text( size = gg_ptsz, margin = unit(rep(0.35,times=4),&quot;cm&quot;))
                                , plot.title        = element_text( size = gg_ptsz)
                                , plot.subtitle     = element_text( size = 0.7*gg_ptsz)
                                , axis.ticks.length = unit(-0.25,&quot;cm&quot;)
                                , legend.position   = &quot;bottom&quot;
                                , legend.direction  = &quot;horizontal&quot;
                                )#end theme
         gg_now = gg_now + scale_x_continuous(trans=xTPlot,limits=xLimit)
         gg_now = gg_now + scale_y_continuous(trans=yTPlot,limits=yLimit)
         #      gg_now = gg_now + coord_trans(x=xTPlot,y=yTPlot,xlim=xLimit,ylim=yLimit)
         
         # Save plot in every format requested.
         for (d in sequence(ndevice)){
            f_output = paste0(&quot;SMAPlot_&quot;,yName,&quot;_by-&quot;,zName,&quot;_&quot;,photo_suffix,&quot;.&quot;,gg_device[d])
            dummy    = ggsave( filename = f_output
                             , plot     = gg_now
                             , device   = gg_device[d]
                             , path     = categ_photo_path
                             , width    = gg_width
                             , height   = gg_height
                             , units    = gg_units
                             , dpi      = gg_depth
                             )#end ggsave
         }#end for (o in sequence(nout))
         
         # Write plot settings to the list.
         yzName             = paste0(yName,&quot;_&quot;,zName)
         gg_Photo[[yzName]] = gg_now
      }else{
         cat0(&quot; + Skip plot for &quot;,yDesc,&quot; by &quot;,zDesc,&quot;: too few valid points.&quot;)

      }#end if (PlotPhoto)
   }#end for (y in yloop)
}#end for (z in seq_along(CategTrait))

# If sought, plot images on screen
cnt_gg_Photo = length(gg_Photo)
if (gg_screen &amp;&amp; (cnt_gg_Photo %gt% 0L)){
   gg_show = sort(sample.int(n=cnt_gg_Photo,size=min(cnt_gg_Photo,3L),replace=FALSE))
   gg_Photo[gg_show]
}#end if (gg_screen &amp;&amp; (length(gg_Photo) %gt% 0L))</code></pre>
<p><img src="TraitTradeOffs_files/figure-html/plot-sma-photo-1.png" width="768" /><img src="TraitTradeOffs_files/figure-html/plot-sma-photo-2.png" width="768" /><img src="TraitTradeOffs_files/figure-html/plot-sma-photo-3.png" width="768" /></p>
</div>
<div id="plot-global-trait-distribution" class="section level2">
<h2>Plot global trait distribution</h2>
<p>Here we plot the global trait distribution as a separate set, which
can be useful for some analyses.</p>
<pre class="r"><code># Select reference data set for trade-off analysis
DataTRY    = switch( EXPR       = fit_taxon
                   , Individual = TidyTRY
                   , Species    = SpeciesTRY
                   , Genus      = GenusTRY
                   , stop(&quot;Invalid settings for variable \&quot;fit_taxon\&quot;.&quot;)
                   )#end switch

# Set path for this group of plots.
global_trdist_path = file.path(trdist_path,&quot;Global&quot;)

# Select distribution statistics for this trait type
InfoNow = InfoDistr %&gt;%
   filter(TraitClass %in% c(&quot;All&quot;)) %&gt;%
   select(! c(Class,TraitClass)) %&gt;%
   mutate(Label = NA_character_)

# Find out how many distribution plots we will make
xPlotDistr = which(try_trait$SMA &amp; (try_trait$Name %in% InfoDistr$x) &amp; plot_global_distrib)
CntDistr   = length(xPlotDistr)

# Initialise list with plots
gg_Distr = list()

# Loop through the SMA variables
for (x in sequence(CntDistr)){
   # Load settings for the y axis.
   xIndex    = xPlotDistr[x]
   xTrait    = try_trait$TraitID[xIndex]
   xName     = try_trait$Name   [xIndex]
   xLower    = paste0(yName,&quot;_Lower&quot;)
   xUpper    = paste0(yName,&quot;_Upper&quot;)
   xDesc     = try_trait$Desc   [xIndex]
   xUnit     = try_trait$Unit   [xIndex]
   xTrans    = try_trait$Trans  [xIndex]
   xTPlot    = switch( EXPR = xTrans, log = &quot;log10&quot;, neglog=&quot;neglog10&quot;,xTrans)
   xInfo     = which(InfoNow$x %in% xName)
   xDistr    = InfoNow$Distrib[xInfo]
   xFirst    = InfoNow$First  [xInfo]
   xSecond   = InfoNow$Second [xInfo]
   xThird    = InfoNow$Third  [xInfo]
   xColLine  = RColorBrewer::brewer.pal(n=2L,name=&quot;Paired&quot;)[2L]
   xColPoint = RColorBrewer::brewer.pal(n=2L,name=&quot;Paired&quot;)[1L]

      
   # Select valid data for the x axis
   xSel = switch( EXPR     = xTrans
                , identity = is.finite(DataTRY[[xName]])
                , log      = DataTRY[[xName]] %gt% 0.
                , neglog   = DataTRY[[xName]] %lt% 0.
                , sqrt     = DataTRY[[xName]] %ge% 0.
                , cbrt     = is.finite(DataTRY[[xName]])
                , stop(paste0(&quot; Invalid transformation for trait &quot;,xName,&quot; (TraitID = &quot;,xTrait,&quot;).&quot;))
                )#end switch

   # Fit density according to the distribution.
   xFun = switch( xDistr
                , &quot;uniform&quot;       = dunif
                , &quot;normal&quot;        = dnorm
                , &quot;logistic&quot;      = dlogis
                , &quot;skew-normal&quot;   = sn::dsn
                , &quot;log-normal&quot;    = dlnorm
                , &quot;neglog-normal&quot; = dnlnorm
                , &quot;weibull&quot;       = dweibull
                , &quot;gamma&quot;         = dgamma
                , NA_character_
                )#end switch

         
   # Subset data and see if there are sufficient points for plotting the global distribution
   DataPlot = DataTRY %&gt;%
      filter(xSel)        %&gt;%
      select_at(vars(c(xName))) %&gt;%
      mutate( density = NA_real_)
   CntDataPlot = nrow(DataPlot)


   # Plot only the variables with meaningful data
   PlotDistr   = (! is.na(xInfo)) &amp; (CntDataPlot %gt% n_fit_min)
   if (PlotDistr){
      cat0(&quot; + Plot the global trait distribution for &quot;,xDesc,&quot;.&quot;)

      
      # Set path for this group of plots.
      dummy = dir.create(path=global_trdist_path,recursive=TRUE,showWarnings=FALSE)

      # Labels for title and sub-title
      xTitle    = paste0(&quot;Density function - &quot;,xDesc)
      xSubtitle = paste0(&quot;Fitted distribution: &quot;,str_to_sentence(xDistr),&quot;.&quot;)

      # Find limits for plots.   
      xLimit = range(DataPlot[[xName]],finite=TRUE)
      
      DistrPlot = tibble( x = seq(from=xLimit[1L],to=xLimit[2L],length.out=n_predict)
                        , y = rep(NA_real_,times=n_predict)
                        , d = rep(NA_character_,times=n_predict)
                        )#end tibble
      names(DistrPlot) = c(xName,&quot;density&quot;,&quot;distr&quot;)

            

      # Decide whether the distribution needs two or three parameters
      if (xDistr %in% &quot;skew-normal&quot;){
         DistrPlot$density = xFun(DistrPlot[[xName]],xFirst,xSecond,xThird)
         DataPlot$density  = xFun(DataPlot [[xName]],xFirst,xSecond,xThird)
      }else if (! is.na(xDistr)){
         DistrPlot$density = xFun(DistrPlot[[xName]],xFirst,xSecond)
         DataPlot$density  = xFun(DataPlot [[xName]],xFirst,xSecond)
      }#end if (xDistr %in% &quot;skew-normal&quot;)

      # Prepare DataPlot to have random density locations below the curves
      DataPlot = DataPlot %&gt;%
         mutate   ( density = density * runif(n=CntDataPlot) )

      # Find limits for density scale
      yLimit = range(DistrPlot$density,finite=TRUE)
         
      # Build the plot
      gg_now = ggplot()
      gg_now = gg_now + geom_rug(data=DataPlot,aes_string(x=xName,y=&quot;density&quot;),colour=xColPoint,sides=&quot;b&quot;)
      #gg_now = gg_now + geom_point(data=DataPlot,aes_string(x=xName,y=&quot;density&quot;),size=1.5,colour=&quot;#AAAAAA&quot;)
      gg_now = gg_now + geom_line(data=DistrPlot,aes_string(x=xName,y=&quot;density&quot;),size=1.25,colour=xColLine,inherit.aes = FALSE)
      gg_now = gg_now + labs( x        = desc.unit(desc=xDesc,unit=untab[[xUnit]])
                            , y        = desc.unit(desc=&quot;Density function&quot;,unit=i.untab[[xUnit]])
                            , title    = xTitle
                            , subtitle = xSubtitle
                            )#end labs
      gg_now = gg_now + theme_grey( base_size = gg_ptsz, base_family = &quot;Helvetica&quot;,base_line_size = 0.5,base_rect_size =0.5)
      gg_now = gg_now + theme( axis.text.x       = element_text( size = gg_ptsz, margin = unit(rep(0.35,times=4),&quot;cm&quot;))
                             , axis.text.y       = element_text( size = gg_ptsz, margin = unit(rep(0.35,times=4),&quot;cm&quot;))
                             , plot.title        = element_text( size = gg_ptsz)
                             , plot.subtitle     = element_text( size = 0.7*gg_ptsz)
                             , axis.ticks.length = unit(-0.25,&quot;cm&quot;)
                             , legend.position   = &quot;bottom&quot;
                             , legend.direction  = &quot;horizontal&quot;
                             )#end theme
      gg_now = gg_now + scale_x_continuous(trans=xTPlot,limits=xLimit)
      gg_now = gg_now + scale_y_continuous(trans=&quot;identity&quot;,limits=yLimit)

      # Save plot in every format requested.
      for (d in sequence(ndevice)){
         f_output = paste0(&quot;DistrPlot_&quot;,xName,&quot;_Global_&quot;,base_suffix,&quot;.&quot;,gg_device[d])
         dummy = ggsave( filename = f_output
                       , plot     = gg_now
                       , device   = gg_device[d]
                       , path     = global_trdist_path
                       , width    = gg_square
                       , height   = gg_height
                       , units    = gg_units
                       , dpi      = gg_depth
                       )#end ggsave
      }#end for (d in sequence(ndevice))
      
      # Write plot settings to the list.
      gg_Distr[[xName]] = gg_now
   }else{
      cat0(&quot; + Skip plot for &quot;,xDesc,&quot;: too few valid points.&quot;)
      
   }#end if (PlotDistr)
}#end for (x in sequence(CntDistr))

# If sought, plot images on screen
cnt_gg_Distr = length(gg_Distr)
if (gg_screen &amp;&amp; (cnt_gg_Distr %gt% 0L)){
   gg_show = sort(sample.int(n=cnt_gg_Distr,size=min(cnt_gg_Distr,3L),replace=FALSE))
   gg_Distr[gg_show]
}#end if (gg_screen &amp;&amp; (cnt_gg_Distr %gt% 0L))</code></pre>
<p><img src="TraitTradeOffs_files/figure-html/plot-global-distrib-1.png" width="768" /><img src="TraitTradeOffs_files/figure-html/plot-global-distrib-2.png" width="768" /><img src="TraitTradeOffs_files/figure-html/plot-global-distrib-3.png" width="768" /></p>
</div>
<div id="plot-trait-density-function-by-group" class="section level2">
<h2>Plot trait density function by group</h2>
<p>Here we plot the density functions of traits, separated by classes,
and along with the global distribution.</p>
<pre class="r"><code># Select reference data set for trade-off analysis
DataTRY    = switch( EXPR       = fit_taxon
                   , Individual = TidyTRY
                   , Species    = SpeciesTRY
                   , Genus      = GenusTRY
                   , stop(&quot;Invalid settings for variable \&quot;fit_taxon\&quot;.&quot;)
                   )#end switch



# Find the number of sub-classes to test the model
CategDistr    = CategExtra %&gt;%
   filter( ( (XYUse %in% &quot;Colour&quot;) | (TraitID %in% 0L) | is.na(TraitID)) &amp; (! duplicated(Class))) %&gt;%
   mutate( Label = paste0(Class,&quot; (Not fitted)&quot;) )
CntCategDistr = nrow(CategDistr)


# Find out how many distribution plots we will make
xPlotDistr = which(try_trait$SMA &amp; (try_trait$Name %in% InfoDistr$x))
CntDistr   = length(xPlotDistr)

# Initialise list with plots
gg_Distr = list()


CategSel    = is.finite(CategDistr$TraitID) &amp; plot_categ_distrib
CategTrait  = sort(unique(CategDistr$TraitID[CategSel]))
for (ct in seq_along(CategTrait)){
   # Load settings for the classes.
   zTrait = CategTrait[ct]
   if (zTrait %in% 0L){
      zName  = &quot;Cluster&quot;
      zDesc  = &quot;Data-based cluster class&quot;
   }else{
      z      = match(zTrait,try_trait$TraitID)
      zName  = try_trait$Name   [z]
      zDesc  = try_trait$Desc   [z]
   }#end if (zTrait %in% 0L)
   zTitle = paste0(&quot;Trait distribution by &quot;,tolower(zDesc))

   # Set path for this group of plots.
   categ_trdist_path = file.path(trdist_path,zName)

   # Select categories for this trait type.
   CategDistr = CategExtra %&gt;%
      filter( (TraitID %in% zTrait) | is.na(TraitID)) %&gt;%
      filter((! duplicated(Class))) %&gt;%
      mutate(Label = ifelse(test=Class %in% &quot;UKN&quot;,yes=&quot;UKN&quot;,no=NA_character_))
   CntCategDistr = nrow(CategDistr)
   
   
   # Select distribution statistics for this trait type
   InfoNow = InfoDistr %&gt;%
      filter(TraitClass %in% c(&quot;All&quot;,zName)) %&gt;%
      select(! TraitClass) %&gt;%
      rename_at( vars(c(&quot;Class&quot;)), ~ c(zName)) %&gt;%
      mutate(Label = NA_character_)

   # Loop through the SMA variables
   for (x in sequence(CntDistr)){
      # Load settings for the y axis.
      xIndex = xPlotDistr[x]
      xTrait = try_trait$TraitID[xIndex]
      xName  = try_trait$Name   [xIndex]
      xLower = paste0(xName,&quot;_Lower&quot;)
      xUpper = paste0(xName,&quot;_Upper&quot;)
      xDesc  = try_trait$Desc   [xIndex]
      xUnit  = try_trait$Unit   [xIndex]
      xTrans = try_trait$Trans  [xIndex]
      xTPlot = switch( EXPR = xTrans, log = &quot;log10&quot;, neglog=&quot;neglog10&quot;,xTrans)
      
      # Select valid data for the x axis
      xSel = switch( EXPR     = xTrans
                   , identity = is.finite(DataTRY[[xName]])
                   , log      = DataTRY[[xName]] %gt% 0.
                   , neglog   = DataTRY[[xName]] %lt% 0.
                   , sqrt     = DataTRY[[xName]] %ge% 0.
                   , cbrt     = is.finite(DataTRY[[xName]])
                   , stop(paste0(&quot; Invalid transformation for trait &quot;,xName,&quot; (TraitID = &quot;,xTrait,&quot;).&quot;))
                   )#end switch
      
      # Subset data 
      DataPlot = DataTRY %&gt;%
         filter(xSel) %&gt;%
         select_at(vars(c(xName,zName))) %&gt;%
         mutate( across(c(zName), ~ifelse(.x %in% CategDistr$Class,.x,&quot;UKN&quot;))
               , across(c(zName), ~factor(.x,levels=CategDistr$Class))
               , density = NA_real_                                           )

      # Append dummy data with category ALL so legends can be merged.
      DataDummy = DataPlot[rep(1L,times=CntCategDistr),,drop=FALSE] %&gt;%
         mutate( across(c(xName,&quot;density&quot;), ~ c(NA_real_))
               , across(c(zName), ~ factor(CategDistr$Class,levels=CategDistr$Class) ) )
      DataPlot    = rbind(DataPlot,DataDummy)
      CntDataPlot = nrow(DataPlot)

      # Plot only the variables with meaningful data
      PlotDistr   = CntDataPlot %gt% n_fit_min
      if (PlotDistr){
         cat0(&quot; + Plot the trait distribution for &quot;,xDesc,&quot; by &quot;,zName,&quot;.&quot;)

         # Set path for this group of plots.
         dummy = dir.create(path=categ_trdist_path,recursive=TRUE,showWarnings=FALSE)

         # Find limits for plots.   
         xLimit = range(DataPlot[[xName]],finite=TRUE)
      
         DistrPlot = tibble( x = rep(seq(from=xLimit[1L],to=xLimit[2L],length.out=n_predict),times=CntCategDistr)
                           , y = rep(NA_real_,times=CntCategDistr*n_predict)
                           , z = rep(CategDistr$Class,each=n_predict)
                           , d = rep(NA_character_,times=CntCategDistr*n_predict)
                           )#end tibble
         names(DistrPlot) = c(xName,&quot;density&quot;,zName,&quot;distr&quot;)

         # Turn classes into levels, so legends can be merged.
         DistrPlot = DistrPlot %&gt;%
            mutate( across(c(zName), ~ factor(.x,levels = CategDistr$Class)) ) 

         # Generate consistent density functions
         zLoop = which(CategDistr$Class %in% unique(InfoNow[[zName]]))
         for (z in zLoop){
            # Identfy distribution
            zValue  = CategDistr$Class[z]
            zInfo   = which((InfoNow[[zName]] %in% zValue) &amp; (InfoNow$x %in% xName))
            zDistr  = InfoNow$Distrib[zInfo]
            zFirst  = InfoNow$First  [zInfo]
            zSecond = InfoNow$Second [zInfo]
            zThird  = InfoNow$Third  [zInfo]
            if (zValue %in% &quot;ALL&quot;){
               zSel = DistrPlot[[zName]] %in% zValue
               rSel = DataPlot [[zName]] %in% &quot;UKN&quot;
            }else{
               zSel = DistrPlot[[zName]] %in% zValue
               rSel = DataPlot [[zName]] %in% zValue
            }#end if (zValue %in% &quot;ALL&quot;)

            # Set the distribution         
            DistrPlot$distr[zSel] = zDistr

            # Update label to include fitted distribution
            if (is.na(zDistr)){
               CategDistr$Label[z] = paste0(CategDistr$Class[z],&quot; (Not fitted)&quot;)
            }else{
               CategDistr$Label[z] = paste0(CategDistr$Class[z],&quot; (&quot;,str_to_sentence(zDistr),&quot;)&quot;)
            }#end if (is.na(zDistr))
            
            
            # Fit density according to the distribution.
            zFun = switch( zDistr
                         , &quot;uniform&quot;       = dunif
                         , &quot;normal&quot;        = dnorm
                         , &quot;logistic&quot;      = dlogis
                         , &quot;skew-normal&quot;   = sn::dsn
                         , &quot;log-normal&quot;    = dlnorm
                         , &quot;neglog-normal&quot; = dnlnorm
                         , &quot;weibull&quot;       = dweibull
                         , &quot;gamma&quot;         = dgamma
                         , NA_character_
                         )#end switch

            # Decide whether the distribution needs two or three parameters
            if (zDistr %in% &quot;skew-normal&quot;){
               if (any(zSel)) DistrPlot$density[zSel] = zFun(DistrPlot[[xName]][zSel],zFirst,zSecond,zThird)
               if (any(rSel)) DataPlot$density [rSel] = zFun(DataPlot [[xName]][rSel],zFirst,zSecond,zThird)
            }else if (! is.na(zDistr)){
               if (any(zSel)) DistrPlot$density[zSel] = zFun(DistrPlot[[xName]][zSel],zFirst,zSecond)
               if (any(rSel)) DataPlot$density [rSel] = zFun(DataPlot [[xName]][rSel],zFirst,zSecond)
            }#end if (zDistr %in% &quot;skew-normal&quot;)
         }#end for (z in zLoop)
         
         # Prepare DataPlot to have random density locations below the curves
         DataPlot = DataPlot %&gt;%
            mutate   ( density = density * runif(n=CntDataPlot) )

         # Find limits for density scale
         yLimit = range(DistrPlot$density,finite=TRUE)
         
         
         # Set categories for colours, lines and symbols
         colClasses        = CategDistr$Colour
         names(colClasses) = CategDistr$Class
         pchClasses        = CategDistr$Symbol
         names(pchClasses) = CategDistr$Class
         ltyClasses        = rep(&quot;solid&quot;,times=CntCategDistr)
         names(ltyClasses) = CategDistr$Class
         labClasses        = CategDistr$Label
         names(labClasses) = CategDistr$Class
         
         
         # Build the plot
         gg_now = ggplot()
         gg_now = gg_now + geom_point(data=DataPlot,aes_string(x=xName,y=&quot;density&quot;,colour=zName,shape=zName),size=1.5)
         gg_now = gg_now + geom_line(data=DistrPlot,aes_string(x=xName,y=&quot;density&quot;,colour=zName),size=1.25,inherit.aes = FALSE)
         gg_now = gg_now + scale_colour_manual  (values=colClasses,breaks=CategDistr$Class,labels=labClasses)
         gg_now = gg_now + scale_shape_manual   (values=pchClasses,breaks=CategDistr$Class,labels=labClasses)
         gg_now = gg_now + scale_linetype_manual(values=ltyClasses,breaks=CategDistr$Class,labels=labClasses)
         gg_now = gg_now + labs( x        = desc.unit(desc=xDesc,unit=untab[[xUnit]])
                               , y        = desc.unit(desc=&quot;Density function&quot;,unit=i.untab[[xUnit]])
                               , colour   = element_blank()
                               , fill     = element_blank()
                               , shape    = element_blank()
                               , title    = zTitle
                               , subtitle = LabelSubtitle
                               )#end labs
         gg_now = gg_now + theme_grey( base_size = gg_ptsz, base_family = &quot;Helvetica&quot;,base_line_size = 0.5,base_rect_size =0.5)
         gg_now = gg_now + theme( axis.text.x       = element_text( size = gg_ptsz, margin = unit(rep(0.35,times=4),&quot;cm&quot;))
                                , axis.text.y       = element_text( size = gg_ptsz, margin = unit(rep(0.35,times=4),&quot;cm&quot;))
                                , plot.title        = element_text( size = gg_ptsz)
                                , plot.subtitle     = element_text( size = 0.7*gg_ptsz)
                                , axis.ticks.length = unit(-0.25,&quot;cm&quot;)
                                , legend.position   = &quot;bottom&quot;
                                , legend.direction  = &quot;horizontal&quot;
                                )#end theme
         gg_now = gg_now + scale_x_continuous(trans=xTPlot,limits=xLimit)
         gg_now = gg_now + scale_y_continuous(trans=&quot;identity&quot;,limits=yLimit)
         gg_now = gg_now + guides(colour = guide_legend(nrow=2,byrow=TRUE))
         gg_now = gg_now + guides(shape  = guide_legend(nrow=2,byrow=TRUE))

         # Save plot in every format requested.
         for (d in sequence(ndevice)){
            f_output = paste0(&quot;DistrPlot_&quot;,xName,&quot;_by-&quot;,zName,&quot;_&quot;,base_suffix,&quot;.&quot;,gg_device[d])
            dummy = ggsave( filename = f_output
                          , plot     = gg_now
                          , device   = gg_device[d]
                          , path     = categ_trdist_path
                          , width    = gg_width
                          , height   = gg_height
                          , units    = gg_units
                          , dpi      = gg_depth
                          )#end ggsave
         }#end for (o in sequence(nout))
      
         # Write plot settings to the list.
         xzName = paste0(xName,&quot;_&quot;,zName)
         gg_Distr[[xzName]] = gg_now
      }else{
         cat0(&quot; + Skip plot for &quot;,xDesc,&quot; by &quot;,zDesc,&quot;: too few valid points.&quot;)
         
      }#end if (PlotSMA)
   }#end for (y in yloop)
}#end for (ct in seq_along(CategTrait)){


# If sought, plot images on screen
cnt_gg_Distr = length(gg_Distr)
if (gg_screen &amp;&amp; (cnt_gg_Distr %gt% 0L)){
   gg_show = sort(sample.int(n=cnt_gg_Distr,size=min(cnt_gg_Distr,3L),replace=FALSE))
   gg_Distr[gg_show]
}#end if (gg_screen &amp;&amp; (length(gg_Photo) %gt% 0L))</code></pre>
<p><img src="TraitTradeOffs_files/figure-html/plot-categ-distrib-1.png" width="768" /><img src="TraitTradeOffs_files/figure-html/plot-categ-distrib-2.png" width="768" /><img src="TraitTradeOffs_files/figure-html/plot-categ-distrib-3.png" width="768" /></p>
</div>
<div
id="plot-trait-density-function-by-group-using-ridge-joy-division-plots"
class="section level2">
<h2>Plot trait density function by group using ridge (Joy Division)
plots</h2>
<p>Here we plot the density functions of traits, separated by classes,
and along with the global distribution. We do not use the
<code>ggridges</code> package because we want the fitted distributions
to be plotted instead of the non-parametric distributions.</p>
<pre class="r"><code># Select reference data set for trade-off analysis
DataTRY    = switch( EXPR       = fit_taxon
                   , Individual = TidyTRY
                   , Species    = SpeciesTRY
                   , Genus      = GenusTRY
                   , stop(&quot;Invalid settings for variable \&quot;fit_taxon\&quot;.&quot;)
                   )#end switch

# Find out how many distribution plots we will make
xPlotDistr = which(try_trait$SMA &amp; (try_trait$Name %in% InfoDistr$x))
CntDistr   = length(xPlotDistr)

# Initialise list with plots
gg_Ridge = list()

CategInput  = CategExtra %&gt;%
   filter( ( (XYUse %in% &quot;Colour&quot;) | (TraitID %in% 0L) | is.na(TraitID) ) &amp; (! duplicated(Class)) &amp; plot_categ_ridge )
CategTrait  = sort(unique(CategInput$TraitID[CategSel]))
for (ct in seq_along(CategTrait)){
   # Load settings for the classes.
   zTrait = CategTrait[ct]
   if (zTrait %in% 0L){
      zName  = &quot;Cluster&quot;
      zDesc  = &quot;Data-based cluster class&quot;
   }else{
      z      = match(zTrait,try_trait$TraitID)
      zName  = try_trait$Name   [z]
      zDesc  = try_trait$Desc   [z]
   }#end if (zTrait %in% 0L)
   zTitle = paste0(&quot;Trait distribution by &quot;,tolower(zDesc))

   # Set path for this group of plots.
   categ_trridge_path = file.path(trridge_path,zName)

   # Select categories for this trait type.
   CategDistr = CategInput %&gt;%
      filter( (TraitID %in% zTrait) | (Class %in% &quot;ALL&quot;) ) %&gt;%
      filter((! duplicated(Class))) %&gt;%
      mutate(Label = NA_character_)
   CntCategDistr = nrow(CategDistr)
   
   
   # Select distribution statistics for this trait type
   InfoNow = InfoDistr %&gt;%
      filter(TraitClass %in% c(&quot;All&quot;,zName)) %&gt;%
      select(! TraitClass) %&gt;%
      rename_at( vars(c(&quot;Class&quot;)), ~ c(zName)) %&gt;%
      mutate(Label = NA_character_)

   # Loop through the SMA variables
   for (x in sequence(CntDistr)){
      # Load settings for the y axis.
      xIndex = xPlotDistr[x]
      xTrait = try_trait$TraitID[xIndex]
      xName  = try_trait$Name   [xIndex]
      xLower = paste0(xName,&quot;_Lower&quot;)
      xUpper = paste0(xName,&quot;_Upper&quot;)
      xDesc  = try_trait$Desc   [xIndex]
      xUnit  = try_trait$Unit   [xIndex]
      xTrans = try_trait$Trans  [xIndex]
      xTPlot = switch( EXPR = xTrans, log = &quot;log10&quot;, neglog=&quot;neglog10&quot;,xTrans)
      
      # Select valid data for the x axis
      xSel = switch( EXPR     = xTrans
                   , identity = is.finite(DataTRY[[xName]])
                   , log      = DataTRY[[xName]] %gt% 0.
                   , neglog   = DataTRY[[xName]] %lt% 0.
                   , sqrt     = DataTRY[[xName]] %ge% 0.
                   , cbrt     = is.finite(DataTRY[[xName]])
                   , stop(paste0(&quot; Invalid transformation for trait &quot;,xName,&quot; (TraitID = &quot;,xTrait,&quot;).&quot;))
                   )#end switch
      
      # Subset data 
      DataPlot = DataTRY %&gt;%
         filter(xSel) %&gt;%
         select_at(vars(c(xName,zName))) %&gt;%
         mutate( across(c(zName), ~ifelse(.x %in% CategDistr$Class,.x,&quot;ALL&quot;))
               , across(c(zName), ~factor(.x,levels=CategDistr$Class))
               , offset  = NA_real_
               , density = NA_real_                                           )

      # Append dummy data with category ALL so legends can be merged.
      DataDummy = DataPlot[rep(1L,times=CntCategDistr),,drop=FALSE] %&gt;%
         mutate( across(c(xName,&quot;offset&quot;,&quot;density&quot;), ~ c(NA_real_))
               , across(c(zName), ~ factor(CategDistr$Class,levels=CategDistr$Class) ) )
      DataPlot    = rbind(DataPlot,DataDummy)
      CntDataPlot = nrow(DataPlot)

      # Plot only the variables with meaningful data
      PlotDistr   = CntDataPlot %gt% n_fit_min
      if (PlotDistr){
         cat0(&quot; + Plot the trait distribution for &quot;,xDesc,&quot; by &quot;,zName,&quot;.&quot;)

         # Set path for this group of plots.
         dummy = dir.create(path=categ_trridge_path,recursive=TRUE,showWarnings=FALSE)

         # Find limits for plots.   
         xLimit = range(DataPlot[[xName]],finite=TRUE)
      
         DistrPlot = tibble( x  = rep(seq(from=xLimit[1L],to=xLimit[2L],length.out=n_predict),times=CntCategDistr)
                           , l  = rep(NA_real_,times=CntCategDistr*n_predict)
                           , u  = rep(NA_real_,times=CntCategDistr*n_predict)
                           , z  = rep(CategDistr$Class,each=n_predict)
                           , d  = rep(NA_character_,times=CntCategDistr*n_predict)
                           )#end tibble
         names(DistrPlot) = c(xName,&quot;offset&quot;,&quot;density&quot;,zName,&quot;distr&quot;)

         # Turn classes into levels, so legends can be merged.
         DistrPlot = DistrPlot %&gt;%
            mutate( across(c(zName), ~ factor(.x,levels = CategDistr$Class)) ) 

         # Generate consistent density functions
         zLoop = which(CategDistr$Class %in% unique(InfoNow[[zName]]))
         onow  = -1L
         for (z in zLoop){
            # Update offset
            onow = onow + 1L

            # Identfy distribution
            zValue  = CategDistr$Class[z]
            zInfo   = which((InfoNow[[zName]] %in% zValue) &amp; (InfoNow$x %in% xName))
            zDistr  = InfoNow$Distrib[zInfo]
            zFirst  = InfoNow$First  [zInfo]
            zSecond = InfoNow$Second [zInfo]
            zThird  = InfoNow$Third  [zInfo]
            if (zValue %in% &quot;ALL&quot;){
               zSel = DistrPlot[[zName]] %in% zValue
               rSel = DataPlot [[zName]] %in% &quot;UKN&quot;
            }else{
               zSel = DistrPlot[[zName]] %in% zValue
               rSel = DataPlot [[zName]] %in% zValue
            }#end if (zValue %in% &quot;ALL&quot;)

            # Set the distribution         
            DistrPlot$distr[zSel] = zDistr

            # Update label to include fitted distribution
            if (is.na(zDistr)){
               CategDistr$Label[z] = paste0(CategDistr$Class[z],&quot; (Not fitted)&quot;)
            }else{
               CategDistr$Label[z] = paste0(CategDistr$Class[z],&quot; (&quot;,str_to_sentence(zDistr),&quot;)&quot;)
            }#end if (is.na(zDistr))
            
            
            # Fit density according to the distribution.
            zFun = switch( zDistr
                         , &quot;uniform&quot;       = dunif
                         , &quot;normal&quot;        = dnorm
                         , &quot;logistic&quot;      = dlogis
                         , &quot;skew-normal&quot;   = sn::dsn
                         , &quot;log-normal&quot;    = dlnorm
                         , &quot;neglog-normal&quot; = dnlnorm
                         , &quot;weibull&quot;       = dweibull
                         , &quot;gamma&quot;         = dgamma
                         , NA_character_
                         )#end switch

            # Append offsets
            if (any(zSel)) DistrPlot$offset[zSel] = onow
            if (any(rSel)) DataPlot$offset [rSel] = onow
            
            # Decide whether the distribution needs two or three parameters
            if (zDistr %in% &quot;skew-normal&quot;){
               if (any(zSel)) DistrPlot$density[zSel] = zFun(DistrPlot[[xName]][zSel],zFirst,zSecond,zThird)
               if (any(rSel)) DataPlot$density [rSel] = zFun(DataPlot [[xName]][rSel],zFirst,zSecond,zThird)
            }else if (! is.na(zDistr)){
               if (any(zSel)) DistrPlot$density [zSel] = zFun(DistrPlot[[xName]][zSel],zFirst,zSecond)
               if (any(rSel)) DataPlot$density  [rSel] = zFun(DataPlot [[xName]][rSel],zFirst,zSecond)
            }#end if (zDistr %in% &quot;skew-normal&quot;)
         }#end for (z in zLoop)

         # Find scaling factor for all densities, allowing a bit of overlap between the curves
         DensityMax = 0.6 * max(DistrPlot$density,na.rm=TRUE)
         DistrPlot  = DistrPlot %&gt;%
            mutate( ridge = offset + density / DensityMax)
         DataPlot   = DataPlot %&gt;%
            mutate( ridge = offset + density / DensityMax * runif(n=CntDataPlot))

         # Find limits for density scale
         yLimit  = range(c(DistrPlot$offset,DistrPlot$ridge),finite=TRUE)
         yAt     = seq_along(zLoop) - 1L
         yLabels = CategDistr$Label[zLoop]
         

                  
         # Set categories for colours, lines and symbols
         colClasses        = CategDistr$Colour
         names(colClasses) = CategDistr$Class
         bgClasses         = alpha(colClasses,alpha=0.4)
         names(bgClasses)  = CategDistr$Class
         pchClasses        = CategDistr$Symbol
         names(pchClasses) = CategDistr$Class
         ltyClasses        = rep(&quot;solid&quot;,times=CntCategDistr)
         names(ltyClasses) = CategDistr$Class
         labClasses        = CategDistr$Label
         names(labClasses) = CategDistr$Class
         
         
         # Build the plot
         gg_now = ggplot()
         gg_now = gg_now + geom_ribbon( data        = DistrPlot
                                      , mapping     = aes_string(x=xName,ymin=&quot;offset&quot;,ymax=&quot;ridge&quot;,colour=zName,fill=zName)
                                      , size        = 1.25
                                      , inherit.aes = FALSE
                                      , show.legend = FALSE
                                      )#end geom_ribbon
         gg_now = gg_now + geom_point( data        = DataPlot
                                     , mapping     = aes_string(x=xName,y=&quot;ridge&quot;,colour=zName,shape=zName)
                                     , size        = 1.5
                                     , show.legend = FALSE
                                     )#end geom_point
         gg_now = gg_now + scale_colour_manual  (values=colClasses,breaks=CategDistr$Class,labels=labClasses)
         gg_now = gg_now + scale_fill_manual    (values=bgClasses ,breaks=CategDistr$Class,labels=labClasses)
         gg_now = gg_now + scale_shape_manual   (values=pchClasses,breaks=CategDistr$Class,labels=labClasses)
         gg_now = gg_now + scale_linetype_manual(values=ltyClasses,breaks=CategDistr$Class,labels=labClasses)
         gg_now = gg_now + labs( x        = desc.unit(desc=xDesc,unit=untab[[xUnit]])
                               , y        = element_blank()
                               , colour   = element_blank()
                               , fill     = element_blank()
                               , shape    = element_blank()
                               , title    = zTitle
                               , subtitle = LabelSubtitle
                               )#end labs
         gg_now = gg_now + theme_grey( base_size = gg_ptsz, base_family = &quot;Helvetica&quot;,base_line_size = 0.5,base_rect_size =0.5)
         gg_now = gg_now + theme( axis.text.x       = element_text( size = gg_ptsz, margin = unit(rep(0.35,times=4),&quot;cm&quot;))
                                , axis.text.y       = element_text( size = gg_ptsz, margin = unit(rep(0.35,times=4),&quot;cm&quot;))
                                , plot.title        = element_text( size = gg_ptsz)
                                , plot.subtitle     = element_text( size = 0.7*gg_ptsz)
                                , axis.ticks.length = unit(-0.25,&quot;cm&quot;)
                                , legend.position   = &quot;bottom&quot;
                                , legend.direction  = &quot;horizontal&quot;
                                )#end theme
         gg_now = gg_now + scale_x_continuous(trans=xTPlot,limits=xLimit)
         gg_now = gg_now + scale_y_continuous(trans=&quot;identity&quot;,limits=yLimit,breaks=yAt,labels=yLabels)
         gg_now = gg_now + guides(colour = guide_legend(nrow=2,byrow=TRUE))
         gg_now = gg_now + guides(shape  = guide_legend(nrow=2,byrow=TRUE))

         # Save plot in every format requested.
         for (d in sequence(ndevice)){
            f_output = paste0(&quot;RidgePlot_&quot;,xName,&quot;_by-&quot;,zName,&quot;_&quot;,base_suffix,&quot;.&quot;,gg_device[d])
            dummy = ggsave( filename = f_output
                          , plot     = gg_now
                          , device   = gg_device[d]
                          , path     = categ_trridge_path
                          , width    = gg_width
                          , height   = gg_height
                          , units    = gg_units
                          , dpi      = gg_depth
                          )#end ggsave
         }#end for (o in sequence(nout))
      
         # Write plot settings to the list.
         xzName = paste0(xName,&quot;_&quot;,zName)
         gg_Ridge[[xzName]] = gg_now
      }else{
         cat0(&quot; + Skip plot for &quot;,xDesc,&quot; by &quot;,zDesc,&quot;: too few valid points.&quot;)
         
      }#end if (PlotSMA)
   }#end for (y in yloop)
}#end for (ct in seq_along(CategTrait)){


# If sought, plot images on screen
cnt_gg_Ridge = length(gg_Ridge)
if (gg_screen &amp;&amp; (cnt_gg_Ridge %gt% 0L)){
   gg_show = sort(sample.int(n=cnt_gg_Ridge,size=min(cnt_gg_Ridge,3L),replace=FALSE))
   gg_Ridge[gg_show]
}#end if (gg_screen &amp;&amp; (length(gg_Ridge) %gt% 0L))</code></pre>
<p><img src="TraitTradeOffs_files/figure-html/plot-categ-ridge-1.png" width="768" /><img src="TraitTradeOffs_files/figure-html/plot-categ-ridge-2.png" width="768" /><img src="TraitTradeOffs_files/figure-html/plot-categ-ridge-3.png" width="768" /></p>
</div>
</div>




</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.odd').parent('tbody').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open');
  });
});
</script>

<!-- code folding -->


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
